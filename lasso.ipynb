{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49cb1a53-b491-425d-a007-2813a03ecaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPIKE-AND-SLAB-LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b01ca8-7ed4-4fff-9e4c-2b64e3c00382",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyro-ppl torch pandas matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ae3d7-56b3-4289-8849-fe4d67265838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from pyro.optim import ClippedAdam\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    # Training parameters\n",
    "    \"max_epochs\": 5000,\n",
    "    \"batch_size\": 128,\n",
    "    \"initial_lr\": 5e-4,\n",
    "    \"lr_decay\": 0.2,\n",
    "    \"decay_step\": 500,\n",
    "    \"clip_norm\": 10.0,\n",
    "    \"early_stop_patience\": 200,\n",
    "    \n",
    "    # Device and precision\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"precision\": torch.float32,\n",
    "    \"pin_memory\": False if torch.cuda.is_available() else True,  # Only pin if using CPU\n",
    "    \"num_workers\": 0,  # Set to 0 for Windows\n",
    "    \"cuda_deterministic\": False,\n",
    "    \n",
    "    # Model parameters\n",
    "    \"elbo_particles\": 10,\n",
    "    \"warmup_epochs\": 100,\n",
    "    \"n_folds\": 5,\n",
    "    \n",
    "    # Logging and checkpointing\n",
    "    \"log_freq\": 100,\n",
    "    \"checkpoint_freq\": 500,\n",
    "    \n",
    "    # Paths\n",
    "    \"data_path\": r\"D:\\cox-model-imputation\\error-in-r-code-for-mcar\\datasets\\vb-cox\\realistic_cox_data.csv\",\n",
    "    \"results_dir\": f\"results_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "}\n",
    "\n",
    "def setup_gpu():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        \n",
    "        # Set the default generator to CUDA and set seeds for reproducibility\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "        \n",
    "        print(\"\\nGPU Information:\")\n",
    "        print(f\"PyTorch version: {torch.__version__}\")\n",
    "        print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "        \n",
    "        # Initial GPU memory info (just once at startup)\n",
    "        print(f\"Initial GPU Memory: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB allocated, {torch.cuda.memory_reserved(0)/1024**2:.2f} MB reserved\")\n",
    "        \n",
    "        # Set for reproducibility\n",
    "        torch.backends.cudnn.deterministic = config[\"cuda_deterministic\"]\n",
    "        torch.backends.cudnn.benchmark = not config[\"cuda_deterministic\"]\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(\"\\nNo GPU available, using CPU\")\n",
    "        return False\n",
    "\n",
    "def load_and_preprocess(path, config):\n",
    "    print(f\"Loading data from: {path}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(path)\n",
    "        print(f\"Data shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Extract features and survival data\n",
    "    X = data.iloc[:, 1:-2].values  # Skip ID, time, event\n",
    "    time_values = data['time'].values\n",
    "    event_values = data['event'].values\n",
    "    \n",
    "    # Handle missing values and standardize\n",
    "    X = (X - np.nanmean(X, axis=0)) / (np.nanstd(X, axis=0) + 1e-8)\n",
    "    X = np.nan_to_num(X)\n",
    "    \n",
    "    # Convert to tensors and move to GPU if available\n",
    "    X_tensor = torch.tensor(X, dtype=config[\"precision\"]).to(config[\"device\"])\n",
    "    time_tensor = torch.tensor(time_values, dtype=config[\"precision\"]).to(config[\"device\"])\n",
    "    event_tensor = torch.tensor(event_values, dtype=config[\"precision\"]).to(config[\"device\"])\n",
    "    \n",
    "    print(f\"Data loading time: {time.time()-start_time:.2f}s\")\n",
    "    print(f\"Data loaded on: {X_tensor.device}\")\n",
    "    print(f\"Number of features: {X_tensor.shape[1]}\")\n",
    "    print(f\"Number of samples: {X_tensor.shape[0]}\")\n",
    "    print(f\"Event rate: {event_tensor.mean().item():.2%}\")\n",
    "    \n",
    "    return X_tensor, time_tensor, event_tensor\n",
    "\n",
    "class CoxPartialLikelihood(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-8\n",
    "        self.max_exp = 20.0\n",
    "        \n",
    "    def forward(self, X_beta, survival_time, event):\n",
    "        event_mask = event == 1\n",
    "        n_events = event_mask.sum()\n",
    "        \n",
    "        if n_events < 1:\n",
    "            return torch.tensor(0.0, device=X_beta.device)\n",
    "        \n",
    "        X_beta = X_beta - X_beta.max()\n",
    "        exp_Xb = torch.clamp(X_beta.exp(), max=torch.exp(torch.tensor(self.max_exp, device=X_beta.device)))\n",
    "        \n",
    "        risk_matrix = (survival_time.unsqueeze(0) >= survival_time[event_mask].unsqueeze(1)).float()\n",
    "        sum_exp = (risk_matrix * exp_Xb.unsqueeze(0)).sum(dim=1)\n",
    "        log_sum_exp = torch.log(sum_exp + self.eps)\n",
    "        \n",
    "        return (X_beta[event_mask] - log_sum_exp).sum() / X_beta.size(0)\n",
    "\n",
    "def model(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    device = X.device\n",
    "    \n",
    "    # Global shrinkage parameter\n",
    "    global_scale = pyro.sample(\"global_scale\", \n",
    "                             dist.HalfCauchy(torch.tensor(1.0, device=device)))\n",
    "    \n",
    "    # Use a single Normal distribution instead of a mixture for simplicity\n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        # Local shrinkage parameters\n",
    "        local_scale = pyro.sample(\"local_scale\", \n",
    "                                dist.HalfCauchy(torch.tensor(1.0, device=device)))\n",
    "        \n",
    "        # Use a single shrinkage prior\n",
    "        scale = global_scale * local_scale\n",
    "        beta = pyro.sample(\"beta\", dist.Normal(torch.zeros(p, device=device), scale))\n",
    "    \n",
    "    # Compute likelihood\n",
    "    cox_likelihood = CoxPartialLikelihood()\n",
    "    log_pl = cox_likelihood(X @ beta, survival_time, event)\n",
    "    pyro.factor(\"log_pl\", log_pl)\n",
    "    \n",
    "    return beta\n",
    "\n",
    "def guide(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    device = X.device\n",
    "    \n",
    "    # Define parameters for global scale\n",
    "    global_scale_loc = pyro.param(\n",
    "        \"global_scale_loc\", \n",
    "        torch.tensor(1.0, device=device),\n",
    "        constraint=constraints.positive\n",
    "    )\n",
    "    \n",
    "    global_scale_scale = pyro.param(\n",
    "        \"global_scale_scale\",\n",
    "        torch.tensor(0.1, device=device),\n",
    "        constraint=constraints.positive\n",
    "    )\n",
    "    \n",
    "    # Sample global scale\n",
    "    pyro.sample(\n",
    "        \"global_scale\",\n",
    "        dist.LogNormal(global_scale_loc.log(), global_scale_scale)\n",
    "    )\n",
    "    \n",
    "    # Define parameters for local scales and betas\n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        # Local scale parameters\n",
    "        local_scale_loc = pyro.param(\n",
    "            \"local_scale_loc\",\n",
    "            torch.ones(p, device=device),\n",
    "            constraint=constraints.positive\n",
    "        )\n",
    "        \n",
    "        local_scale_scale = pyro.param(\n",
    "            \"local_scale_scale\",\n",
    "            torch.ones(p, device=device) * 0.1,\n",
    "            constraint=constraints.positive\n",
    "        )\n",
    "        \n",
    "        # Sample local scales\n",
    "        pyro.sample(\n",
    "            \"local_scale\",\n",
    "            dist.LogNormal(local_scale_loc.log(), local_scale_scale)\n",
    "        )\n",
    "        \n",
    "        # Beta parameters\n",
    "        beta_loc = pyro.param(\n",
    "            \"beta_loc\", \n",
    "            torch.zeros(p, device=device)\n",
    "        )\n",
    "        \n",
    "        beta_scale = pyro.param(\n",
    "            \"beta_scale\",\n",
    "            torch.ones(p, device=device) * 0.1,\n",
    "            constraint=constraints.positive\n",
    "        )\n",
    "        \n",
    "        # Sample beta\n",
    "        pyro.sample(\"beta\", dist.Normal(beta_loc, beta_scale))\n",
    "\n",
    "def initialize_params():\n",
    "    # This function ensures all parameters are registered before training\n",
    "    device = config[\"device\"]\n",
    "    \n",
    "    # Initialize with dummy tensors just to register parameters\n",
    "    X_dummy = torch.zeros((10, 1000), device=device)\n",
    "    time_dummy = torch.zeros(10, device=device)\n",
    "    event_dummy = torch.zeros(10, device=device)\n",
    "    \n",
    "    # Run model and guide once with dummy data to register all parameters\n",
    "    pyro.clear_param_store()\n",
    "    model(X_dummy, time_dummy, event_dummy)\n",
    "    guide(X_dummy, time_dummy, event_dummy)\n",
    "    \n",
    "    # Print registered parameters\n",
    "    print(\"Initialized parameters:\")\n",
    "    for name, param in pyro.get_param_store().items():\n",
    "        print(f\"  {name}: {param.shape}\")\n",
    "\n",
    "class BayesianCoxModel:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = config[\"device\"]\n",
    "        pyro.clear_param_store()\n",
    "        \n",
    "        # Initialize parameters to ensure they're registered\n",
    "        initialize_params()\n",
    "\n",
    "    def train(self, train_loader, val_loader=None):\n",
    "        optimizer = ClippedAdam({\n",
    "            \"lr\": self.config[\"initial_lr\"],\n",
    "            \"clip_norm\": self.config[\"clip_norm\"],\n",
    "            \"weight_decay\": 1e-4\n",
    "        })\n",
    "        \n",
    "        svi = SVI(model, guide, optimizer, \n",
    "                 loss=Trace_ELBO(num_particles=self.config[\"elbo_particles\"]))\n",
    "        \n",
    "        best_loss = float('inf')\n",
    "        losses = []\n",
    "        val_losses = []\n",
    "        patience = 0\n",
    "        param_trajectories = {}\n",
    "        \n",
    "        # Initialize parameter trajectories with all current parameters\n",
    "        for name in pyro.get_param_store().keys():\n",
    "            param_trajectories[name] = []\n",
    "        \n",
    "        try:\n",
    "            for epoch in range(self.config[\"max_epochs\"]):\n",
    "                epoch_loss = 0.0\n",
    "                for batch_idx, (X_batch, t_batch, e_batch) in enumerate(train_loader):\n",
    "                    # Ensure data is on the correct device\n",
    "                    X_batch = X_batch.to(self.device)\n",
    "                    t_batch = t_batch.to(self.device)\n",
    "                    e_batch = e_batch.to(self.device)\n",
    "                    \n",
    "                    loss = svi.step(X_batch, t_batch, e_batch)\n",
    "                    epoch_loss += loss\n",
    "                \n",
    "                avg_loss = epoch_loss / len(train_loader)\n",
    "                losses.append(avg_loss)\n",
    "                \n",
    "                # Store parameter trajectories\n",
    "                for name, param in pyro.get_param_store().items():\n",
    "                    if name not in param_trajectories:\n",
    "                        param_trajectories[name] = []\n",
    "                    param_trajectories[name].append(param.detach().cpu().numpy())\n",
    "                \n",
    "                # Validation loss\n",
    "                if val_loader is not None:\n",
    "                    val_loss = self.evaluate(svi, val_loader)\n",
    "                    val_losses.append(val_loss)\n",
    "                    \n",
    "                    if val_loss < best_loss:\n",
    "                        best_loss = val_loss\n",
    "                        patience = 0\n",
    "                        # Save best model parameters\n",
    "                        self.save_checkpoint(epoch, val_loss)\n",
    "                    else:\n",
    "                        patience += 1\n",
    "                        \n",
    "                    if patience >= self.config[\"early_stop_patience\"]:\n",
    "                        print(f\"Early stopping at epoch {epoch}\")\n",
    "                        break\n",
    "                \n",
    "                # Learning rate decay\n",
    "                if epoch % self.config[\"decay_step\"] == 0 and epoch > 0:\n",
    "                    current_lr = self.config[\"initial_lr\"] * \\\n",
    "                               (self.config[\"lr_decay\"] ** (epoch // self.config[\"decay_step\"]))\n",
    "                    optimizer.set_state({'lr': current_lr})\n",
    "                    \n",
    "                if epoch % self.config[\"log_freq\"] == 0:\n",
    "                    print(f\"Epoch {epoch}: Loss = {avg_loss:.4f}\")\n",
    "                    if val_loader is not None:\n",
    "                        print(f\"Validation Loss = {val_losses[-1]:.4f}\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nTraining interrupted by user\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during training: {e}\")\n",
    "            raise\n",
    "        \n",
    "        return losses, val_losses, param_trajectories\n",
    "    \n",
    "    def evaluate(self, svi, loader):\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, t_batch, e_batch in loader:\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                t_batch = t_batch.to(self.device)\n",
    "                e_batch = e_batch.to(self.device)\n",
    "                val_loss += svi.evaluate_loss(X_batch, t_batch, e_batch)\n",
    "        return val_loss / len(loader)\n",
    "    \n",
    "    def save_checkpoint(self, epoch, val_loss):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss,\n",
    "            'param_store': pyro.get_param_store().get_state()\n",
    "        }\n",
    "        torch.save(checkpoint, \n",
    "                  os.path.join(self.config[\"results_dir\"], f'best_model.pth'))\n",
    "\n",
    "def cross_validate(model_class, X_tensor, time_tensor, event_tensor, config):\n",
    "    device = config[\"device\"]\n",
    "    # Use CPU for KFold as sklearn expects numpy arrays\n",
    "    kf = KFold(n_splits=config[\"n_folds\"], shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    \n",
    "    # Create array for KFold splitting (on CPU)\n",
    "    X_np = X_tensor.cpu().numpy()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_np)):\n",
    "        print(f\"\\nTraining fold {fold + 1}/{config['n_folds']}\")\n",
    "        \n",
    "        # Convert indices to torch tensors and move to GPU\n",
    "        train_idx = torch.tensor(train_idx, device=device)\n",
    "        val_idx = torch.tensor(val_idx, device=device)\n",
    "        \n",
    "        # Create data loaders for this fold\n",
    "        train_loader = DataLoader(\n",
    "            TensorDataset(X_tensor[train_idx], time_tensor[train_idx], event_tensor[train_idx]),\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            pin_memory=False,  # Don't pin CUDA tensors\n",
    "            generator=torch.Generator(device=device)  # Use CUDA generator for shuffling\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            TensorDataset(X_tensor[val_idx], time_tensor[val_idx], event_tensor[val_idx]),\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            pin_memory=False,  # Don't pin CUDA tensors\n",
    "            generator=torch.Generator(device=device)  # Use CUDA generator\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        model = model_class(config)\n",
    "        losses, val_losses, param_trajectories = model.train(train_loader, val_loader)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        with torch.no_grad():\n",
    "            beta = pyro.param(\"beta_loc\").detach()\n",
    "            risk_scores = X_tensor[val_idx] @ beta\n",
    "            \n",
    "            metrics = {\n",
    "                'c_index': concordance_index(\n",
    "                    time_tensor[val_idx].cpu().numpy(),\n",
    "                    -risk_scores.cpu().numpy(),\n",
    "                    event_tensor[val_idx].cpu().numpy()\n",
    "                ),\n",
    "                'final_loss': float(losses[-1]),\n",
    "                'param_trajectories': param_trajectories\n",
    "            }\n",
    "            \n",
    "            fold_results.append(metrics)\n",
    "        \n",
    "        # Clear GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "def plot_diagnostics(results_dir, fold_results, losses, param_trajectories):\n",
    "    # Create diagnostic plots directory\n",
    "    plots_dir = os.path.join(results_dir, 'plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. ELBO convergence plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(losses)\n",
    "    plt.title('ELBO Loss Convergence')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('ELBO Loss')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig(os.path.join(plots_dir, 'elbo_convergence.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Parameter trajectories\n",
    "    for param_name, trajectories in param_trajectories.items():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        trajectories_array = np.array(trajectories)\n",
    "        \n",
    "        if len(trajectories_array.shape) == 2:\n",
    "            for i in range(min(10, trajectories_array.shape[1])):\n",
    "                plt.plot(trajectories_array[:, i], alpha=0.5, label=f'Dim {i}')\n",
    "        else:\n",
    "            plt.plot(trajectories_array)\n",
    "            \n",
    "        plt.title(f'{param_name} Convergence')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(plots_dir, f'{param_name}_convergence.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    # 3. Cross-validation results\n",
    "    c_indices = [result['c_index'] for result in fold_results]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot(c_indices)\n",
    "    plt.title('Cross-validation C-index Distribution')\n",
    "    plt.ylabel('C-index')\n",
    "    plt.savefig(os.path.join(plots_dir, 'cv_c_index.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Feature importance and stability\n",
    "    beta_samples = np.stack([result['param_trajectories']['beta_loc'][-1] \n",
    "                           for result in fold_results])\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(beta_samples, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Coefficient Stability Across Folds')\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Fold')\n",
    "    plt.savefig(os.path.join(plots_dir, 'feature_stability.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Correlation analysis\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    corr_matrix = np.corrcoef(beta_samples.T)\n",
    "    sns.heatmap(corr_matrix, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.savefig(os.path.join(plots_dir, 'feature_correlation.png'))\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Setup GPU\n",
    "    setup_gpu()\n",
    "    \n",
    "    # Create results directory\n",
    "    os.makedirs(config[\"results_dir\"], exist_ok=True)\n",
    "    \n",
    "    # Save configuration\n",
    "    with open(os.path.join(config[\"results_dir\"], 'config.json'), 'w') as f:\n",
    "        json.dump({k: str(v) if isinstance(v, (torch.dtype, type)) else v \n",
    "                  for k, v in config.items()}, f, indent=2)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    try:\n",
    "        X_tensor, time_tensor, event_tensor = load_and_preprocess(config[\"data_path\"], config)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in data preprocessing: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    try:\n",
    "        fold_results = cross_validate(BayesianCoxModel, X_tensor, time_tensor, event_tensor, config)\n",
    "        \n",
    "        # Train final model on full dataset\n",
    "        dataset = TensorDataset(X_tensor, time_tensor, event_tensor)\n",
    "        train_loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            pin_memory=False,  # Don't pin CUDA tensors\n",
    "            generator=torch.Generator(device=config[\"device\"])  # Use CUDA generator\n",
    "        )\n",
    "        \n",
    "        final_model = BayesianCoxModel(config)\n",
    "        losses, _, param_trajectories = final_model.train(train_loader)\n",
    "        \n",
    "        # Plot diagnostics\n",
    "        plot_diagnostics(config[\"results_dir\"], fold_results, losses, param_trajectories)\n",
    "        \n",
    "        # Save results summary\n",
    "        results_summary = {\n",
    "            'mean_c_index': float(np.mean([r['c_index'] for r in fold_results])),\n",
    "            'std_c_index': float(np.std([r['c_index'] for r in fold_results])),\n",
    "            'final_loss': float(losses[-1]),\n",
    "            'n_epochs': len(losses),\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'user': config.get('user', 'unknown')\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(config[\"results_dir\"], 'results_summary.json'), 'w') as f:\n",
    "            json.dump(results_summary, f, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training: {e}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        raise\n",
    "    \n",
    "    finally:\n",
    "        # Clean up\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nProcess interrupted by user\")\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in main execution: {e}\")\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ba9df-0532-43d9-b2a3-29512ed8faed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc85bb4-b977-48c3-ba7e-e36e1ed06769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd424dc4-f394-41c9-9e03-40f8bcb1c644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0247711-44db-4046-8e9b-193075bfeafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92e86c4-fc1c-48ee-b387-e433a7d661a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7daecca-c450-4e27-b815-da0490bd6d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de728424-54ea-4b3b-ba14-d17fa3707f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd28fdf-2b29-4d44-ad1c-658a3078578f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f6482-14c4-4925-9d0e-8119d398f793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa08406-8b75-4bbb-a605-a6bc66255031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18108d56-3de9-438a-8a0a-28d66adcc7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
