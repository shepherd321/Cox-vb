{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a550445-b0c4-4e62-a5c3-c6f0e14eb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPIKE-AND-SLAB-LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7271f23e-591b-475e-a6f5-47c403923a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "print(f'CUDA version: {torch.version.cuda}')\n",
    "print(f'Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad948dfc-8b06-4fa5-8636-e1fe5e4b4b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyro-ppl in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (1.9.1)\n",
      "Requirement already satisfied: torch in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from pyro-ppl) (3.4.0)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from pyro-ppl) (0.1.2)\n",
      "Requirement already satisfied: tqdm>=4.36 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from pyro-ppl) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from tqdm>=4.36->pyro-ppl) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\chikomana\\anaconda3\\envs\\vb_cox_pymc\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyro-ppl torch pandas matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c52193-0815-4fa4-97fe-093cac30b826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading time: 0.22s\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected a 'cuda' device type for generator but found 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 223\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m2d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Feature \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m4d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Prob: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq_z[idx]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Coef: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mposterior_means[idx]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 223\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 149\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    146\u001b[0m epoch_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    147\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m--> 149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, t_batch, e_batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m    150\u001b[0m     loss \u001b[38;5;241m=\u001b[39m svi\u001b[38;5;241m.\u001b[39mstep(X_batch, t_batch, e_batch)\n\u001b[0;32m    151\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[1;32mC:\\Users\\CHIKOM~1\\ANACON~1\\envs\\vb_cox_pymc\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mC:\\Users\\CHIKOM~1\\ANACON~1\\envs\\vb_cox_pymc\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:672\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[1;32mC:\\Users\\CHIKOM~1\\ANACON~1\\envs\\vb_cox_pymc\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:620\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\CHIKOM~1\\ANACON~1\\envs\\vb_cox_pymc\\lib\\site-packages\\torch\\utils\\data\\sampler.py:288\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[0;32m    287\u001b[0m idx_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 288\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler:\n\u001b[0;32m    289\u001b[0m     batch[idx_in_batch] \u001b[38;5;241m=\u001b[39m idx\n\u001b[0;32m    290\u001b[0m     idx_in_batch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mC:\\Users\\CHIKOM~1\\ANACON~1\\envs\\vb_cox_pymc\\lib\\site-packages\\torch\\utils\\data\\sampler.py:168\u001b[0m, in \u001b[0;36mRandomSampler.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n):\n\u001b[1;32m--> 168\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandperm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandperm(n, generator\u001b[38;5;241m=\u001b[39mgenerator)\u001b[38;5;241m.\u001b[39mtolist()[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m%\u001b[39m n]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected a 'cuda' device type for generator but found 'cpu'"
     ]
    }
   ],
   "source": [
    "# Complete Variational Bayesian Cox Model with Spike-and-Slab Lasso Priors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import ClippedAdam\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    \"max_epochs\": 5000,\n",
    "    \"batch_size\": 256,\n",
    "    \"initial_lr\": 1e-3,\n",
    "    \"lr_decay\": 0.1,\n",
    "    \"decay_step\": 1000,\n",
    "    \"clip_norm\": 10.0,\n",
    "    \"early_stop_patience\": 200,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"precision\": torch.float32,\n",
    "    \"log_freq\": 100,\n",
    "    \"checkpoint_freq\": 500\n",
    "}\n",
    "\n",
    "# Set up GPU if available\n",
    "if config[\"device\"] == \"cuda\":\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "\n",
    "def load_and_preprocess(path):\n",
    "    start_time = time.time()\n",
    "    data = pd.read_csv(path)\n",
    "    print(f\"Data loading time: {time.time()-start_time:.2f}s\")\n",
    "    \n",
    "    # Extract features and survival data\n",
    "    X = data.iloc[:, 1:-2].values  # Skip ID, time, event\n",
    "    time_values = data['time'].values\n",
    "    event_values = data['event'].values\n",
    "    \n",
    "    # Handle missing values and standardize\n",
    "    X = (X - np.nanmean(X, axis=0)) / (np.nanstd(X, axis=0) + 1e-8)\n",
    "    X = np.nan_to_num(X)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_tensor = torch.tensor(X, dtype=config[\"precision\"], device=config[\"device\"])\n",
    "    time_tensor = torch.tensor(time_values, dtype=config[\"precision\"], device=config[\"device\"])\n",
    "    event_tensor = torch.tensor(event_values, dtype=config[\"precision\"], device=config[\"device\"])\n",
    "    \n",
    "    # Sort by survival time\n",
    "    sort_idx = torch.argsort(time_tensor)\n",
    "    return X_tensor[sort_idx], time_tensor[sort_idx], event_tensor[sort_idx]\n",
    "\n",
    "class CoxPartialLikelihood(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-8\n",
    "        self.max_exp = 20.0\n",
    "        \n",
    "    def forward(self, X_beta, survival_time, event):\n",
    "        event_mask = event == 1\n",
    "        n_events = event_mask.sum()\n",
    "        \n",
    "        if n_events < 1:\n",
    "            return torch.tensor(0.0)\n",
    "        \n",
    "        # Numerical stability\n",
    "        X_beta = X_beta - X_beta.max()\n",
    "        exp_Xb = torch.clamp(X_beta.exp(), max=torch.exp(torch.tensor(self.max_exp)))\n",
    "        \n",
    "        # Vectorized computation\n",
    "        risk_matrix = (survival_time.unsqueeze(0) >= survival_time[event_mask].unsqueeze(1)).float()\n",
    "        sum_exp = (risk_matrix * exp_Xb.unsqueeze(0)).sum(dim=1)\n",
    "        log_sum_exp = torch.log(sum_exp + self.eps)\n",
    "        \n",
    "        return (X_beta[event_mask] - log_sum_exp).sum() / X_beta.size(0)\n",
    "\n",
    "def model(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    alpha = pyro.sample(\"alpha\", dist.Beta(1., 100.))\n",
    "    \n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        z = pyro.sample(\"z\", dist.Bernoulli(alpha))\n",
    "        tau = pyro.sample(\"tau\", dist.HalfNormal(0.05))\n",
    "        theta = pyro.sample(\"theta\", dist.Laplace(0., 1/(tau + 1e-8)))\n",
    "        beta = z * theta\n",
    "    \n",
    "    cox_likelihood = CoxPartialLikelihood()\n",
    "    log_pl = cox_likelihood(X @ beta, survival_time, event)\n",
    "    pyro.factor(\"log_pl\", log_pl)\n",
    "\n",
    "def guide(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    alpha_a = pyro.param(\"alpha_a\", torch.tensor(1.), constraint=constraints.positive)\n",
    "    alpha_b = pyro.param(\"alpha_b\", torch.tensor(100.), constraint=constraints.positive)\n",
    "    pyro.sample(\"alpha\", dist.Beta(alpha_a, alpha_b))\n",
    "    \n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        q_z = pyro.param(\"q_z\", torch.ones(p)*0.01, constraint=constraints.interval(0., 1.))\n",
    "        pyro.sample(\"z\", dist.Bernoulli(q_z))\n",
    "        \n",
    "        tau_loc = pyro.param(\"tau_loc\", torch.zeros(p))\n",
    "        tau_scale = pyro.param(\"tau_scale\", torch.ones(p)*0.01, constraint=constraints.positive)\n",
    "        pyro.sample(\"tau\", dist.LogNormal(tau_loc, tau_scale))\n",
    "        \n",
    "        theta_loc = pyro.param(\"theta_loc\", torch.zeros(p))\n",
    "        theta_scale = pyro.param(\"theta_scale\", torch.ones(p)*0.1, constraint=constraints.positive)\n",
    "        pyro.sample(\"theta\", dist.Laplace(theta_loc, theta_scale))\n",
    "\n",
    "def main():\n",
    "    # Load and prepare data\n",
    "    data_path = r\"D:\\cox-model-imputation\\error-in-r-code-for-mcar\\datasets\\vb-cox\\realistic_cox_data.csv\"\n",
    "    X, survival_time, event = load_and_preprocess(data_path)\n",
    "    \n",
    "    # Create data loader\n",
    "    dataset = TensorDataset(X, survival_time, event)\n",
    "    loader = DataLoader(dataset, \n",
    "                      batch_size=config[\"batch_size\"], \n",
    "                      shuffle=True,\n",
    "                      pin_memory=config[\"device\"] == \"cuda\")\n",
    "    \n",
    "    # Initialize model\n",
    "    pyro.clear_param_store()\n",
    "    \n",
    "    # FIX: Use the proper pyro optimizer setup\n",
    "    optimizer = ClippedAdam({\n",
    "        \"lr\": config[\"initial_lr\"],\n",
    "        \"clip_norm\": config[\"clip_norm\"],\n",
    "        \"weight_decay\": 1e-4\n",
    "    })\n",
    "    \n",
    "    # No need for separate scheduler - pass the optimizer directly to SVI\n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO(num_particles=1))\n",
    "    \n",
    "    # Training setup\n",
    "    best_loss = float('inf')\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "    epoch_times = []\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(config[\"max_epochs\"]):\n",
    "            epoch_start = time.time()\n",
    "            total_loss = 0.0\n",
    "            \n",
    "            for X_batch, t_batch, e_batch in loader:\n",
    "                loss = svi.step(X_batch, t_batch, e_batch)\n",
    "                total_loss += loss\n",
    "            \n",
    "            avg_loss = total_loss / len(loader)\n",
    "            losses.append(avg_loss)\n",
    "            \n",
    "            # Manually update learning rate at specific epochs\n",
    "            if epoch % config[\"decay_step\"] == 0 and epoch > 0:\n",
    "                current_lr = config[\"initial_lr\"] * (config[\"lr_decay\"] ** (epoch // config[\"decay_step\"]))\n",
    "                optimizer.set_state({'lr': current_lr})\n",
    "                print(f\"Learning rate decreased to {current_lr:.2e}\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                patience = 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= config[\"early_stop_patience\"]:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "            \n",
    "            # Logging\n",
    "            epoch_time = time.time() - epoch_start\n",
    "            epoch_times.append(epoch_time)\n",
    "            if epoch % config[\"log_freq\"] == 0:\n",
    "                print(f\"Epoch {epoch:04d} | Loss: {avg_loss:.2f} | Time: {epoch_time:.2f}s\")\n",
    "            \n",
    "            # Checkpointing\n",
    "            if epoch % config[\"checkpoint_freq\"] == 0 and epoch > 0:\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'losses': losses,\n",
    "                    'params': pyro.get_param_store().get_state()\n",
    "                }\n",
    "                torch.save(checkpoint, f\"checkpoint_epoch_{epoch}.pt\")\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTraining interrupted by user\")\n",
    "    \n",
    "    # Final output\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {total_time/3600:.2f} hours\")\n",
    "    print(f\"Average epoch time: {np.mean(epoch_times):.2f}s\")\n",
    "    \n",
    "    # Save final model\n",
    "    final_state = {\n",
    "        'params': pyro.get_param_store().get_state(),\n",
    "        'losses': losses,\n",
    "        'config': config\n",
    "    }\n",
    "    torch.save(final_state, \"final_model.pt\")\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"Training Loss (Negative ELBO)\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"training_loss.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature analysis\n",
    "    q_z = pyro.param(\"q_z\").detach().cpu().numpy()\n",
    "    theta_loc = pyro.param(\"theta_loc\").detach().cpu().numpy()\n",
    "    posterior_means = q_z * theta_loc\n",
    "    \n",
    "    print(\"\\nTop 10 Features:\")\n",
    "    top_idx = np.argsort(-q_z)[:10]\n",
    "    for i, idx in enumerate(top_idx):\n",
    "        print(f\"{i+1:2d}. Feature {idx:4d} | Prob: {q_z[idx]:.4f} | Coef: {posterior_means[idx]:.6f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1485bf-6e93-40d5-8c4b-7e44d023729d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf610d9-6214-4b47-a150-32ccafec0cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e23984-e435-41cf-9a2e-f689afce5b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec483e-36a3-467b-a8a5-a001a11edbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4470e9a-5fe2-43e8-bb1a-1d663ed91066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading time: 0.20s\n",
      "Epoch 0000 | Loss: 201203.15 | Time: 0.04s\n",
      "Epoch 0100 | Loss: 91782.58 | Time: 0.04s\n",
      "Epoch 0200 | Loss: 42617.45 | Time: 0.05s\n",
      "Epoch 0300 | Loss: 20690.76 | Time: 0.05s\n",
      "Epoch 0400 | Loss: 10917.30 | Time: 0.05s\n",
      "Epoch 0500 | Loss: 6859.95 | Time: 0.04s\n",
      "Epoch 0600 | Loss: 5227.39 | Time: 0.05s\n",
      "Epoch 0700 | Loss: 4164.12 | Time: 0.05s\n",
      "Epoch 0800 | Loss: 3358.21 | Time: 0.06s\n",
      "Epoch 0900 | Loss: 2667.94 | Time: 0.04s\n",
      "Learning rate decreased to 1.00e-04\n",
      "Epoch 1000 | Loss: 2087.76 | Time: 0.05s\n",
      "Epoch 1100 | Loss: 1597.86 | Time: 0.04s\n",
      "Epoch 1200 | Loss: 1261.55 | Time: 0.03s\n",
      "Epoch 1300 | Loss: 1084.04 | Time: 0.04s\n",
      "Epoch 1400 | Loss: 1028.42 | Time: 0.05s\n",
      "Epoch 1500 | Loss: 996.26 | Time: 0.03s\n",
      "Epoch 1600 | Loss: 1037.54 | Time: 0.06s\n",
      "Epoch 1700 | Loss: 1038.40 | Time: 0.03s\n",
      "Early stopping at epoch 1764\n",
      "\n",
      "Training completed in 0.02 hours\n",
      "Average epoch time: 0.04s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Features:\n",
      " 1. Feature  418 | Prob: 0.3618 | Coef: -0.008205\n",
      " 2. Feature  653 | Prob: 0.3563 | Coef: 0.054447\n",
      " 3. Feature  847 | Prob: 0.3542 | Coef: 0.011081\n",
      " 4. Feature  270 | Prob: 0.3541 | Coef: -0.021383\n",
      " 5. Feature  423 | Prob: 0.3540 | Coef: -0.006755\n",
      " 6. Feature  420 | Prob: 0.3536 | Coef: -0.061419\n",
      " 7. Feature  169 | Prob: 0.3513 | Coef: 0.003790\n",
      " 8. Feature  360 | Prob: 0.3499 | Coef: 0.044806\n",
      " 9. Feature  100 | Prob: 0.3484 | Coef: -0.004839\n",
      "10. Feature  990 | Prob: 0.3476 | Coef: 0.000984\n",
      "\n",
      "Concordance Index (C-Index): 0.6629\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAIhCAYAAAAy8fsSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAADNyklEQVR4nOzdd3gUVRfH8e+mJ/ReAwm9CUiTXkRAOoYqRXqR3ovUgAIiVXqVJohUAVFAFEFAkQ6CgJhIC9JrIHXfP8bsS6gbSDIpv8/z7JPZ2dmZM+GycPbee67FarVaERERERERERHTOZgdgIiIiIiIiIgYlKSLiIiIiIiIxBFK0kVERERERETiCCXpIiIiIiIiInGEknQRERERERGROEJJuoiIiIiIiEgcoSRdREREREREJI5Qki4iIiIiIiISRyhJFxEREREREYkjlKSLiIi8omPHjtG2bVu8vb1xc3MjadKkFCtWjAkTJnDz5s0on2/UqFFYLJZI+ypXrkzlypVtz/39/bFYLEycOPF1w7fLyZMnGTVqFP7+/k+91qZNG7y8vGIljidZLJZIjxQpUlC5cmW+/fbbSMd5eXnRpk2bKJ8/MDCQUaNGsXPnzugJWERExE5K0kVERF7B/PnzKV68OL///jsDBgzg+++/Z/369TRu3Jg5c+bQvn37aLnOrFmzmDVrVrSc61WcPHkSX1/fZybpw4cPZ/369bEf1H8aNWrEvn372LNnDzNnzuTKlSvUrVv3qUT9VQQGBuLr66skXUREYp2T2QGIiIjEN/v27ePDDz+kWrVqbNiwAVdXV9tr1apVo1+/fnz//ffRcq0CBQpEy3kiBAYG4uHhES3nypkzZ7Sc51VlyJCB0qVLA1C2bFnKlClDrly5mDp1KrVr1zY1NhERkVelnnQREZEoGjt2LBaLhXnz5kVK0CO4uLhQr1492/NVq1ZRvXp1MmXKhLu7O/nz52fw4ME8ePDgpdd6crh7hPDwcD755BOyZcuGm5sbJUqUYMeOHZGOiRg+f+jQIRo1akSqVKlsifWBAwdo1qwZXl5euLu74+Xlxfvvv88///xje//ixYtp3LgxAFWqVLENLV+8eDHw7OHujx49YsiQIXh7e+Pi4kKWLFno1q0bt2/fjnScl5cXderU4fvvv6dYsWK4u7uTL18+Fi1a9NLfyfPkzJmTdOnSRbqHZzl//jwtW7Ykffr0uLq6kj9/fiZNmkR4eDhgTClIly4dAL6+vrb7fpVh8yIiIlGlnnQREZEoCAsL48cff6R48eJ4enra9Z6zZ89Sq1YtevfuTZIkSfjzzz/59NNP2b9/Pz/++OMrxTFjxgyyZ8/O1KlTCQ8PZ8KECdSsWZOff/6ZMmXKRDrWx8eHZs2a0aVLF9sXA/7+/uTNm5dmzZqROnVqAgICmD17NiVLluTkyZOkTZuW2rVrM3bsWD766CNmzpxJsWLFgOf3oFutVho0aMCOHTsYMmQIFSpU4NixY4wcOZJ9+/axb9++SF9qHD16lH79+jF48GAyZMjAggULaN++Pbly5aJixYpR/p3cunWLGzdukDt37ucec+3aNcqWLUtwcDBjxozBy8uLzZs3079/f86dO8esWbPIlCkT33//Pe+++y7t27enQ4cOALbEXUREJCYpSRcREYmC69evExgYiLe3t93vGTZsmG3barVSrlw58ufPT6VKlTh27BiFCxeOchxhYWFs374dNzc3AGrUqIGXlxcjRoxg+/btkY5t3bo1vr6+kfY1atSIRo0aRTpfnTp1yJAhAytWrKBnz56kS5fOlvAWKFDANrT8ebZt28bWrVuZMGECAwYMAIzh/56enjRt2pSlS5fSsWNH2/HXr19nz549ZMuWDYCKFSuyY8cOVqxYYVeSbrVaCQ0NxWq1cu7cOfr27Ut4eDgtWrR47nsmT57MpUuX+O233yhVqhRg/O7CwsKYM2cOvXv3Jk+ePBQvXhyArFmzvvS+RUREopOGu4uIiMSwv//+m+bNm5MxY0YcHR1xdnamUqVKAJw6deqVzunj42NL0AGSJUtG3bp12bVrF2FhYZGObdiw4VPvv3//PoMGDSJXrlw4OTnh5ORE0qRJefDgwSvHFDEq4Mlh4Y0bNyZJkiRPDccvWrSoLUEHcHNzI0+ePC8drh5h1qxZODs74+LiQv78+dm7dy+jR4+ma9euL4yxQIECtgQ9Qps2bbBara88skFERCS6qCddREQkCtKmTYuHhwd+fn52HX///n0qVKiAm5sbH3/8MXny5MHDw4MLFy7g4+PDw4cPXymOjBkzPnNfcHAw9+/fJ0WKFLb9mTJleurY5s2bs2PHDoYPH07JkiVJnjw5FouFWrVqvXJMN27cwMnJ6alh4RaLhYwZM3Ljxo1I+9OkSfPUOVxdXe2+fpMmTRgwYAAWi4VkyZKRM2dOHB0dXxrjs5aNy5w5s+11ERERMylJFxERiQJHR0eqVq3Kd999x8WLF8maNesLj//xxx+5fPkyO3futPWeA08VUouqK1euPHOfi4sLSZMmjbT/ybXX79y5w+bNmxk5ciSDBw+27Q8KCnql9d0jpEmThtDQUK5duxYpUbdarVy5coWSJUu+8rmfJV26dJQoUSLKMQYEBDy1//Lly4DxJYyIiIiZNNxdREQkioYMGYLVaqVjx44EBwc/9XpISAibNm0C/p8gP1kFfu7cua8Vw7p163j06JHt+b1799i0aRMVKlR4aW+yxWLBarU+FdOCBQueGiofcYw9vdtVq1YFYPny5ZH2r127lgcPHtheN1PVqlU5efIkhw4dirR/6dKlWCwWqlSpAkTtvkVERKKTetJFRESiqEyZMsyePZuuXbtSvHhxPvzwQwoWLEhISAiHDx9m3rx5FCpUiLp161K2bFlSpUpFly5dGDlyJM7Oznz55ZccPXr0tWJwdHSkWrVqtmJpn376KXfv3n2qQNyzJE+enIoVK/LZZ5+RNm1avLy8+Pnnn1m4cCEpU6aMdGyhQoUAmDdvHsmSJcPNzQ1vb+9nDlWvVq0aNWrUYNCgQdy9e5dy5crZqru/+eabtGrV6rXuOTr06dOHpUuXUrt2bUaPHk327Nn59ttvmTVrFh9++CF58uQBjDn+2bNn55tvvqFq1aqkTp3a9rsSERGJSepJFxEReQUdO3bkwIEDFC9enE8//ZTq1avToEEDVq5cSfPmzZk3bx5gDK/+9ttv8fDwoGXLlrRr146kSZOyatWq17p+9+7dqVatGj179qR58+aEhoby7bffUq5cObvev2LFCqpUqcLAgQPx8fHhwIEDbN++PdJcdgBvb2+mTp3K0aNHqVy5MiVLlrSNEniSxWJhw4YN9O3bly+++IJatWoxceJEWrVqxY8//vjMNeVjW7p06di7dy9vv/02Q4YMoU6dOraK9NOnT4907MKFC/Hw8KBevXqULFmSUaNGmRO0iIgkKhar1Wo1OwgRERERERERUU+6iIiIiIiISJyhJF1EREREREQkjlCSLiIiIiIiIhJHKEkXERERERERiSOUpIuIiIiIiIjEEaYm6bt27aJu3bpkzpzZtmzLy/z8888UL14cNzc3cuTIwZw5c2I+UBEREREREZFY4GTmxR88eECRIkVo27YtDRs2fOnxfn5+1KpVi44dO7J8+XL27NlD165dSZcunV3vBwgPD+fy5cskS5YMi8XyurcgIiIiIiIi8kJWq5V79+6ROXNmHBxe3FceZ9ZJt1gsrF+/ngYNGjz3mEGDBrFx40ZOnTpl29elSxeOHj3Kvn377LrOxYsX8fT0fN1wRURERERERKLkwoULZM2a9YXHmNqTHlX79u2jevXqkfbVqFGDhQsXEhISgrOz81PvCQoKIigoyPY84jsJPz8/kiVLFrMBR7OQkBB++uknqlSp8sx7FQG1E7GP2onYS21F7KF2IvZQOxF7JNR2cu/ePby9ve3KQeNVkn7lyhUyZMgQaV+GDBkIDQ3l+vXrZMqU6an3jBs3Dl9f36f279u3Dw8PjxiLNaZ4eHjw22+/mR2GxHFqJ2IPtROxl9qK2EPtROyhdiL2SIjtJDAwEMCuKdfxKkmHp28qomf8eTc7ZMgQ+vbta3t+9+5dPD09qV69OsmTJ4+5QGNASEgI27dvp1q1agnqWyWJXmonYg+1E7GX2orYQ+1E7KF2IvZIqO3k7t27dh8br5L0jBkzcuXKlUj7rl69ipOTE2nSpHnme1xdXXF1dX1qv7Ozc7z9Q4/PsUvsUTsRe6idiL3UVsQeaidiD7UTsUdCaydRuZd4tU56mTJl2L59e6R927Zto0SJEgnqD1BEREREREQSJ1N70u/fv89ff/1le+7n58eRI0dInTo12bJlY8iQIVy6dImlS5cCRiX3GTNm0LdvXzp27Mi+fftYuHAhK1eujNa4rFYroaGhhIWFRet5X1dISAhOTk48evQozsUmcYO+rBIRERERid9MTdIPHDhAlSpVbM8j5o63bt2axYsXExAQwPnz522ve3t7s2XLFvr06cPMmTPJnDkzn3/+ud1rpNsjODiYgIAA28T+uMRqtZIxY0YuXLigNd7lmSwWCxkzZjQ7DBEREREReUWmJumVK1fmRcu0L168+Kl9lSpV4tChQzEST3h4OH5+fjg6OpI5c2ZcXFziVDIcHh7O/fv3SZo0KQ4O8WqmgsQCq9XKtWvXCAgIiFPtVkRERERE7BevCsfFtODgYMLDw/H09IyTy7OFh4cTHByMm5ubknR5pnTp0nH//n0cHR3NDkVERERERF6BMr1nUAIs8ZV60EVERERE4jdloyIiIiIiIiJxhJJ0ERERERERkThCSXoMCQuDnTth5UrjZ3xZMW3x4sWkTJnS9nzUqFEULVrU9rxNmzY0aNAgVmPy8vJi6tSpsXpNERERERERMyhJjwHr1oGXF1SpAs2bGz+9vIz9MenKlSv06NGDHDly4OrqiqenJ3Xr1mXHjh2vfM7+/fu/1vuj4skvCCL8/vvvdOrUKVZiEBERERERMZOqu0ezdeugUSN4cmW5S5eM/WvWgI9P9F/X39+fcuXKkTJlSiZMmEDhwoUJCQlh69atdOvWjT///POVzps0aVKSJk36WrEFBwfj4uLyyu9Ply7da13fLCEhITg7O5sdhoiIiIiIxCPqSX8JqxUePLDvcfcu9Oz5dIIecR6AXr2M4+w53wuWkH9K165dsVgs7N+/n0aNGpEnTx4KFixI3759+fXXX23HTZ48mTfeeIMkSZLg6elJ165duX///nPP++Rw9wi+vr6kT5+e5MmT07lzZ4KDg22vVa5cme7du9O3b1/Spk1LtWrVXnrtnTt30rZtW+7cuYPFYsFisTBq1Cjg6eHu58+fp379+iRNmpTkyZPTpEkT/v3336diXrZsGV5eXqRIkYJmzZpx7969F/4O9+zZQ6VKlfDw8CBVqlTUqFGDW7duPTMGgKJFi9piBKOy+pw5c6hfvz5JkiRh9OjRZM2alTlz5kR636FDh7BYLPz9998A3Llzh06dOtl+n2+//TZHjx59YawiIiIiIoldfJ1i/DJK0l8iMBCSJrXvkSKF0WP+PFYrXLxoHGfP+QID7Yvx5s2bfP/993Tr1o0kSZI89frjQ8gdHBz4/PPPOXHiBEuWLOHHH39k4MCBUfqd7Nixg1OnTvHTTz+xcuVK1q9fj6+vb6RjlixZgpOTE3v27GHu3LkvvXbZsmWZOnUqyZMnJyAggICAAPr37//Uta1WKw0aNODmzZv8/PPPbN++nXPnztG0adNIx507d44NGzawefNmNm/ezM8//8z48eOfe09HjhyhatWqFCxYkH379vHLL79Qt25dwqL4N33kyJHUr1+f48eP06FDB5o1a8aXX34Z6ZgVK1ZQpkwZcuTIgdVqpXbt2ly5coUtW7Zw8OBBihUrRtWqVbl582aUri0iIiIikliYNcU4Nmi4ewLw119/YbVayZcv30uP7d27t23b29ubMWPG8OGHHzJr1iy7r+fi4sKiRYvw8PCgYMGCjB49mgEDBjBmzBjbGvO5cuViwoQJdl/bxcWFFClSYLFYyJgx43Ov/cMPP3Ds2DH8/Pzw9PQEYNmyZRQsWJDff/+dkiVLAhAeHs7ixYtJliwZAK1atWLHjh188sknzzzvhAkTKFGiRKTfQ8GCBe3+nURo3rw57dq1sz1v0aIFkydP5p9//iF79uyEh4fz1Vdf8dFHHwHw008/cfz4ca5evYqrqysAEydOZMOGDaxZs0Zz8UVEREREnmDWFOPYop70l/DwgPv37Xts2WLfObdsse98Hh72nc/6X+u0WCwvPfann36iWrVqZMmShWTJkvHBBx9w48YNHjx4YN/FgCJFiuDxWHBlypTh/v37XLhwwbavRIkSMXLtU6dO4enpaUvQAQoUKEDKlCk5deqUbZ+Xl5ctQQfIlCkTV69efe55I3rSX9eT9/3mm2+SL18+Vq5cCcDPP//M1atXadKkCQAHDx7k/v37pEmTxjb/P2nSpPj5+XHu3LnXjkdEREREJCEJCzOmEP8/Qb9jey1iX+/e8Xvou5L0l7BYIEkS+x7Vq0PWrMZ7nncuT0/jOHvOZ0fODUDu3LmxWCyRktRn+eeff6hVqxaFChVi7dq1HDx4kJkzZwJGkbPX9fiXBE8Ou4+ua1ut1md+GfHk/icLtlksFsLDw597Xnd39xde18HBwfZlSIRnxf2s6QYtWrRgxYoVgDHUvUaNGqRNmxYwevwzZcrEkSNHIj1Onz7NgAEDXhiTiIiIiEhis3u3MYUYTgOtAC/ghu11qxUuXDCOi6+UpEcjR0eYNs3YfjKPjHg+dapxXHRKnTo1NWrUYObMmc/slb59+zYABw4cIDQ0lEmTJlG6dGny5MnD5cuXo3y9o0eP8vDhQ9vzX3/9laRJk5I1a9bnvseea7u4uLx0DniBAgU4f/58pF77kydPcufOHfLnzx/le4lQuHDhFy41ly5dOgICAmzP7969i5+fn13nbt68OcePH+fgwYOsWbOGFi1a2F4rVqwYV65cwcnJiVy5ckV6RCTyIiIiIiJiOHDgT6AFUABYDtwGNj913GP/dY93lKRHMx8fYw5EliyR92fNGrNzI2bNmkVYWBilSpVi7dq1nD17llOnTvH5559TpkwZAHLmzEloaCjTp0/n77//ZtmyZU9VHrdHcHAw7du35+TJk3z33XeMHDmS7t272+ajP4s91/by8uL+/fvs2LGD69evE/iMynnvvPMOhQsXpkWLFhw6dIj9+/fzwQcfUKlSpWcOsbfXkCFD+P333+natSvHjh3jzz//ZPbs2Vy/fh2At99+m2XLlrF7925OnDhB69atcbTz2xZvb2/Kli1L+/btCQ0NpX79+pHup0yZMjRo0ICtW7fi7+/P3r17GTZsGAcOHHjl+xERERERSWiuX7/ORx8VAVYA4UBd4Heg9VPHZsoUu7FFJyXpMcDHB/z94aefYMUK46efX8wWL/D29ubQoUNUqVKFfv36UahQIapVq8aOHTuYPXs2YCwZNnnyZD799FMKFSrEl19+ybhx46J8rapVq5I7d24qVqxIkyZNqFu3bqSlyJ7FnmuXLVuWLl260LRpU9KlS/dU4Tkwhq1v2LCBVKlSUbFiRd555x1y5MjBqlWronwfj8uTJw/btm3j6NGjlCpVijJlyvDNN9/g5GTUVhwyZAgVK1akTp061KpViwYNGpAzZ067z9+iRQuOHj2Kj49PpKH1FouFLVu2ULFiRdq1a0eePHlo1qwZ/v7+ZMiQ4bXuSUREREQkvrv02PJZadOmpUWLFjg71wcOAhuByB11EVOMK1SI1TCjlcX65ETbBO7u3bukSJGCO3fukDx58kivPXr0CD8/P7y9vXFzczMpwucLDw/n7t27JE+e/IW91pJ4PXr0iL///hs/Pz+qV6/+1Nx8kQghISFs2bKFWrVqqZ3IC6mtiD3UTsQeaidij4h2ki1bNsaPH8/atWs5duwYBQoUAOD330MpV86JZ5W1iphiHBeru78oD32SlmATERERERGROOH48eNMmDCBvXv32vZt27aNAgUKcPMmNG1qJOjFisHVqxFF5AxZsxo1wOJagh5VStJFRERERETEVMeOHWP06NGsXbvWtq9x48YMHz6cN954g/BwaNnSmEacIwf88AMkT25UcQ8IMOagV6gQ/UW6zaAkXUREREREREwTFBTEO++8w7Vr17BYLJQtW5bp06fz5ptv2o4ZPRq++w7c3GDdOkiVythfubI5McckJekiIiIiIiISq44fP07BggVxcHDA1dWVAQMGcOjQIQYNGsQ///xDoUKFbMd++y34+hrb8+ZBkSImBR1LVH1MREREREREYsXBgwepV68ehQsXZuPGjbb9/fv3Z+XKlRQsWDDS8efOGcPcAbp1g1atYjNacyhJFxERERERkRj1+++/U6dOHUqUKMGmTZtwcHDg6NGjttctEaXZHxMYCA0bwu3bULo0TJ4ciwGbSMPdRUREREREJEbs378fX19ftmzZAoCDgwPNmzdn2LBh5M2b97nvs1qhSxc4ehTSpzeWVXNxia2ozaUkXURERERERKKd1WqlS5cuHD58GAcHB1q2bMnQoUPJkyfPS987d64Dy5YZ1dpXrYIsWWIh4DhCw91FREREREQkWuzbt4979+4BxhB2X19fWrduzZ9//smSJUvsStD//DMV/foZqeqnnybMCu4voiRdXmrevHl4enri4ODA1KlTzQ7Hbjt37sRisXD79m0AFi9eTMqUKW2vjxo1iqJFi8ZqTJUrV6Z3796xek0RERERkZi2Z88eqlevTtmyZZk1a5Ztf926dVm8eDG5c+e26zz//gsTJpQkJMRC48bQt29MRRx3KUlPINq0aYPFYsFiseDs7EyOHDno378/Dx48eK3z3r17l+7duzNo0CAuXbpEp06dXjvWJ5Pl2NK0aVPOnDkTK9d68guCCOvWrWPMmDGxEoOIiIiISEz75ZdfqFatGuXLl2f79u04OTlx48aNVzpXaCi0aOHIzZvu5MtnZeFCeEY9uQRPc9ITkHfffZcvvviCkJAQdu/eTYcOHXjw4AGzZ8+O8rmsVithYWGcP3+ekJAQateuTaZMmWIg6tjj7u6Ou7v7a50jODgYl9eoWJE6derXur6IiIiISFywe/duRo0axY8//giAk5MTbdq04aOPPsLb2/uVzjl4MOza5YC7ewhffw3JkjlHZ8jxhnrS7fTgwYPnPh49emT3sQ8fPrTr2Ffh6upKxowZ8fT0pHnz5rRo0YINGzYARtI9YcIEcuTIgbu7O0WKFGHNmjW290b0/G7dupUSJUrg6urKsmXLeOONNwDIkSMHFosFf39/ADZt2kTx4sVxc3MjR44c+Pr6Ehoaajvf7du36dSpExkyZMDNzY1ChQqxefNmdu7cSdu2bblz546t53/UqFHPvaeNGzdSokQJ3NzcSJs2LT4+PrbXli9fTokSJUiWLBkZM2akefPmXL169bnnel4P/ty5c/H09MTDw4PGjRtH6v1u06YNDRo0YNy4cWTOnNk2h+ZF1/b396dKlSoApEqVCovFQps2bYCnh7vfunWLDz74gFSpUuHh4UHNmjU5e/bsUzFv3bqV/PnzkzRpUt59910CAgKee58iIiIiIjFt5syZ/Pjjjzg7O9OpUyfOnj3L/PnzXzlBX70aJk0ytnv2PEy+fNEYbDyjJN1OSZMmfe6jYcOGkY5Nnz79c4+tWbNmpGO9vLyeeVx0cHd3JyQkBIBhw4bxxRdfMHv2bP744w/69OlDy5Yt+fnnnyO9Z+DAgYwbN45Tp05RvXp1fvjhB8BYOiEgIABPT0+2bt1Ky5Yt6dmzJydPnmTu3LksXryYTz75BIDw8HBq1qzJ3r17Wb58OSdPnmT8+PE4OjpStmxZpk6dSvLkyQkICCAgIID+/fs/M/5vv/0WHx8fateuzeHDh9mxYwclSpSwvR4cHMyYMWM4evQoGzZswM/Pz5YM2+uvv/7i66+/ZtOmTXz//fccOXKEbt26RTpmx44dnDp1iu3bt7N58+aXXtvT05O1a9cCcPr0aQICApg2bdozr9+mTRsOHDjAxo0b2bdvH1arlVq1atn+3AACAwOZOHEiy5YtY9euXZw/f/65vzMRERERkZiwc+dO/Pz8bM+HDx9O586dOXv2LHPnzsXLy+uVz33yJLRta2z36xdGmTKJvEPKmsjcuXPHCljv3Lnz1GsPHz60njx50vrw4cOnXgOe+6hVq1akYz08PJ57bKVKlSIdmzZt2mce9yxhYWHWW7duWcPCwp56rXXr1tb69evbnv/222/WNGnSWJs0aWK9f/++1c3Nzbp3795I72nfvr31/ffft1qtVutPP/1kBawbNmyIdMzhw4etgNXPz8+2r0KFCtaxY8dGOm7ZsmXWTJkyWa1Wq3Xr1q1WBwcH6+nTp595H1988YU1RYoUz3ztcWXKlLG2aNHipcdF2L9/vxWw3rt3L9I93bp165nXHTlypNXR0dF64cIF277vvvvO6uDgYA0ICLBarcbvNUOGDNagoKDXunaESpUqWXv16mW1Wq3WM2fOWAHrnj17bK9fv37d6u7ubv36669tMQPWv/76y3bMzJkzrRkyZHhmHA8fPrT+8ccf1s2bN1uDg4NfGLMkbsHBwdYNGzaonchLqa2IPdROxB5qJ/FPeHi4dceOHdaKFStaAWubNm2i/Rp37litefNarWC1vv221RoYmDDbyYvy0CdpTrqd7t+//9zXHB0dIz1/0ZBrB4fIgxciho9Hh82bN5M0aVJCQ0MJCQmhfv36TJ8+nZMnT/Lo0SOqVasW6fjg4GDefPPNSPse76l+noMHD/L777/bes4BwsLCePToEYGBgRw5coSsWbPatbzCixw5coSOHTs+9/XDhw8zatQojhw5ws2bNwkPDwfg/PnzFChQwK5rZMuWjaxZs9qelylThvDwcE6fPk3GjBkBeOONN56ahx4d1z516hROTk689dZbtn1p0qQhb968nDp1yrbPw8ODnDlz2p5nypTphW1MREREROR1WK1WduzYga+vL7/88gsALi4upEiRAqvViiWaqrlZrUYP+unTkDUrrFwJTspQVTjOXkmSJDH92JepUqUKs2fPxtnZmcyZM+PsbBRaiBiW8u2335IlS5ZI73F1dY1yPOHh4fj6+kaaHx7Bzc3ttYuzRXjReR48eED16tWpXr06y5cvJ126dJw/f54aNWoQHBz8yteM+MB5/IPnyd9JdF3barU+d//j14/4c3w8xue9V0RERETkdfz0008MGzaMvXv3Aka+0KlTJwYNGvRULvG6PvsM1q0DFxdYuxbSp4fHZn0mWkrSE5AkSZKQK1eup/YXKFAAV1dXzp8/T6VKlV77OsWKFeP06dPPvBZA4cKFuXjxImfOnHlmb7qLiwthYWEvvU7hwoXZsWMHbSMmqDzmzz//5Pr164wfPx5PT08ADhw4EMU7MXq+L1++TObMmQHYt28fDg4OLxwFYM+1I3reX3SfBQoUIDQ0lN9++42yZcsCcOPGDc6cOUP+/PmjfC8iIiIiIq/r559/Zu/evbi5udmS84j/K0enH3+EIUOM7c8/h1Klov0S8ZaS9EQgWbJk9O/fnz59+hAeHk758uW5e/cue/fuJWnSpLRu3TpK5xsxYgR16tTB09OTxo0b4+DgwLFjxzh+/Dgff/wxlSpVomLFijRs2JDJkyeTK1cu/vzzTywWC++++y5eXl7cv3+fHTt2UKRIETw8PPDw8HjqOiNHjqRq1arkzJmTZs2aERoaynfffcfAgQPJli0bLi4uTJ8+nS5dunDixIlXWn/czc2N1q1bM3HiRO7evUvPnj1p0qSJbaj7s9hz7ezZs2OxWNi8eTO1atXC3d39qYKAuXPnpn79+nTs2JG5c+eSLFkyBg8eTJYsWahfv36U70VEREREJCqsVivfffcdKVOmtHUa9e7dm8DAQPr06RNjSzBfuABNm0J4uDHcvVOnGLlMvKXq7onEmDFjGDFiBOPGjSN//vzUqFGDTZs2vdISCTVq1GDz5s1s376dkiVLUrp0aSZPnkz27Nltx6xdu5aSJUvy/vvvU6BAAQYOHGjrVS5btixdunShadOmpEuXjgkTJjzzOpUrV2b16tVs3LiRokWL8vbbb/Pbb78BkC5dOhYvXszq1aspUKAA48ePZ+LEiVG+l1y5cuHj40OtWrWoXr06hQoVYtasWS98jz3XzpIlC76+vgwePJgMGTLQvXv3Z57riy++oHjx4tSpU4cyZcpgtVrZsmXLU0PcRURERESii9Vq5dtvv+Wtt96idu3a9O/f3zadMmXKlEyYMCHGEvSgIGjUCK5fhzffhJkzIZqmuCcYFmsim9x69+5dUqRIwZ07d0iePHmk1x49eoSfnx/e3t64ubmZFOHzhYeHc/fuXZInT/5UAToRMNrw33//jZ+fH9WrV1eyL88VEhLCli1bqFWrltqJvJDaithD7UTsoXZiPqvVyubNmxk9erRtuqa7uztdu3Zl7NixTxVLjgldusDcuZAqFRw8CE/2GSbUdvKiPPRJGu4uIiIiIiKSwP3000/079+fQ4cOAcYKQt26daN///6kT58+VmL44gsjQbdYYMWKpxN0MShJFxERERERSeD+/fdfDh06RJIkSWzJebp06WLt+ocOwYcfGtu+vvDuu7F26XhHSbqIiIiIiEgCEh4ezjfffENwcDBNmzYFoHHjxpw/f5527dqRNm3aWI3nxg1o2NCYj16nDgwdGquXj3c0sVlERERERCQBCA8PZ+3atbz55pv4+PjQp08fHj58CICjoyMDBw6M9QQ9LAxatAB/f8iZE5YtA5XXejH1pD9DIqulJwmI2q6IiIhI4hORnI8ePZoTJ04AxjLM7du3t62wZBZfX9i6FdzdYd06SJnS1HDiBSXpj4moHhgYGIi7u7vJ0YhEXXBwMGB8UIuIiIhIwrd7924+/PBD/vjjDwCSJ09Or1696N27N6lTpzY1ts2bYcwYY3vePChc2NRw4g0l6Y9xdHQkZcqUXL16FTAqHlri0KJ94eHhBAcH8+jRIy3BJk8JDw/n2rVruLu7K0kXERERSSSSJk3KH3/8QYoUKejduze9evUiVapUZofFX39By5bGdvfu/9+Wl1OS/oSMGTMC2BL1uMRqtfLw4UPc3d3j1JcHEnc4ODiQOXNms8MQERERkRgQFhbGqlWr+OeffxgyZAgAb775JitWrKBmzZqkjCNjyQMDwccH7tyBsmVh0iSzI4pflKQ/wWKxkClTJtKnT09ISIjZ4UQSEhLCrl27qFixom1ovsjjXFxcTJ93JCIiIiLRKzQ0lK+++oqPP/6Y06dP4+zsTMuWLfH09ATg/fffNznC/7NaoXNnOH4cMmSA1avBxcXsqOIXJenP4ejoiKOjo9lhROLo6EhoaChubm5K0uW5lKSLiIiIJAyhoaGsWLGCjz/+mLNnzwKQOnVq+vbtG2d6zZ80cyYsXw6OjvD116BBnlGnJF1ERERERCSOOXjwIM2aNeOvv/4CIE2aNPTr14/u3buTLFkyk6N7tr17oU8fY/uzz6BiRXPjia+UpIuIiIiIiMQx2bJl4/Lly6RJk4b+/fvTrVu3OJucA1y5Ao0aQWgoNG0KvXubHVH8pSRdRERERETERCEhISxbtoxffvmFRYsWAZAuXTq+/fZbSpQoQdKkSU2O8MVCQozEPCAAChSABQtAda5fnZJ0EREREREREwQHB7N06VLGjh2Ln58fAG3btqVChQoAVK5c2cTo7DdoEOzaBcmSwbp1EMe/U4jzlKSLiIiIiIjEouDgYBYvXszYsWP5559/AEifPj0DBw6kWLFiJkcXNatWwZQpxvaSJZA3r7nxJARK0kVERERERGLJmTNnqFatGufPnwcgQ4YMDBw4kC5duuDh4WFydFHzxx/Qvr2xPXgwvPeeufEkFErSRUREREREYom3tzeOjo5kzJiRQYMG0alTp3iXnAPcuQM+PvDgAbzzDnz8sdkRJRxK0kVERERERGJAUFAQCxcuZOXKlezYsQMXFxecnZ3ZtGkTOXLkwN3d3ewQX4nVCm3awJkz4OkJK1YY66JL9HAwOwAREREREZGE5NGjR8yYMYOcOXPSrVs3fvnlF1asWGF7vWDBgvE2QQf49FPYsAFcXGDtWkiXzuyIEhb1pIuIiIiIiESDhw8fMn/+fD799FMuX74MQNasWRkyZAjNmjUzObro8cMPMHSosT1jBpQsaW48CZGSdBERERERkdd0/fp1ChcuTEBAAACenp4MGTKEdu3a4erqanJ00eP8eXj/fQgPh3btoEMHsyNKmJSki4iIiIiIvILw8HAcHIwZxGnTpqVQoUI4Ozvz0Ucf0aZNmwSTnAM8egQNG8L161C8OMycCRaL2VElTErSRUREREREouDBgwfMmTOHmTNnsm/fPjJkyADAkiVLSJMmDS4uLiZHGP169YIDByB1alizBtzczI4o4TK9cNysWbPw9vbGzc2N4sWLs3v37hceP3PmTPLnz4+7uzt58+Zl6dKlsRSpiIiIiIgkZg8ePOCzzz7D29ub/v374+fnx5w5c2yvZ8qUKUEm6IsWwbx5Rs/5ypXg5WV2RAmbqT3pq1atonfv3syaNYty5coxd+5catasycmTJ8mWLdtTx8+ePZshQ4Ywf/58SpYsyf79++nYsSOpUqWibt26JtyBiIiIiIgkdPfv32fWrFlMnDiRa9euAcZ650OHDuWDDz4wObqYdfAgdO1qbI8ZA9WrmxtPYmBqkj558mTat29Ph/8qDkydOpWtW7cye/Zsxo0b99Txy5Yto3PnzjRt2hSAHDly8Ouvv/Lpp58qSRcRERERkWgXFBRE/vz5uXjxIgA5c+Zk6NChtGzZEmdnZ5Oji1k3bhjz0IOCoF49GDLE7IgSB9OS9ODgYA4ePMjgwYMj7a9evTp79+595nuCgoJwe2Lyg7u7O/v37yckJOSZf0mCgoIICgqyPb979y4AISEhhISEvO5txKqIeONb3BK71E7EHmonYi+1FbGH2onYIz61k4cPH9rWMXdwcKBevXps27aNwYMH07x5c5ycjDQqPtzLqwoLg/ffd+SffxzIlcvKggWhhIUZ+2NSfGonURGV+7FYrVZrDMbyXJcvXyZLlizs2bOHsmXL2vaPHTuWJUuWcPr06afe89FHH/HFF1+wefNmihUrxsGDB6lduzZXr17l8uXLZMqU6an3jBo1Cl9f36f2r1ixAg8Pj+i9KRERERERibcCAwP59ttv2bhxI8OHDydPnjyAkbS7uLjg6OhocoSx58sv87F6dV5cXUP59NNdeHndMzukeC0wMJDmzZtz584dkidP/sJjTa/ubnmibr/Van1qX4Thw4dz5coVSpcujdVqJUOGDLRp04YJEyY89y/MkCFD6Nu3r+353bt38fT0pHr16i/95cQ1ISEhbN++nWrVqiX4oTXy6tROxB5qJ2IvtRWxh9qJ2CMut5M7d+4wc+ZMpk2bxq1btwA4e/YsvXv3Njcwk2zaZGH1aiNVnD8fmjWrEGvXjsvt5HVEjOi2h2lJetq0aXF0dOTKlSuR9l+9etW2hMGT3N3dWbRoEXPnzuXff/8lU6ZMzJs3j2TJkpE2bdpnvsfV1fWZ6xM6OzvH2z/0+By7xB61E7GH2onYS21F7KF2IvaIS+3k9u3bfP7550yZMoXbt28DkC9fPoYPH07Tpk0TVc95hLNnoW1bY7tnT2jVypyUMS61k+gQlXsxLUl3cXGhePHibN++nffee8+2f/v27dSvX/+F73V2diZr1qwAfPXVV9SpUwcHB9NXkxMRERERkXjCarVSsWJFjh8/DkCBAgUYPnw4jRs3TpTJOcCDB+DjA3fvQrlyMHGi2RElTqYOd+/bty+tWrWiRIkSlClThnnz5nH+/Hm6dOkCGEPVL126ZFsL/cyZM+zfv5+33nqLW7duMXnyZE6cOMGSJUvMvA0REREREYkHbt26RbJkyXBycsJisdClSxdmzZrFiBEjaNSoUaLu+LNaoVMnOHECMmaE1ashAXVkxyumtsKmTZsydepURo8eTdGiRdm1axdbtmwhe/bsAAQEBHD+/Hnb8WFhYUyaNIkiRYpQrVo1Hj16xN69e/Hy8jLpDkREREREJK67ceMGw4YNI3v27Hz11Ve2/Z06deLYsWM0adIkUSfoANOnw4oV4ORkJOjPqMktscT0wnFdu3ala9euz3xt8eLFkZ7nz5+fw4cPx0JUIiIiIiIS312/fp3Jkyczffp07t+/D8D69etp2bIlgG0ptcTul1+gXz9je+JEKF/e3HgSO7VKERERERFJUK5fv86kSZOYMWOGLTkvUqQII0aMoEGDBuYGF8cEBEDjxhAaCs2aGcXixFxK0kVEREREJEFp2bIlW7duBaBo0aKMHDmSevXqJfoh7U8KCYEmTeDKFShUCBYsgOeshi2xSEm6iIiIiIjEa1evXsXFxYWUKVMCMGDAAK5evcqoUaOoW7cuFmWezzRwoDHUPXlyWLcOkiQxOyIBkwvHiYiIiIiIvKp///2X/v374+3tzcTH1gt7++23OXjwIPXq1VOC/hwrV8LUqcb20qWQO7ep4chj1JMuIiIiIiLxypUrV/jss8+YPXs2Dx8+BODXX3/FarVisViUmL/EiRPQoYOx/dFHUL++ufFIZOpJFxERERGReCEgIIA+ffrg7e3N5MmTefjwIaVKleLbb79l+/btSs7tcOcO+PhAYCBUqwajR5sdkTxJPekiIiIiIhIvjB49mjlz5gBQunRpRo4cSY0aNZSc2yk8HFq3hrNnIVs2Y110R0ezo5InKUkXEREREZE46dKlS4SEhODl5QXAoEGDOHXqFB999BHVqlVTch5F48fDN9+AqyusXQtp05odkTyLhruLiIiIiEiccuHCBbp160aOHDno37+/bb+Xlxc7d+6kevXqStCjaNs2GDbM2J45E0qUMDceeT71pIuIiIiISJxw4cIFxo0bx8KFCwkODgbg2rVrBAUF4erqanJ08dc//0Dz5mC1GgXj2rc3OyJ5EfWki4iIiIiIqc6fP8+HH35Izpw5mT17NsHBwVSqVIkff/yRnTt3KkF/DY8eQcOGcOOG0Xs+fbrZEcnLqCddRERERERMtXr1altBuMqVKzNy5EgqV65sblAJRI8ecPAgpEkDa9aAm5vZEcnLKEkXEREREZFY5e/vz7Vr1yhZsiQAXbp0Yd++ffTs2ZOKFSuaHF3CsWCB8XBwgJUrIXt2syMSeyhJFxERERGRWHHlyhU6d+7MsmXLyJ8/P0eOHMHBwYEkSZKwZs0as8NLUH7/Hbp1M7Y//thYE13iByXpIiIiIiISo86dO8eYMWNYtmwZ4eHhAGTMmJFbt26RJk0ak6NLeK5fh0aNIDgY6teHQYPMjkiiQoXjREREREQkRvz999+0bduWvHnzsmTJEsLDw6levTp79+5l27ZtStBjQFgYvP8+nD8PuXPDkiXGcHeJP9STLiIiIiIiMeLUqVMsXrwYgBo1avD222/Tp08fnJ2dzQ0sARsxAn74ATw8YN06SJHC7IgkqvSdioiIiIiIRIszZ86wceNG2/NatWrRu3dvfv31VzZt2kTevHlNjC7h++YbGDvW2F64EAoVMjceeTXqSRcRERERkdfy559/8vHHH7Ny5UpSpEiBv78/yZMnx2KxMGXKFABCQkJMjjJhO3MGPvjA2O7dG5o1MzUceQ3qSRcRERERkVdy6tQpmjdvToECBfjyyy8JDw+nfPny3Llzx+zQEpX798HHB+7ehQoVYMIEsyOS16EkXUREREREosTPz4/333+fggULsnLlSqxWK/Xr1+fgwYNs3LgRT09Ps0NMNKxW6NAB/vgDMmWCr78GTfmP3zTcXUREREREoiQ4OJivv/4aq9XKe++9x4gRIyhatKjZYSVK06bBqlXg5ASrV0PGjGZHJK9LSbqIiIiIiLzQ8ePH+fnnn+nevTsAefPmZerUqVSsWJEiRYqYHF3itXs39O9vbE+eDOXKmRuPRA8l6SIiIiIi8kxHjx5l9OjRrFu3DgcHB6pXr06ePHkA6NGjh8nRJW4BAdCkibEuevPm8N/3J5IAKEkXEREREZFIjhw5wujRo1m/fj0AFouFhg0b4uSk9CEuCA6Gxo3hyhV44w2YNw8sFrOjkuiiv2UiIiIiIgLAxYsX6d69O9988w1gJOdNmjRh+PDhFCxY0OToJMKAAbBnD6RIAevWQZIkZkck0UlJuoiIiIiIAJA8eXJ27dqFxWKhWbNmDBs2jAIFCpgdljxmxQr4/HNje9kyyJXL3Hgk+ilJFxERERFJpA4cOMDKlSuZOHEiFouF5MmT88UXX5AnTx7y589vdnjyhGPHjOXWAIYNg7p1zY1HYoaSdBERERGRRGb//v34+vqyZcsWAKpWrUqtWrUAqF+/vpmhyXPcvg0+PvDwIdSoAaNGmR2RxBQl6SIiIiIiicRvv/2Gr68v3333HQCOjo60aNGCvHnzmhyZvEh4OHzwAZw7B9mzw5dfgqOj2VFJTFGSLiIiIiKSwN24cYMWLVqwdetWwEjOW7VqxdChQ8mlSc1x3rhxsGkTuLoaheLSpDE7IolJStJFRERERBK4VKlScenSJRwdHWndujUfffQROXPmNDssscPWrTB8uLE9ezYUK2ZuPBLzHMwOQEREREREotfu3btp0qQJgYGBADg4OLBw4ULOnDnDwoULlaDHE/7+0Lw5WK3QqRO0bWt2RBIblKSLiIiIiCQQu3btomrVqlSsWJHVq1czZ84c22ulSpUiR44cJkYnUfHwITRsCDdvQsmS/192TRI+DXcXEREREYnndu7cia+vLzt37gTA2dmZtm3b4uPjY25g8kqsVujWDQ4dgrRpYc0aYz66JA5K0kVERERE4qng4GBq1KgRKTlv3749Q4YMIVu2bOYGJ69s/nz44gtwcICvvgL9USYuStJFREREROIpFxcX0qRJg4uLCx06dGDw4MF4enqaHZa8hv37oUcPY3vsWKha1dx4JPZpTrqIiIiISDxgtVrZvn07VapUwd/f37b/s88+49y5c8ycOVMJejx37Ro0agTBwfDeezBwoNkRiRmUpIuIiIjpwsJg505YudL4GRZmdkQicYfVamXbtm2UK1eO6tWrs3PnTsaPH2973dvbm6xZs5oYoUSH0FB4/324cAHy5IHFi8FiMTsqMYOGu4uIiIip1q2DXr3g4sX/78uaFaZNA9W8ksTMarWydetWfH19+fXXXwFwdXWlc+fODBo0yOToJLoNHw47dkCSJMbnYvLkZkckZlGSLiIiIqZZt84Y2mm1Rt5/6ZKxf80aJeqSOFmtVmrUqMH27dsBcHNzo0uXLgwcOJBMmTKZHJ1Et/XrIWJwxKJFULCgufGIuTTcXUREREwRFmb0oD+ZoMP/9/XuraHvknhYrVas/zV+i8VCiRIlcHd3p0+fPvj5+TFlyhQl6AnQ6dPQurWx3bcvNGlibjxiPiXpIiIiYorduyMPcX+S1WrMzdy9O/ZiEjGD1Wpl8+bNlCpVip9++sm2f+DAgfj5+TF58mQyZsxoYoQSU+7fN0YL3bsHFSv+vzddEjcl6SIiImKKgAD7jrt0KWbjEDGL1Wpl48aNlCxZkrp163LgwAEmTJhgez1lypRkyJDBxAglJlmt0L49nDwJmTPD11+Ds7PZUUlcoCRdRERETGHvqN0hQ2D2bHjwIGbjEYktVquVb775huLFi1O/fn0OHjxIkiRJGDRoEMuWLTM7PIklU6f+PzFfvRr0fYxEUJIuIiIipqhQwaji/qIlhiwWY8h7167GsYMGwfnzsRejSExo2rQpDRo04PDhwyRNmpTBgwfj7+/P+PHjSZcundnhSSz4+WcYMMDYnjIFypY1Nx6JW5Ski4iIiCkcHY1l1p7FYjEey5bB559Dzpxw+zZMmAA5ckDTprBv37OLzonENeHh4YSGhtqe161bl2TJkvHRRx/h7+/PuHHjSJs2rYkRSmy6dMkoDhcWBi1bGl9CijxOSbqIiIiYxsfHWGYtSZLI+7NmNfa3aAE9ehjVjzduhLffNv5j+/XXRs9T6dKwciWEhJgTv8iLhIeHs3r1aooUKcL8+fNt+99//338/f355JNPSJMmjYkRSmwLDobGjeHqVShcGObOffFoIkmclKSLiIiIqXx8IHduY7t3b/jpJ/Dzi7w+uqMj1K0LO3bA0aPQrh24usL+/dC8OXh7w7hxcOOGKbcgEklYWBirVq2icOHCNGnShBMnTjBz5kzb8mpOTk6kTp3a5CjFDP36GaOAUqSAdevAw8PsiCQuinKS/kBVW0RERCQaPXoEf/xhbPfqBZUrG0n58xQuDAsXGnPTR4+GjBmN4aMffWT0wHfubFRLFoltYWFhrFy5kjfeeINmzZrxxx9/kCJFCkaOHMnu3buxqMs0UVu+HGbM+P92zpzmxiNxV5ST9AwZMtCuXTt++eWXmIhHREREEpnjx43h6mnSQPbs9r8vfXoYPhz8/WHpUnjzTSPhnzcPChaEGjVgyxYID4+x0EUi6d69O82bN+fUqVOkTJmSUaNG4e/vz6hRo0iVKpXZ4YmJjh6FTp2M7REjoE4dc+ORuC3KSfrKlSu5c+cOVatWJU+ePIwfP57Lly/HRGwiIiKSCBw8aPwsXvzV5ma6ukKrVsZ5du0yhsk7OMC2bVC7NuTPD7NmaQk3iX5hYWHcv3/f9rxt27akSpWK0aNH4+/vz8iRI0mZMqV5AUqccOuW8bn08CG8+66RpIu8SJST9Lp167J27VouX77Mhx9+yMqVK8mePTt16tRh3bp1kSpXioiIiLzMgQPGzxIlXu88FouxrNvatXDunDH3M3lyOHMGunXTEm4SfUJDQ1m2bBkFChRg6NChtv2lSpXi4sWLDB8+nBQpUpgYocQV4eHwwQfw99/g5QVffvni6Twi8BqF49KkSUOfPn04evQokydP5ocffqBRo0ZkzpyZESNGEBgYGJ1xioiISAIV0ZP+ukn647y8YOJEuHgRpk+HXLkiL+HWpAns3asl3CRqQkNDWbJkCQUKFOCDDz7gzJkzrF27lqCgINsxHqoEJo/55BPYvBnc3IxCcaoXKPZ45ST9ypUrTJgwgfz58zN48GAaNWrEjh07mDJlCuvXr6dBgwbRGKaIiIgkRI8ewYkTxnbx4tF//mTJoHt3Ywm3TZugalVjCbfVq6FcOXjrLVixwlgWSeR5QkNDWbx4Mfny5aNNmzacPXuWtGnTMn78eE6dOoWrq6vZIUoc9N13MHKksT17tlE3Q8QeTlF9w7p16/jiiy/YunUrBQoUoFu3brRs2TLSfJuiRYvyplqhiIiIvMSxYxAaCunSgadnzF3HwcEo1FSnjlGobto0o7ry778ba7EPGGAMie/UCdKmjbk4JH4aO3YsI//LttKmTcuAAQPo2rUrSZMmNTkyiav8/IzPFqsVunSBNm3Mjkjikyj3pLdt25bMmTOzZ88ejhw5Qvfu3Z8qiJEjR45I83NEREREniViPvqrFo17FW+8AQsWwIULMGaMsYTb5cswdKjxRUGnTv9fEk4Sp+DgYAICAmzPO3XqRPbs2fnss8/w9/dn4MCBStDluR4+hIYNjYJxb70FU6eaHZHEN1FO0gMCApg7dy4lS5Z87jHu7u62bxtFREREnie6isa9inTpYNgw+OcfWLYMihUzht/Pnw+FCkH16lrCLbEJDg5m3rx55MmThzaPdX1mzJiRc+fO0b9/f5IkSWJegBLnWa3QtSscPmx8xqxZY6xAIRIVUU7SkyVLxtWrV5/af+PGDRxVqlBERESi4PHl18zi4gItWxpfGOzebfSAOTjA9u2Rl3B7bKUtSWCCgoKYM2cOuXPnpnPnzvzzzz8cPXqUa9eu2Y7R/3PFHvPmweLFxmfIV18Zq0qIRFWUk3Trc8qgBgUF4eLi8toBiYiISOLw8OH/h5Wb0ZP+JIsFypc3er4ilnBLkeL/S7h5esLAgVrCLSEJCgpi9uzZ5M6dmw8//JDz58+TMWNGpkyZwt9//026dOnMDlHikd9+gx49jO3x4+Htt82NR+IvuwvHff755wBYLBYWLFgQaR5OWFgYu3btIl++fFEOYNasWXz22WcEBARQsGBBpk6dSoUKFZ57/JdffsmECRM4e/YsKVKk4N1332XixImkSZMmytcWERER8xw9alRaT58esmQxO5rIIpZwGzkSliwxCs399Rd89hlMngzvvQe9e0PZsrE3l16i38qVK+natSsAmTJlYvDgwXTs2BF3d3eTI5P45upVaNQIQkLAxwf69zc7IonP7E7Sp0yZAhg96XPmzIk05MfFxQUvLy/mzJkTpYuvWrWK3r17M2vWLMqVK8fcuXOpWbMmJ0+eJFu2bE8d/8svv/DBBx8wZcoU6taty6VLl+jSpQsdOnRg/fr1Ubq2iIiImOvx+ehxNdGNWMKta1djfvq0afDDD0Zv+5o1Ruy9e0PjxsaweYnbHj16hJ+fH/nz5wegefPmzJ8/n/fff58OHTrg5uZmcoQSH4WGQrNmcPEi5MsHX3wRdz/TJH6wO0n38/MDoEqVKqxbt45UqVK99sUnT55M+/bt6dChAwBTp05l69atzJ49m3Hjxj11/K+//oqXlxc9e/YEwNvbm86dOzNhwoTXjkVERERiV8R89Lgw1P1lnlzC7fPPjWJzBw4Y89kjlnDr3FlLuMVFDx8+ZP78+Xz66ae4ubnx559/4uzsjIuLC3v27DE7PInnhg6Fn36CpElh3TpIntzsiCS+i/I66T/99FO0XDg4OJiDBw8yePDgSPurV6/O3r17n/mesmXLMnToULZs2ULNmjW5evUqa9asoXbt2s+9TlBQEEFBQbbnd+/eBSAkJISQkJBouJPYExFvfItbYpfaidhD7UTsFZNt5fffnQALRYqEEhLy7Jo3cVG+fEYhOV9fWLDAgTlzHAgIsDBsGHz8sZXmza107x5GoUJmRxp74upnysOHD1mwYAETJ060LamWNWtWTp8+Td68eU2OLvGJq+3kdaxbZ2HCBCOlmjcvlFy5rCSg2zNFQmwnELX7sVifVwnuMX379mXMmDEkSZKEvn37vvDYyZMn23Xhy5cvkyVLFvbs2UPZsmVt+8eOHcuSJUs4ffr0M9+3Zs0a2rZty6NHjwgNDaVevXqsWbMGZ2fnZx4/atQofH19n9q/YsUKPDw87IpVREREoldQkCPvv1+b8HALixZtJXXqR2aH9MpCQizs3ZuFjRtzcu5cStv+IkWuUrfu3xQr9i8OUS7VK68jKCiIrVu3sn79em7dugVA2rRpadSoEVWrVn3u/xtFouLixaT071+JR4+caNDgLG3anDQ7JInDAgMDad68OXfu3CH5S4Zb2NWTfvjwYVvmf/jw4eceZ3mFyRdPvsdqtT73PCdPnqRnz56MGDGCGjVqEBAQwIABA+jSpQsLFy585nuGDBkS6YuFu3fv4unpSfXq1V/6y4lrQkJC2L59O9WqVdM/LvJcaidiD7UTsVdMtZV9+yyEh1vImNFKy5bxvwRy/fpGNed9+0L5/HMHNmywcPRoeo4eTU+uXFZ69AinVatwHqu7m6DEtc+UX375hUWLFgGQPXt2Bg0axAcffKCViEwW19rJ67h3D8qVc+LRIwuVKoWzYoUXTk5eZoeVICSkdvK4iBHd9rArSX98iHt0DXdPmzYtjo6OXLlyJdL+q1evkiFDhme+Z9y4cZQrV44BAwYAULhwYZIkSUKFChX4+OOPyZQp01PvcXV1xdXV9an9zs7O8fYPPT7HLrFH7UTsoXYi9orutnLkiPGzRAlLgmqDlSoZj3/+gRkzYP58+OsvC716OTJihCMdOxqF6LJnNzvSmGHWZ8qDBw84ePAgFStWBIwaSq1bt6Z8+fJKzuOg+P5vj9Vq1J/4809jZYpVqxxwd9dwmegW39vJk6JyL6a1JhcXF4oXL8727dsj7d++fXuk4e+PCwwMxOGJ8WIRVebtGLUvIiIicURE0bjixc2NI6Zkz24s13bxopGs584Nd+4Yy7rlyGFUg9+zx/jP/uPCwmDnTli50vgZFmZG9PHH/fv3mTBhAt7e3tSqVYtr167ZXlu8eDEdOnRQgi7RbvJkY3UHZ2dYvRqe078o8srs6kn38fGx+4Tr1q2z+9i+ffvSqlUrSpQoQZkyZZg3bx7nz5+nS5cugDFU/dKlSyxduhSAunXr0rFjR2bPnm0b7t67d29KlSpF5syZ7b6uiIiImOvx5dcSsqRJjarvH34I330HU6c+fwm3zZuhVy8jsY+QNaux7FsU/iuWKNy7d4+ZM2cyadIkrl+/DkDOnDnx9/cnXbp0JkcnCdnOnTBokLE9dSqUKWNmNJJQ2ZWkp0iRIkYu3rRpU27cuMHo0aMJCAigUKFCbNmyhez/jQELCAjg/PnztuPbtGnDvXv3mDFjBv369SNlypS8/fbbfPrppzESn4iIiES/+/eNYaKQcHvSn+TgALVrG48TJ4zEe/ny/y/h1r073L799PsuXYJGjYyEXom6kZxPnz6dSZMmcfPmTQBy5crFsGHDaNGiBU5OUV64SMRuFy9CkybGCJcPPjC+fBOJCXZ9kn3xxRcxFkDXrl3p2rXrM19bvHjxU/t69OhBjx49YiweERERiVlHjkB4OGTODM8oJ5PgFSpkzFUfNw7mzYPp0+GJEj02VitYLEZve/368N8sv0Tr1q1bjBo1ipCQEPLkycOwYcN4//33lZxLjAsONka8XLsGRYrA7NnG302RmKAKByIiIhKrIuajJ/Sh7i+TNi189BH8N6vvuaxWuHABdu+Onbjikjt37vDVV1/ZnmfLlo1Ro0axfPlyTp48SatWrZSgS6zo0wd+/RVSpoR160ArOUtMsutTrVixYuzYsYNUqVLx5ptvvnCptUOHDkVbcCIiIpLwRMxHTyxD3V/mvynVLzVtmpEgFCmS8Hvwbt++zbRp05g6dSq3b98mb968vPnmmwB89NFHJkcnic3SpTBrlvH37ssvjeKPIjHJriS9fv36tmXMGjRoEJPxiIiISAKXWIrG2cveIf8bNhiPHDmgYUPjUapUwkrYb9++zdSpU5k6dSp37twBIH/+/Ny7d8/kyCSxOnLEWG4NYORIqFXL1HAkkbArSR85cuQzt0VERESi4t49OH3a2FZPuqFCBaOK+6VLTy/JBkYSniqVcdzWrfD338bybp99ZrzPx8dI2MuVi79z1h88eMCECROYOnUqd+/eBaBAgQKMGDGCRo0a2ZbcFYlNt24Zf78ePTKS8+HDzY5IEotXnpN+4MABli1bxvLlyzkYMblMRERE5AUOHzYS0axZtbZwBEdHYyg7PN0rHvF8/nyjF/3aNfj6a2ja1Fje7eJF+PxzqFTJKMTXpQts3w4hIbF6C6/NwcGBefPmcffuXQoWLMjXX3/N8ePHadq0qRJ0MUV4uLHygp8feHvDsmXGKg0isSHKTe3ixYtUqFCBUqVK0atXL3r27EnJkiUpX748Fy5ciIkYRUREJIGI+F5fveiR+fgYy6xlyRJ5f9askZdfS5rUqDD91VdGwv7NN8ZSUClTwtWrMHcuVK9ufAHStq2x9vqjR7F+Oy9148YNJk2aRFhYGADu7u5MmTKF1atXc+zYMRo3boyDMiIx0ZgxsGULuLkZheJSpzY7IklMovzp165dO0JCQjh16hQ3b97k5s2bnDp1CqvVSvv27WMiRhEREUkgNB/9+Xx8wN8ffvoJVqwwfvr5PX99dDc3qFcPliyBf/+F77+Hjh0hXTpjmO7ixVC3LqRPD82bw9q18OBBbN7R065fv86QIUPw8vKif//+rFmzxvZas2bNaNSokZJzMd2WLeDra2zPnQtFi5oajiRCUV6zYvfu3ezdu5e8efPa9uXNm5fp06dTrly5aA1OREREEhb1pL+YoyNUrhz197m4QI0axmP2bGO5trVrjR7Ay5dh5Urj4e4ONWsac9jr1IHkyaP9Fp7p2rVrTJo0iRkzZvDgv28KihYtStq0aWMnABE7/f03tGhhTMvp2tUYqSIS26L8VWW2bNkIecZEp9DQULI8OUZLRERE5D9376poXGyISPSnTzfWV9+7F/r1Ay8vePjQSNxbtDB63GvXhkWL4MaNmIklODiYQYMG4e3tzaeffsqDBw8oVqwY33zzDYcOHaJq1aoxc2GRVxAYaIxcuX0bSpeGKVPMjkgSqygn6RMmTKBHjx4cOHAA638lSA8cOECvXr2YOHFitAcoIiIiCcPhw8bPbNmMIdgS8xwcoEwZmDjR6CE8eBA++gjy5oXgYGNYb/v2xhz2d94xeuGvXIm+6zs7O7Nr1y4ePHhA8eLF2bRpEwcOHKBevXpYEtLacRLvWa3w4Ydw9Kjx+bR6tTFCRcQMdg13T5UqVaQP0gcPHvDWW2/h5GS8PTQ0FCcnJ9q1a6d11EVEROSZIuajqxfdHBYLFCtmPD75BE6eNIbEr11rJCY7dhiPbt2M5dwaNjR6FbNls/8aV65cYcaMGQwZMoSUKVNisViYNGkSt27dolatWkrMJc6aMweWLjVGoqxaZRRtFDGLXUn61KlTYzgMERERSehUNC5uKVDAeAwfDn/9ZQyDX7sW9u+HX34xHn36QMmSRsLesCHkyvXscwUEBLBw4UKaNWvGo0eP8PDwYOTIkQCULVs2Fu9KJOr27YNevYzt8eNfrS6ESHSyK0lv3bp1TMchIiIiCZyKxsVduXLBwIHG48KF/yfsv/wCv/9uPAYPhsKF/5+wFygAAQGX+fTTT5k3bx6P/lvrrXTp0pQvX97kOxKxz7//QqNGEBJi/OzXz+yIRF6huvvjHj58+FQRueSxVSZURERE4o07d+DsWWNbSXrc5ulp9Cr26mXMT9+wwUjYf/oJjh0zHiNHWkmVqj93784kLCwIgHz58jFp0iRq1qypYe0SL4SGQrNmxgoI+fMbRRTVdCUuiHLhuAcPHtC9e3fSp09P0qRJSZUqVaSHiIiIyJMOHTJ+Zs8OWnUr/siYEbp0ge3bjR7HRYuMivAuLhZu3br5X4JejowZt5Enz0aSJauO1aosR+KHIUNg505ImtQYPZIsmdkRiRiinKQPHDiQH3/8kVmzZuHq6sqCBQvw9fUlc+bMLF26NCZiFBERkXhO89HjtwsXLjBiRDfeeuskmzfD1aswZcoIypf/ATe33Vy5Uo2NG3NTsaIT2bJBjx5G8hMWZnbkIs+2Zo2x6gHA4sWQL5+p4YhEEuUkfdOmTcyaNYtGjRrh5OREhQoVGDZsGGPHjuXLL7+MiRhFREQknouYj64kPX45f/48H374ITlz5mTWrFmMGTMGgBQpoHdvb3bvrsr16xa++iqUChUukiyZlUuXYMYMqFIFMmWCTp1g61Zjzq9IXHDqFLRta2wPHGjUWBCJS6KcpN+8eRNvb2/AmH9+8+ZNAMqXL8+uXbuiNzoRERFJELT8Wvzyzz//0LlzZ3LlysWcOXMICQmhUqVKdO7c+aljkyQBHx8r/fod5NKlUDZtgjZtIFUquHYN5s+Hd9811p5u3Ro2boT/asyJxLq7d+G99+D+feOLpE8+MTsikadFOUnPkSMH/v7+ABQoUICvv/4aMHrYU6ZMGZ2xiYiISAJw6xacO2dsK0mP+wYPHkyuXLmYN28eISEhVKlShZ07d7Jz504qv2RtKjc3qFMHvvjCmMO+bRt07mwk6LdvG+tQ168P6dIZBbtWrzaSpWcJCzOGzK9cqaHzEj2sVmjXDk6fNtZB/+orcHqtMtoiMSPKSXrbtm05evQoAEOGDLHNTe/Tpw8DBgyI9gBFREQkfosoGuftDalTmxuLvFzKlCkJDQ3lnXfeYdeuXfz4449UqlQpyudxdoZq1WDOHKN69s8/Q8+eRnJ0/z6sWgVNmhgJ+3vvwfLlRiIPRhEvLy+jp7N5c+Onl5exX+RVTZxorFTg7GzMSU+f3uyIRJ4tyt8d9enTx7ZdpUoVTp06xcGDB8mZMydFihSJ1uBEREQk/lPRuLjr3LlzfPLJJzRo0IB69eoB0K1bNypUqEC5cuWi7TqOjlCxovGYOtVYd33tWuNx7pyxzNuGDUbyVKgQHD789DkuXTLWsV6zBnx8oi00SSR+/BEGDza2P/8c3nrL3HhEXuS1B3hkz56d7NmzR0csIiIikgBFFI3TUPe446+//uLjjz9m+fLlhIWFceTIEerWrYvFYiFZsmTRmqA/yWKBUqWMx/jxxrrrEQn7yZPPTtDBGKpssUDv3saQeUfHGAtREpgLF4zpFeHhRr2EZ5RWEIlTojzcHWDHjh3UqVOHnDlzkitXLurUqcMPP/wQ3bGJiIhIAqCe9Ljj7NmztG7dmrx587JkyRLCwsKoWbMms2bNwmKJ/fXNLRYoUgRGj4Y//oAlS158vNVqJFy7d8dOfBL/BQVB48ZGEcM334RZs4x2JxKXRTlJnzFjBu+++y7JkiWjV69e9OzZk+TJk1OrVi1mzJgREzGKiIhIPHXzJvj5GdvFipkbS2I3ZswY8uXLx9KlSwkPD6dWrVr89ttvbNmyhdKlS5sdHmAMd7dHQEDMxiEJR+/e8NtvxmoDa9eCu7vZEYm8XJSHu48bN44pU6bQvXt3276ePXtSrlw5Pvnkk0j7RUREJHGLGOqeM6fxn2QxzxtvvEF4eDh16tRhxIgRlCxZ0uyQnpIpk33HrVkDNWuCFhaSF1m82ChcaLHAl18axStF4oMo96TfvXuXd99996n91atX5+7du9ESlIiIiCQMEUm6hrrHrlOnTtG8eXMmTpxo21e/fn2OHDnCpk2b4mSCDlChglH9/WXDkdetgzx5YNEiY56xyJMOH4YPPzS2R40yvtQRiS+inKTXq1eP9evXP7X/m2++oW7dutESlIiIiCQMEfPRVTQudvzxxx80a9aMggULsnLlSiZMmEBQUBAAFoslzq/E4+gI06YZ208m6haL8RgxAvLlM+YYt28PZcoY1eJFIty8aawA8OgR1K4Nw4aZHZFI1Ng13P3zzz+3befPn59PPvmEnTt3UqZMGQB+/fVX9uzZQ79+/WImShEREYmX1JMeO06cOMGYMWNYvXo1VqsVgAYNGjBixAhcXV1Nji5qfHyM4ey9esHFi//fnzWrsXybjw8MHQrTp4OvL+zfbyyn1a4djBtnrLsuiVd4OLRoAf7+kCMHLFsGDq9UKlvEPHYl6VOmTIn0PFWqVJw8eZKTJ0/a9qVMmZJFixYxTF9ViYiICHD9uvEfZVDRuJg0bdo0evfubXvu4+PD8OHDKVq0qGkxvS4fH2OZtd27jSJxmTIZQ+Ejll1zcYF+/aB5cxg0yEjEFi40CoONHm0Mc3Z67YWGJT7y9YXvvzcKxK1bp1oYEj/Z9fHlF1GWVURERMROEb3ouXNDihTmxpLQhIWF4fhfxvrOO+/g4OBgS84LFy5scnTRw9ERKld+8TGZMsHSpca61927w5Ej0LMnzJ8PM2ZAxYqxEanEFZs3G1/SAMybZyzvJxIfvdbgD6vVahtSJSIiIvK4iCRd89Gjz5EjR/Dx8aFTp062fQULFsTf35/Vq1cnmAQ9qsqVM+ofzJ4NqVPD8eNQqZLR037pktnRSWw4dw5atTK2u3eHli3NjUfkdbxSkr506VLeeOMN3N3dcXd3p3Dhwixbtiy6YxMREZF4LKJonOajv77Dhw/z3nvv8eabb7J+/XqWLVvGtWvXbK97enqaGF3c4OgIXbrAmTPGT4sFVq6EvHlh/Hj4r36eJECBgcYUidu3jUKCkyaZHZHI64lykj558mQ+/PBDatWqxddff82qVat499136dKly1Nz10VERCTxUk/66zt06BD169enWLFibNiwAYvFwvvvv8+RI0dIpwppz5QmjdGjfuCAkbA9eABDhsAbbxhzlSVhsVqN6Q7HjkH69LB6tVGzQCQ+i3JJjenTpzN79mw++OAD27769etTsGBBRo0aRZ8+faI1QBEREYl/rl2D8+eNbRWNezVffvklLf8bs+vg4MD777/PsGHDyJcvn8mRxQ/FisEvv8Dy5TBwIJw9a6yVXa8eTJliVP6W+G/WLOPP2NERvv4asmQxOyKR1xflnvSAgADKli371P6yZcsSEBAQLUGJiIhI/BbRi543LyRPbm4s8UlgYKBtu1atWqROnZpWrVpx8uRJli9frgQ9ihwc4IMPjCHwffsaFd83boQCBYz11h/7dUs8tHcvRCxsMGGCUYdAJCGIcpKeK1cuvv7666f2r1q1ity5c0dLUCIiIhK/RcxH11B3+/z666/UrFmTd955x1aUN1WqVPj5+bF06VLy5s1rcoTxW/LkxjzlY8fgnXeM+eljxkD+/Maa7KqDHP9cuQKNG0NoKDRpAhrMKwlJlIe7+/r60rRpU3bt2kW5cuWwWCz88ssv7Nix45nJu4iIiCQ+Khpnn3379uHr68vWrVsBcHR05OTJkxQsWBCA5BqGEK3y54dt24z1s/v2NaZkNG4MVavC558bPewS94WEQNOmcPmy8We2cKFRKFAkoYhyT3rDhg3Zv38/adOmZcOGDaxbt460adOyf/9+3nvvvZiIUUREROIZFY17sT179lC9enXKli3L1q1bcXR0pG3btpw+fdqWoEvMsFigYUM4dQqGDwdXV9ixw1hTu18/uHvX7AjlZQYPhl27IFky4wuXpEnNjkgkekUpSQ8JCaFt27akTJmS5cuXc/DgQQ4dOsTy5ct58803YypGERERiUf+/RcuXjSSIf334Gk//PAD5cuXZ/v27Tg5OdG+fXvOnDnDokWLyJkzp9nhJRoeHjB6NJw8aRSTCw2FyZMhTx5YuhTCw82OUJ7l66+NPyeAJUuMuhciCU2UknRnZ2fWr18fU7GIiIhIAvB40bhkycyNJa64evWqbbtKlSq88cYbdOzYkTNnzrBgwQJyqNS4aXLkgG++gS1bIHdu40um1q2hfHk4dMjs6ORxf/wB7doZ24MGgQbxSkIV5eHu7733Hhs2bIiBUERERCQh0Hz0/9u5cydVqlShaNGiPHr0CDDmnR88eJB58+bh7e1tcoQSoWZNOH4cxo+HJElg3z6jDXfpAjdumB2d3L0LPj7GuvdVq8LHH5sdkUjMiXLhuFy5cjFmzBj27t1L8eLFSZIkSaTXe/bsGW3BiYiISPyT2OejW61Wdu7cia+vLz///DNgjEbct28fVapUsT2XuMfV1eihbdkSBgyAlSth7lxYvdpICjt1MtbjlthltUKbNsZSep6exp+LU5SzGJH4I8rNe8GCBaRMmZKDBw9yMOJf4f9YLBYl6SIiIolcYu1Jt1qt/PTTT4waNYrdu3cD4OLiQocOHRg8eDCenp4mRyj2ypIFVqyAzp2hRw+jh71rV5g3D2bMgHLlzI4wcZkwAdavBxcXY8m8dOnMjkgkZkU5Sffz84uJOERERCQBCAgwlkVycICiRc2OJnadPn2aqlWrAkZy3rFjRwYPHkzWrFlNjkxeVaVKxrz0OXOMSvBHjhhz1Vu1gk8/hUyZzI4w4duxAz76yNiePh1KlTI3HpHYEKU56b/99htDhw5l0KBBbNu2LaZiEhERkXgqYpBdvnwJf1kkq9XKn3/+aXueL18+mjRpQo8ePfj777+ZMWOGEvQEwMkJunc3hlp36GCsWrBsmVEYceJECA42O8KE6/x5aNbMqLTfrh107Gh2RCKxw+4kff369ZQrV45p06Yxd+5catasydSpU2MwNBEREYlvEsNQd6vVyvfff0+ZMmUoUqQIFy5csL321Vdf8fnnn5MlSxYTI5SYkC4dzJ8Pv/1m9Obeu2fMWy9SBLZvNzu6hCcoCBo1guvXoVgxY5qBxWJ2VCKxw+4kfezYsbRp04bbt29z+/ZtfH19+VhlFUVEROQxCblonNVqZcuWLZQuXZqaNWvy22+/4eDgwP79+23HWJRFJHglSxqV3xctMhL3P/+E6tWhYUP45x+zo0s4evaE33+H1Klh7Vpwdzc7IpHYY3eSfvr0aQYOHIjTf6UUBwwYwO3bt7l+/XqMBSciIiLxS0LsSbdarXz77be89dZb1K5dm/379+Pu7k7fvn3x8/OjYcOGZocosczBAdq2NYbA9+xpVHxft86Y5jF6NDx8aHaE8duiRUaRPovFKODn5WV2RCKxy+4k/f79+6RMmdL23NXVFXd3d+7evRsTcYmIiEg8c/kyXLmS8IrG3bx5kyZNmvD777/j7u5Ov3798PPzY9KkSWTMmNHs8MREKVPCtGlw+DBUrgyPHsHIkVCgAHzzjbF0mETNoUNGJX0wvvCoUcPceETMEKXq7lu3biVFihS25+Hh4ezYsYMTJ07Y9tWrVy/6ohMREZF4I6IXvUAB8PAwN5bXYbVa+eWXX6hQoQIAadKkYeDAgTx48ID+/fuTPn16kyOUuOaNN+DHH+Hrr6F/f/D3hwYNjARz2jSjyJy83I0b4ONjzEevW/f/Vd1FEpsoJemtW7d+al/nzp1t2xaLhbCwsNePSkREROKdiPno8XWou9Vq5ZtvvmH06NEcPnyYXbt22RL1kSNHmhydxHUWCzRtCrVrw9ixMGkSbN1qJPB9+sCwYZAsmdlRxl1hYdCihTGvP1cuWLrUGJUjkhjZ3fTDw8Nf+lCCLiIiknhF9KTHt6Jx4eHhrF+/njfffJP33nuPw4cPkzRpUs6dO2d2aBIPJU1qJOknTkCtWhASAhMmGPPVV6zQEPjnGTXK+FLD3d2Y3//YLFuRREffT4mIiMhrs1rjX096eHg4a9eu5c0338THx4ejR4+SNGlSPvroI/z8/GjTpo3ZIUo8ljs3fPstbNoEOXMaNRtatIBKleDYMbOji1s2bYKIRaPmzzdGH4gkZkrSRURE5LVdugT//mtUuS5SxOxo7BMWFsaAAQM4duwYyZIlY+jQofj7+/PJJ5+QNm1as8OTBKJOHaNX/eOPjV7i3bvhzTehRw+4dcvs6Mz311/QqpWx3aOH8UWGSGKnJF1EREReW8RQ94IF4+56xuHh4axbt47g4GAAnJ2d+fjjjxk+fDj+/v58/PHHpEmTxuQoJSFyc4OhQ4011Rs3hvBwmDED8uQxeo4T64zRBw+MQnF37kC5cjBxotkRicQNStJFRETktUUMdY+L89HDwsL46quveOONN2jYsCFLly61vda8eXNGjx5N6tSpTYxQEots2YwK8Dt2GKsgXL8OnTpB6dLw229mRxe7rFbj3o8fh4wZjd+Li4vZUYnEDUrSRURE5LVF9KTHpfnoYWFhrFixgkKFCvH+++9z8uRJUqZMaetJFzHL22/DkSMwZQokT278/SldGtq1M6aNJAYzZhiF9BwdjQQ9c2azIxKJO5Ski4iIyGt5vGhcXOhJt1qtLF++nIIFC9KiRQv+/PNPUqVKxejRo/H396dr165mhyiCszP07g1nzkBEjcIvvjCGwE+bZlSFT6j27rXQt6+xPXEi/LfSoYj8x6510lOlSoXFYrHrhDdv3nytgERERCR+uXABrl0DJycoXNjsaMBisbB06VJOnz5N6tSp6du3Lz169CB58uRmhybylAwZjOS8UyejcNrBg0byPn8+TJ8OVaqYHWH0unXLlQ8/dCQ0FJo1g169zI5IJO6xK0mfOnVqDIchIiIi8VVEL3qhQuYUjQsNDeXLL7+kRo0aZMyYEYDRo0dTpUoVunfvTrJkyWI/KJEoKlPGmJe+cCF89BH88YcxLL5JE6O32dPT7AhfX0gIfPZZCQICLBQsaHwRYWc/oEiiYleS3rp16xgLYNasWXz22WcEBARQsGBBpk6dSoXnjHlp06YNS5YseWp/gQIF+OOPP2IsRhEREXm+iPnosT3UPSQkhOXLl/PJJ59w7tw5+vXrx8T/ykOXLl2a0qVLx25AIq/J0dHoUW/UCEaMgNmzjfnamzcb1eH79QNXV7OjfHVDhjhw8mRakie3sm6dhaRJzY5IJG56rTnpDx8+5O7du5EeUbFq1Sp69+7N0KFDOXz4MBUqVKBmzZqcP3/+mcdPmzaNgIAA2+PChQukTp2axo0bv85tiIiIyGuI6EmPraJxISEhLFq0iHz58tGuXTvOnTtH2rRpyZYtW+wEIBLDUqc2CqsdPAjly0NgoJGkFywI335rdnSv5quv4PPPHQFYtCiMPHlMDkgkDotykv7gwQO6d+9O+vTpSZo0KalSpYr0iIrJkyfTvn17OnToQP78+Zk6dSqenp7Mnj37mcenSJGCjBkz2h4HDhzg1q1btG3bNqq3ISIiItHAao3dnvSlS5eSN29e2rdvz99//026dOmYMGECfn5+9OzZM+YDEIlFRYvCrl2wfDlkygTnzkGdOsbjr7/Mjs5+f/wB7dsb2w0bnqFePau5AYnEcXYNd3/cwIED+emnn5g1axYffPABM2fO5NKlS8ydO5fx48fbfZ7g4GAOHjzI4MGDI+2vXr06e/futescCxcu5J133iF79uzPPSYoKIigoCDb84je/pCQEELiWdnMiHjjW9wSu9ROxB5qJ2Kvl7UVf3+4ccMZZ2cr+fOHxnhF6v379+Pn50f69Onp168fnTp1IkmSJC+MUWKePlNiVpMmULMmfPKJA9OnO/Dttxa2b7fSp084gweH899fgTjpzh1o0MCJwEALVaqE0bz5KUJCspodlsRhCfXzJCr3Y7FarVH6KitbtmwsXbqUypUrkzx5cg4dOkSuXLlYtmwZK1euZMuWLXad5/Lly2TJkoU9e/ZQtmxZ2/6xY8eyZMkSTp8+/cL3BwQE4OnpyYoVK2jSpMlzjxs1ahS+vr5P7V+xYgUeHh52xSoiIiLPtndvJiZMKEWOHLeZPPnnaD13SEgIP/74I7ly5SJnzpwA3Lhxg19++YV3330X1/g8OVfkFV28mJQFC97gyJH0AKRJ85C2bU9QrtzlOFeELTwcxo8vxf79mUiXLpBJk34mefJgs8MSMUVgYCDNmzfnzp07L11tJMo96Tdv3sTb2xuA5MmT25ZcK1++PB9++GGUg31yaTer1WrXcm+LFy8mZcqUNGjQ4IXHDRkyhL4RCzFi9KR7enpSvXr1eLcUS0hICNu3b6datWo4OzubHY7EUWonYg+1E7HXy9rKnj3GzLkqVZJTq1ataLlmUFAQixcvZsKECVy4cIFatWrRo0cP2+utWrWKlutI9NFnSuzq2BE2bgxlwABH/P3dmTixJAcOhDNlShgFC5od3f99+qkD+/c74uJiZeNGFwoXrqR2Ii+VUD9PolK/LcpJeo4cOfD39yd79uwUKFCAr7/+mlKlSrFp0yZSpkxp93nSpk2Lo6MjV65cibT/6tWrZMiQ4YXvtVqtLFq0iFatWuHi4vLCY11dXZ/5Tbuzs3O8/UOPz7FL7FE7EXuonYi9ntdWjhwxfpYs6YCz82vVoyUoKIiFCxcybtw4Ll68CECmTJl49913cXJysutLfDGXPlNiT6NGULs2TJgA48fDzp0OlCjhQI8eMGoUpEhhbnzbt8PIkcb2zJkWSpd2IiTEGMCrdiL2SGjtJCr3EuV/Tdu2bcvRo0cBo5d61qxZuLq60qdPHwYMGGD3eVxcXChevDjbt2+PtH/79u2Rhr8/y88//8xff/1F+4gKFCIiIhLrHi8a97qV3ZcvX07OnDnp1q0bFy9eJEuWLEyfPp2///6bHj16KEEXeQZ3dyMRPnUK3nsPwsJg6lTIkwe++MIYbm6Gf/6B9983rt++PXToYE4cIvFVlHvS+/TpY9uuUqUKf/75JwcOHCBnzpwUKVIkSufq27cvrVq1okSJEpQpU4Z58+Zx/vx5unTpAhhfAly6dImlS5dGet/ChQt56623KFSoUFTDFxERkWji7w+3boGLC7zuP8l37tzh0qVLZM2alSFDhtCuXTvc3NyiJU6RhM7LC9atg23boGdPOH0a2rWDuXONpdxia3lEgEePjF7+GzeMFR9mzIi9a4skFFFO0v39/fHy8rI9z5Yt2yuvS9q0aVNu3LjB6NGjCQgIoFChQmzZssVWrT0gIOCpNdPv3LnD2rVrmTZt2itdU0RERKJHRC/6G29AVGq4PXz4kLlz55I9e3bee+89ANq3b4+rqyutWrVSQTiRV1S9Ohw7Bp9/Dr6+8NtvUKqU0ZM9diykTRvzMfTsaXw2pEkDa9eCvmsTibooD3fPkSMH5cuXZ+7cubaica+ja9eu+Pv7ExQUxMGDB6lYsaLttcWLF7Nz585Ix6dIkYLAwEA6duz42tcWERGRV3fwoPHT3l66wMBApkyZQo4cOejTpw+DBw8mLCwMADc3Nzp06KAEXeQ1ubhA//5Gb3rLlsa0lPnzIXdumDkTQkNj7toLFxrXslhg5Up4wSrJIvICUU7SDxw4QJkyZfj444/JnDkz9evXZ/Xq1ZHWIhcREZGEL6InvXjxFx/34MEDJk2aRI4cOejbty9Xrlwhe/bs9OvXjyiuBCsidsqcGZYtg927oUgRuH0bunc3/r7u3h391ztwALp1M7Y//hiqVYv+a4gkFlFO0osVK8Znn33G+fPn+e6770ifPj2dO3cmffr0tGvXLiZiFBERkTjGarWvJ3316tXkyJGD/v378++//+Ll5cX8+fM5c+YMnTp1wskpyjPvRCQKypc3/q7OnAmpUhnD4StWhBYt4PLl6LnG9evQsCEEBUH9+jB4cPScVySxeuW1UiwWC1WqVGH+/Pn88MMP5MiRgyVLlkRnbCIiIhJH/f230TPn4sIL12VOnTo1V69exdvbm4ULF3LmzBk6dOjw0iVURST6ODpC165w5gx07mwMR1+xAvLmNZZwCw5+9XOHhUHz5nD+POTKBUuWgMPrrcYokui98l+hCxcuMGHCBIoWLUrJkiVJkiQJM1S+UUREJFGIGOpepIiRqAPcu3eP8ePHM3HiRNtxb7/9Nhs2bOD06dO0a9cuQa15KxLfpE0Lc+bA779D6dJw/z4MGmQUf9y69dXOOWKEsSa6hwesX2/++uwiCUGUx5jNmzePL7/8kj179pA3b15atGjBhg0bIlV8FxERkYQtYqh78eJw9+5dZsyYweTJk7lx4wbJkiWjXbt2pE6dGovFQv369c0NVkQiKV4c9uwx5qwPGmT0sL/7LjRoAJMng7e3fef55hujajzAggWvvxSjiBii3JM+ZswYSpUqxYEDB/jjjz/46KOPlKCLiIgkMkZP+l2uXPkEb29vhg4dyo0bN8idOzczZswgefLkZocoIi/g4ACtWxtV4Pv0MYbEb9gABQrAyJEQGPji9589Cx98YGz36gXvvx/jIYskGlHuST9//jwWiyUmYhEREZF4IDwcfvvtW6AVGzbcAiBv3rwMGzaMZs2aqRicSDySIoXRe96hg7HG+Y4dMHq0Mbd88mR47z1jDntYmFEVPiAAUqaEAQPg7l2jMN1nn5l9FyIJi13/ih47doxChQrh4ODA8ePHX3hs4cKFoyUwERERiZvOnYPAwALAPfLmzceIEcNp2rQpjo6OZocmIq+oQAFjbvnatdC3L/zzj1GxvVo1qFPHSMQvXoz8npQp4euvQaUmRKKXXUl60aJFuXLlCunTp6do0aJYLJZI65pGPLdYLISFhcVYsCIiIhL77t+/z+jRowkICGDBggX/DXX3pmDBPRw9WlzJuUgCYbFAo0ZQsyaMH28k5tu3G49nuX0b9u0DH59YDVMkwbMrSffz8yNdunS2bREREUn4bt68yaRJk5g6dSqB/01Q7du3LwcPFgCgUqVSKD8XSXiSJIExY6BVK2MFh0ePnn2cxQK9extro+uzQCT62JWkZ8+e3badLl06PDw8YiwgERERMdfNmzeZPHkyn3/+Offu3QOgYMGCjBw5knz58tmWXytRwsQgRSTGXb78/AQdwGqFCxeMueqVK8daWCIJXpQru6RPn54GDRrQqlUrqlWrhoPDKy+1LiIiInHMnj17qFmzpi05L1SoELVq1WL06NG4uroSHg6HDhnHFi9uYqAiEuMCAqL3OBGxT5Qz7KVLlxIUFMR7771H5syZ6dWrF7///ntMxCYiIiKx4PE6M0WLFsXNzY0iRYqwdu1aDhw4QNmyZW1fyp89C/fugZubUWhKRBKuTJmi9zgRsU+Uk3QfHx9Wr17Nv//+y7hx4zh16hRly5YlT548jB49OiZiFBERkRhw7do1Bg0aRPny5QkPDwcgSZIk7Nu3j0OHDuHj4/PUiLmDB42fb74JWmlNJGGrUAGyZjXmnj+LxQKensZxIhJ9XnmserJkyWjbti3btm3j6NGjJEmSBF9f3+iMTURERGLA1atXGThwIF5eXkyYMIG9e/eybds22+s5c+Z87nS2iPnoGuoukvA5OsK0acb2k4l6xPOpU1U0TiS6vXKS/ujRI77++msaNGhAsWLFuHHjBv3794/O2ERERCQa/fvvv/Tv3x9vb28+++wzAgMDKV68OBs3bqRGjRp2nSOiJ11F40QSBx8fWLMGsmSJvD9rVmO/ll8TiX5RHqi2bds2vvzySzZs2ICjoyONGjVi69atVKpUKSbiExERkWjw559/UqxYMR4+fAhAiRIlGDVqFLVq1cLyvLGsTwgLU9E4kcTIx8dYZm33bqNIXKZMxhB39aCLxIwoJ+kNGjSgTp06LFmyhNq1a+Ps7BwTcYmIiMhrCgoKwtXVFYC8efNSoEABHB0dGTlyJDVr1rQ7OY9w5gzcvw8eHpAvX0xELCJxlaOjllkTiS1RStJDQ0MZP348jRs3JpPKOIqIiMRJAQEBfPrpp6xZs4aTJ0+SPHlyLBYL33//PWnSpIlych4hYqh70aIqGiciIhJTojQn3cnJicGDBxMcHBxT8YiIiMgrunTpEj179sTb25tp06Zx6dIl1qxZY3s9bdq0r5ygw/+Lxmk+uoiISMyJcuG4t956i8OHD8dELCIiIvIKLl68SI8ePciZMyfTp08nKCiI8uXLs337dtq2bRtt14noSdd8dBERkZgT5cFqXbt2pV+/fly8eJHixYuTJEmSSK8XLlw42oITERGRF7tx4wZ58uSxFYSrUKECo0aNokqVKq/Va/6kx4vGqSddREQk5kQ5SW/atCkAPXv2tO2zWCxYrVYsFgthYWHRF52IiIg85datW6RKlQqANGnS4OPjw8WLFxk5ciSVK1eO1uQ8wunTEBgISZJA3rzRfnoRERH5T5STdD8/v5iIQ0RERF7in3/+YezYsSxdupSjR4+SJ08eABYsWICbm1uMXvvgQSPxf/NNLbskIiISk6KcpGfPnj0m4hAREZHn8PPzY+zYsSxevJjQ0FAA1q5dy5AhQwBiPEEHOHzYSNI11F1ERCRmRTlJX7p06Qtf/+CDD145GBEREfm/v//+m7Fjx7JkyRJbcl61alVGjhxJhQoVYjWWiJ50FY0TERGJWVFO0nv16hXpeUhICIGBgbi4uODh4aEkXUREJBoEBwdTpkwZrl69CkC1atUYOXIk5cqVi/VYwsIsHDminnQREZHYEOUl2G7duhXpcf/+fU6fPk358uVZuXJlTMQoIiKSKPj7+2O1WgFwcXGhe/fu1KhRg71797Jt2zZTEnSAixeT8vChhaRJ4b9p8CIiIhJDopykP0vu3LkZP378U73sIiIi8nJnz56ldevW5MqVi++++862f+jQoXz//feUKVPGxOjgr79SAlCsGDhEy/8cRERE5Hmi7Z9aR0dHLl++HF2nExERSfBOnz5Nq1atyJcvH0uXLiUsLIyff/7Z9rpDHMmIz51LCWg+uoiISGyI8pz0jRs3RnputVoJCAhgxowZpg3DExERiU/+/PNPPv74Y1auXEl4eDgAderUYcSIEZQsWdLk6J4WkaRrPrqIiEjMi3KS3qBBg0jPLRYL6dKl4+2332bSpEnRFZeIiEiCZLVaadasGUePHgWgXr16jBgxguJxtJs6NBT8/FIAStJFRERiQ5ST9Ihv/EVERMQ+f/zxB97e3nh4eGCxWBg2bBjLly9nxIgRFCtWzOzwXujkSQgOdiRZMiu5clnMDkdERCTBe+3JbqGhody/fz86YhEREUlQTpw4QZMmTXjjjTeYM2eObX+jRo3YsGFDnE/QAQ4fNhLzYsWsKhonIiISC+z+53bLli0sW7Ys0r5PPvmEpEmTkjJlSqpXr86tW7eiPUAREZH45vjx4zRu3Jg33niD1atXY7VaOXv2rNlhvZKDB/+fpIuIiEjMsztJnzhxInfv3rU937t3LyNGjGD48OF8/fXXXLhwgTFjxsRIkCIiIvHB0aNHadiwIYULF2bNmjWA0Wt+9OhRZs+ebXJ0r0ZJuoiISOyyO0k/ceIEZcuWtT1fs2YN1apVY+jQofj4+DBp0iQ2bdoUI0GKiIjEB2PGjGHdunVYLBaaNGnC8ePHWb16NYULFzY7tFcSEgLHjilJFxERiU12F467d+8eadKksT3/5ZdfaNSoke15wYIFtU66iIgkKocPHyZdunRkzZoVgOHDh+Pk5MTw4cMpWLCgydG9vj/+gKAgCx4eIeTMaXY0IiIiiYPdPemZM2fm1KlTANy/f5+jR49GWhf9xo0beHh4RH+EIiIicczBgwepV68exYoVizTVq0iRInz11VcJIkEHOHjQ+Jkz520VjRMREYkldv+T26hRI3r37s2yZcvo2LEjGTNmpHTp0rbXDxw4QN68eWMkSBERkbjgwIED1K1blxIlSrBp0yYcHBwIDg7Gak2YQ8EPHDB+5sx529Q4REREEhO7h7uPHDmSy5cv07NnTzJmzMjy5ctxdHS0vb5y5Urq1q0bI0GKiIiY6ffff2fUqFFs2bIFAAcHB5o3b86wYcMS9BfUET3puXLdNjUOERGRxMTuJN3Dw+OpJdge99NPP0VLQCIiInHN+vXr2bJlCw4ODrRs2ZKhQ4eSJ08es8OKUcHBcPSosa2edBERkdhjd5IuIiKSWOzbtw8XFxeKFy8OQN++fbl27RoDBw4kd+7cJkcXO06cMBL1lCmtZMwYaHY4IiIiiYbKwIiIiPxnz549VK9enbJly9K3b1/bXPO0adMyf/78RJOgw/+HuhcrZsViMTcWERGRxERJuoiIJHq//PIL1apVo3z58mzfvh0nJydy585NcHCw2aGZJqJonNZHFxERiV0a7i4iIonWb7/9xkcffcSPP/4IgJOTE23btmXIkCF4e3ubHJ25Hu9JFxERkdijnnQREUm0Tp8+zY8//oizszOdOnXi7NmzzJs3L9En6EFBcOyYsV28uJJ0ERGR2GRXT/rnn39u9wl79uz5ysGIiIjEFKvVys6dO7l37x716tUDoHnz5pw+fZrOnTuTLVs2kyOMO06cgJAQSJ0avLzg1CmzIxIREUk87ErSp0yZEun5tWvXCAwMJGXKlADcvn0bDw8P0qdPryRdRETiFKvVyo8//oivry+7d+8ma9as1KhRA1dXV5ycnPjkk0/MDjHOiZiPXrw4KhonIiISy+wa7u7n52d7fPLJJxQtWpRTp05x8+ZNbt68yalTpyhWrBhjxoyJ6XhFRETsYrVa2b59OxUqVOCdd95h9+7duLi4UL9+fR49emR2eHFaxHz0EiXMjUNERCQxinLhuOHDh7NmzRry5s1r25c3b16mTJlCo0aNaNGiRbQGKCIiElW///47vXr1Yt++fQC4urrSsWNHBg0aRNasWU2OLu57vCddREREYleUk/SAgABCQkKe2h8WFsa///4bLUGJiIi8jvDwcPbt24erqyudO3dm0KBBZM6c2eyw4oVHj+D4cWNbPekiIiKxL8rV3atWrUrHjh05cOAAVqtR8fXAgQN07tyZd955J9oDFBEReRGr1cp3333H9OnTbfveeustZs+ezd9//820adOUoEfB8eMQGgpp0oBq6YmIiMS+KCfpixYtIkuWLJQqVQo3NzdcXV156623yJQpEwsWLIiJGEVERJ5itVr59ttveeutt6hVqxYDBw4kICDA9nqXLl2UnL+CiKHuJUqoaJyIiIgZojzcPV26dGzZsoUzZ87w559/YrVayZ8/P3ny5ImJ+ERERCKJSM59fX058F9G6eHhQdeuXXFxcTE5uvgvomic5qOLiIiYI8pJegQvLy+sVis5c+bEyemVTyMiImK348eP07ZtWw7+l0l6eHjQrVs3+vfvT/r06U2OLmF4vCddREREYl+Uh7sHBgbSvn17PDw8KFiwIOfPnwegZ8+ejB8/PtoDFBERiZAuXTr++OMPkiRJwqBBg/D392fChAlK0KPJw4fwxx/GtpJ0ERERc0Q5SR8yZAhHjx5l586duLm52fa/8847rFq1KlqDExGRxCs8PJx169bRq1cv276MGTOyZs0a/P39GT9+POnSpTMxwoTn2DGjaFy6dKCV6kRERMwR5XHqGzZsYNWqVZQuXRrLYxVlChQowLlz56I1OBERSXwikvMxY8Zw7NgxAN5//31Kly4NQO3atc0ML0GLmI+uonEiIiLmiXKSfu3atWcOK3zw4EGkpF1ERCQqwsPDWbt2LaNHj+bEiRMAJEuWjF69eqk4aSyJmI+uonEiIiLmifJw95IlS/Ltt9/ankck5vPnz6dMmTJRDmDWrFl4e3vj5uZG8eLF2b179wuPDwoKYujQoWTPnh1XV1dy5szJokWLonxdERGJO86dO0fhwoVp0qQJJ06cIHny5AwfPhx/f3/GjBlD6tSpzQ4xUVDROBEREfNFuSd93LhxvPvuu5w8eZLQ0FCmTZvGH3/8wb59+/j555+jdK5Vq1bRu3dvZs2aRbly5Zg7dy41a9bk5MmTZMuW7ZnvadKkCf/++y8LFy4kV65cXL16ldDQ0KjehoiIxCGenp7cu3ePFClS0Lt3b3r16kWqVKnMDitRCQyEkyeNbfWki4iImCfKPelly5Zlz549BAYGkjNnTrZt20aGDBnYt28fxaP4r/rkyZNp3749HTp0IH/+/EydOhVPT09mz579zOO///57fv75Z7Zs2cI777yDl5cXpUqVomzZslG9DRERMUlYWBgrVqygdu3ahISEAODi4sLatWvx9/dn1KhRStBNcPQohIVBhgyQJYvZ0YiIiCRer7TA+RtvvMGSJUte68LBwcEcPHiQwYMHR9pfvXp19u7d+8z3bNy4kRIlSjBhwgSWLVtGkiRJqFevHmPGjMHd3f2Z7wkKCiIoKMj2/O7duwCEhITY/nMYX0TEG9/iltildiL2MKOdhIaGsmrVKsaNG8eZM2cAWLp0KR988AEARYoUifWY5P/273cAHClWLJzQ0DDbfn2miD3UTsQeaidij4TaTqJyP1FO0qtUqULLli1p1KgRKVKkiOrbba5fv05YWBgZMmSItD9DhgxcuXLlme/5+++/+eWXX3Bzc2P9+vVcv36drl27cvPmzefOSx83bhy+vr5P7d+2bRseHh6vHL+Ztm/fbnYIEg+onYg9YqOdhIWFsWvXLlavXs3ly5cBSJo0KfXq1cPd3Z0tW7bEeAzyct988yaQjeTJz7Bly+mnXtdnithD7UTsoXYi9kho7SQwMNDuY6OcpL/xxhsMGzaM7t27U6tWLVq1akWtWrVwcXGJ6qkAnqoIb7Van1slPjw8HIvFwpdffmn7gmDy5Mk0atSImTNnPrM3fciQIfTt29f2/O7du3h6elK9enWSJ0/+SjGbJSQkhO3bt1OtWjWcnZ3NDkfiKLUTsUdstZMbN25QoUIF/vrrLwBSp05N79696dq1a7z7DE7ohg41/kvQtGkuatXKaduvzxSxh9qJ2EPtROyRUNtJxIhue0Q5Sf/888+ZOnUqP/zwAytWrKB169Y4OjrSqFEjWrRoQaVKlew6T9q0aXF0dHyq1/zq1atP9a5HyJQpE1myZInUg58/f36sVisXL14kd+7cT73H1dUVV1fXp/Y7OzvH2z/0+By7xB61E7FHTLSTx79szZgxI1myZOHWrVv079+fbt26kSxZsmi9nry+Bw/g1Clj+623nHhWk9BnithD7UTsoXYi9kho7SQq9xLlwnEADg4OVK9encWLF/Pvv/8yd+5c9u/fz9tvv233OVxcXChevPhTwxi2b9/+3EJw5cqV4/Lly9y/f9+278yZMzg4OJA1a9ZXuRUREYkmISEhLFq0iKJFi3L9+nXb/i+++AJ/f38GDx6sBD2OOnoUwsMhUybInNnsaERERBK3V0rSI1y5coU5c+bw6aefcuzYMUpEcWHVvn37smDBAhYtWsSpU6fo06cP58+fp0uXLoAxVD2ioBBA8+bNSZMmDW3btuXkyZPs2rWLAQMG0K5du+cWjhMRkZgVHBzMggULyJs3L+3bt+fYsWPMmDHD9rq3tzdJkyY1MUJ5mYj10bX0moiIiPmiPNz97t27rF27lhUrVrBz505y5MhB8+bN+eqrr8iVK1eUztW0aVNu3LjB6NGjCQgIoFChQmzZsoXs2bMDEBAQwPnz523HJ02alO3bt9OjRw9KlChBmjRpaNKkCR9//HFUb0NERF5TcHAwixcvZuzYsfzzzz8ApE+fnoEDB9q+bJX4ISJJj+J37SIiIhIDopykZ8iQgVSpUtGkSRPGjh1LyZIlXyuArl270rVr12e+tnjx4qf25cuXL8FV+hMRiW+Cg4MpVKgQZ8+eBYx/GwYNGkTnzp3j7coZidnBg8ZP9aSLiIiYL0pJutVqZdq0abRs2VL/CRMRSWRCQ0NxcjL+2XBxcaFq1arcu3ePQYMG0alTJ/27EE/dv///onFK0kVERMwXpTnp1v+1d9/RUVVfG8e/k05vgRB6JzQB4VVA6VIVkRpFkSYKCIioVKV3lSaCoBQV/QkCRlFEEAkgVZDQQpMiAYJIrwkp9/3jOgkxCU4gyZ1Mns9aWUzuvTOzhxyG7Dn77GMY9O3blzNnzqRVPCIi4mQiIiL48MMPKVWqFLt37447PmHCBI4fP86AAQOUoGdgISFgGFC4sNk4TkRERKyVoiTdzc2NsmXLcvHixbSKR0REnERERASzZs2iTJky9O3bl7CwMD744IO483ny5FHTThegpnEiIiLOJcXd3adMmcJbb73F/v370yIeERGx2O3bt5k5cyalS5emX79+nDlzhsKFCzNr1ixmz55tdXiSyuzr0dU0TkRExDmkuHHcCy+8wK1bt6hatSpeXl6JZlEuXbqUasGJiEj6MgyDunXrsuufzK1IkSIMGzaM7t274+3tbXF0khY0ky4iIuJcUpykT58+PQ3CEBERq9y6dQtvb2/c3d2x2Wy88MIL/P333wwdOpRu3bopOXdh16/D4cPmbSXpIiIiziHFSXqXLl3SIg4REUlnERERTJs2jalTpzJjxgwCAwMB6N27N3369MHLy8viCCWt7d5tNo0rUgT8/KyORkREROA+knSAY8eOsXDhQo4dO8aMGTMoUKAAq1evpmjRolSqVCm1YxQRi8XEwKZNEB5udn+uWxfc3a2OSu7XzZs3mTVrFhMnTuTq1asAfPbZZ3FJumbOMw97qbvWo4uIiDiPFDeO27BhA1WqVGH79u2sWLGCGzduALB3715GjhyZ6gGKiLVWrIASJaBhQ+jUyfyzRAnzuGQsN27cYMqUKZQsWZIhQ4Zw9epVSpUqxfz58wkKCrI6PLGAvWmcSt1FREScR4qT9CFDhjBu3DjWrl2boBSyYcOGbN26NVWDExFrrVgB7dvD6dMJj585Yx5Xop6xBAYGMnjwYP7++++4zu379u2je/fueHp6Wh2eWEAz6SIiIs4nxUn6vn37aNOmTaLj+fPn1/7pIi4kJgZee81cr/pv9mMDBpjXiXO6du1aXLUTQL9+/ShTpgyLFi1i3759NG7cWMl5JnbtGhw5Yt7WTLqIiIjzSPGa9Ny5cxMeHk7JkiUTHN+9ezeFCxdOtcBExFqbNiWeQb+bYUBYGAQEQIUKZuOpwoXNP+++nT17+sUspmvXrjFz5kymTZtG//7945YiNWvWjIMHD+Lh4UFUVJTFUYrVfv/d/LNYMcif39pYREREJF6Kk/ROnToxePBgvv76a2w2G7GxsWzevJk333yTF198MS1iFJF09McfsGQJzJ3r+PV//JH8+Vy5kk/g7V958oDNljrxZ2ZXr16NS84vX74MwOrVqxkxYgQ2mw2bzYaHx331CxUXZF+PrlJ3ERER55Li39bGjx9P165dKVy4MIZhULFiRWJiYujUqRNvv/12WsQoImns5ElYutRMzu2za46aOBHy5jVn3c+cMf+03756Nf7rwIHkH8PHJ/kE3v59gQLqKJ+cK1euMGPGDKZPn86VK1cACAgI4J133iEwMBCbPgGRJNjXo6vUXURExLmkOEn39PTkiy++YOzYsfz+++/ExsZSvXp1ypYtmxbxiUgaOX06PjHfsSP+uLs7NG4MHTrAyJHmtmtJrUu32czk+a23kk+er1+PT9zvTuDv/v7vvyEi4r9n5D08zO3fkkrg7bcLFYLMuLX3kCFDmPtP6UOFChUYMWIEHTp0wF2fasg9qGmciIiIc7rvusdSpUpRqlQpYmJi2LdvH5cvXyZPnjypGZuIpLLwcFi2zEzMN2+OP+7mBvXrQ2AgtG0bvz41b16zi7vNljBRt0/MTp9+79ntHDnMNesBAclfExkJZ88mncDbb589C9HR5hr4sLB7v0Y/v3uX1xcuDNmy3fsxnN3ly5e5ffs2hQoVAuCNN95g69atDBs2jPbt2ys5l/905Ur8h2KaSRcREXEuKU7SBwwYQJUqVejRowcxMTHUr1+fLVu2kDVrVr7//nsaNGiQBmGKyP36+29YvtxMzDdsSJhsP/64mZi3bw8FCya+b9u2ZlL/2msJm8gVKWIm6G3bPnh83t5QsqT5lZzoaPjrr3vPyJ8+DXfumNf99Vf8etuk5M597xn5IkXMa9KrSjwmxmzUFx5uVgvUrZv0hx+XLl1i2rRpzJw5k5YtW/K///0PgLJlyxISEqKydnGYfVlLiRKQL5+loYiIiMi/pDhJX7ZsGS+88AIAK1eu5Pjx4xw6dIjPPvuM4cOHs/nu6TkRscT1654sXGhj2TL45ZeE26TVqmUm5h06mAnpf2nbFlq3diyJTCseHmas94rXMODixXvPyIeFwY0b5izilSuwf3/yj5c16383vMuf36xCeBArViT9IciMGfEfgly8eJGpU6fywQcfcP36dQAOHTpEREQEPj4+AErQJUXsH2JpFl1ERMT5pDhJv3DhAgX/mXJbtWoVHTt2pFy5cvTo0YOZM2emeoAi4pirVyEoCL76yp21a5sTExOfPdaoYSbmHTtC8eIpf2x3d3D2IhmbDXx9za9q1ZK/7tq1pBP4u5P7ixfh1i1zD2n7PtJJ8fQ018Hfq+Gdv795XVJWrDCrGP695v/MGfP4ggUXOHz4fWbNmhW333nVqlUZMWIEzzzzDG4P+gmBZFpajy4iIuK8Upyk+/n5ERoair+/P6tXr2b27NkA3Lp1S+sgRdLZ9euwcqVZyr56tVnuDWbiVqWKwbPP2ujYEcqUsTRMp5IzJ1SsaH4l5/bt+HXyyZXXh4dDVBT8+af5lRybLX6d/L+b3L35ZtJN+QzDvN+AAfO5enUSANWqVWPkyJE8/fTTSs7lgWn7NREREeeV4iS9W7dudOzYEX9/f2w2G02aNAFg+/btBNyrO5SIpIpbt+CHH8zE/IcfzM7odhUqQPv2Mfj5BfPyy/XwTG4KV+4pSxYoXdr8Sk5UFJw7d+8Z+TNn4q87dy5+9jJ554G/gCoYBly92ocaNX5mxIh+tGrVSiXtkiouX4Zjx8zbDz9sbSwiIiKSWIqT9FGjRlG5cmXCwsLo0KED3t7eALi7uzNkyJBUD1BEzER89WozMV+5Em7ejD9XtqxZyh4YCJUqQXR0LKtW3bAu2EzC0xOKFjW/khMbCxcuJJ3A79p1997xfwHvAnOA8sAuwAbk4I031vL002n7WiRzsTeNK1XK3MFBREREnMt9bcHWvn37RMe6dOnywMGISLw7d2DNGjMx//Zbs7TdrkSJ+MS8WrX060IuKePmBgUKmF//nrEMDoaGDc8BU4CPgNv/nPEALgDmPnjqvC2pzV7RoaZxIiIizum+kvR169Yxbdo0Dh48iM1mIyAggAEDBvDEE0+kdnwimUpUlNmNfckS+OYbswO5XZEiZuO3wED4v/9TYp6RhYeH88039uTcvl7hUWAk0BxzFt30yivw7rvQrp1+5pI61DRORETEuaW4+9CsWbNo3rw5OXLk4LXXXqN///7kzJmTli1bMmvWrLSIUcSlxcSYifkrr5idwJs3h4ULzQS9YEHo1w9+/dVsTvb++/DII0rWMrpt27Yxc+Z0zAS9FrAa2Aq0AGxxP9/cueHkSXO7vLp1YccOS8IVF6Pt10RERJxbimfSJ06cyLRp0+jbt2/csf79+/PYY48xfvz4BMdFJGmxsbB5szljvmwZ/PVX/Ln8+c3ttwID4fHH03c/ckkbZ86c4eDBg3HVRq1bt6Z79+4EBgZy/XoTBgywJdonffp0aNoU3nsPpkwxx8ujj0KnTjBxIhQrZs1rkYzt4kU4ccK8raZxIiIizinFSfq1a9do3rx5ouNNmzZl8ODBqRKUiCsyDNi2zUzMv/7a3OLLLm9eaNvWTMwbNACP+1qIIs7m9OnTTJo0iU8++YQcOXJw4sQJsmfPjpubG/Pnz4+77plnYNMmc1s3f39z1tz+4cyoUdCzJwwfDp99Bl9+ae6vPnAgDBkCOXJY8tIkg7I3jStdGvLksTYWERERSVqKy92ffvppvvnmm0THv/32W1q1apUqQYm4CsMw13++9ZbZ7K1OHZgxw0zQc+WCLl1g1Spze66PP4YnnlCC7grCwsLo06cPpUuX5sMPPyQyMpKAgADOnz+f5PXu7uaHM889Z/757+qJwoVh0SJzLNWvb3b7nzDB7Oz/8cfmkgkRR2g9uoiIiPNzKB2YOXNm3O0KFSowfvx4goODqV27NmCur9y8eTNvvPFG2kQpkoEYBuzda86YL10avx8xQPbs8PTT5ox5s2bwzw6G4iLOnj3L2LFjmT9/PlFRUQDUq1ePUaNG0aBBgwfe5/zhh2H9evjuO/ODn6NH4eWX4YMPzH4FTZqkxqsQV2Zfj64kXURExHk5lKRPmzYtwfd58uQhNDSU0NDQuGO5c+dmwYIFvP3226kboUgGERpqJuZLlsDhw/HHs2SBVq3MxLxFC/N7cU2XLl1i7ty5GIZBgwYNGDlyJA0aNEjV57DZoHVrcyzNmQOjR8O+feb69ZYtzU7wFSum6lOKC9H2ayIiIs7PoST9hL3LjIgkcORI/Iz5/v3xx729zYQpMBCeegqyZbMuRkk7J0+eZMOGDXTp0gWAypUrM27cOB577DHq16+fps/t5QWvvQadO8PYsTBrlrl04qefzNn1UaPM/dlF7C5cMHeJADWNExERcWYpXpNud+HCBS5evJiasYhkCCdOwKRJUL06lC8PI0aYCbqnp5mQf/45nD9vNvcKDFSC7oqOHz/OSy+9RNmyZenRowfHjx+POzds2LA0T9DvljcvTJtmVnK0aWOuT58zx1yvPmWKuX5dBOJL3cuWNXtiiIiIiHNKUZJ+5coVXn31VXx9ffHz86NAgQL4+vrSt29frly5kkYhilgvLCx+j/JSpWDoUAgJMRt8NWsGCxaY26itXAkvvAA5c1odsaSF48eP06NHD8qVK8f8+fOJjo6mUaNGREZGWh0aZcuaHwwFB5uzpNeuweDBUKGCWe1hGFZHKFZT0zgREZGMweE+0pcuXaJ27dqcOXOG559/ngoVKmAYBgcPHmTRokWsW7eOLVu2kEd7uoiLOHvW3MN8yRLYsiX+uJsbNGxozpK3aQO+vtbFKOnjr7/+YsiQIXz++efE/NNKvVmzZowcOTKugaazqF8ffvsNFi+GYcPg5El49llzV4GpU6FWLasjFKvYZ9K1Hl1ERMS5OZykjxkzBi8vL44dO4afn1+ic02bNmXMmDGJmsyJZCTnz5uJ+dKlsHFj/OyjzWbuXR0YCO3awb/+CYiL8/LyYsWKFcTExNCiRQtGjBhBLSfOdt3c4MUXzbH6/vsweTJs3Qq1a5sJ+8SJ5rZukrloJl1ERCRjcLjcPSgoiPfeey9Rgg5QsGBBpkyZkuT+6SLO7uLF+D3K/f3h1VdhwwYzQa9dG6ZPh9OnzWN9+ihBzwwOHz7M6NGjMf75lCZPnjzMmTOH7du3s2rVKqdO0O+WLZvZM+HoUeje3fyw6auvICAAhg9349Ythz+nlQzu/Hlz2Y7NZvbTEBEREefl8G9o4eHhVKpUKdnzlStX5ty5c6kSlEhau3IFgoLMUvaff4bo6Phz//d/5ox5hw5QrJhVEYoVDh06xLhx4/jf//5HbGwsderUock/m4936tTJ4ujuX6FCMH8+9OsHAweae62/+647uXI9weXLbrz8MngoX3dp9lL3cuXUM0NERMTZOTyT7uvry8mTJ5M9f+LECfLly5caMYmkiWvXzHW6rVqZW1N16warV5sJerVqZgnwsWOwYwe88YYS9Mzk4MGDdOrUiYoVK/LFF18QGxtLq1at8Pf3tzq0VFWtGqxbB999B2XLGly96s2rr7pTtar5b0Fclz1JV6m7iIiI83M4SW/evDnDhw/nzp07ic5FRkbyzjvv0Lx581QNTuRB3bxpzpa3bWsm5p07w/ffQ1QUVKoEY8bA4cOwezcMGWJ2bpfM48qVKzz77LNUqlSJ//3vfxiGQevWrdm1axffffcdlStXtjrEVGezmR9UhYRE89JLe8mb1yA0FFq0gObNze0ExfXY16OraZyIiIjzc7jAcfTo0dSsWZOyZcvy6quvEhAQAEBoaCizZ88mMjKSzz//PM0CFXHU7dvw449mcv7993DrVvy5cuXMUvbAQDNJl8wtR44c7NmzB8MweOaZZxgxYgTVM8mCXU9PeOqpE4wfX4HJkz354AP46SdYuxZ69oTRo9V/wZVoJl1ERCTjcDhJL1KkCFu3bqVPnz4MHTo0rqGSzWajSZMmzJo1i6JFi6ZZoCL3EhkJa9aYifm338KNG/HnSpWKT8wfesicSZTMad++fcycOZMPPvgAHx8f3N3dmTt3Lrly5aJq1apWh2eJPHnMDvB9+pj7qi9fDnPnwpdfwtChMGAAZMlidZTyIM6dM5tfqmmciIhIxpCiVkElS5bkxx9/5PLlyxw9ehSAMmXKkDdv3jQJTuReoqLMpm9LlphN4K5ejT9XrBh07Ggm5jVqKDHP7Pbu3cuYMWNYvnw5AFWrVqVv374A1KtXz8rQnEbp0ub2g5s2mc3ldu4091n/6COYNMncuk3/jjIm+yx6QABkz25tLCIiIvLf7qufb548eXjkkUdSOxaR/xQdDcHBZmK+YgVcuhR/rlAhsyN7YCA8+qi5V7RkbiEhIYwZMyZue0ibzUaHDh1o2LChxZE5r7p1Yfv2+Jn0U6egUyeYMQOmToU6dayOUFLKnqRrPbqIiEjGoE13xOnFxMCvv5qJ+fLl5n6/dgUKQPv2ZmL++ONKzMUUFRVFx44dCQoKAszkPDAwkHfeeYeKFStaG1wG4OYGL7xgNlycNs3c+WD7dnjsMbNCZdIkKFnS6ijFUfamcVqPLiIikjEopRGnFBsLW7bAa69B0aLQoAHMmWMm6Pnywcsvm6XuZ87Ahx9CvXpK0CWep6cnMTEx2Gw2OnXqxIEDB/jf//6nBD2FsmaF4cPh6FF46SWz3H3pUrNsetCghEtMxHmpaZyIiEjGorRGnIZhxO9RXqKEOWs3cyaEh0Pu3PH7moeHm42tGjcGD9WCCPDbb7/Rpk0bwsLC4o69++67hIaG8sUXX1ChQgULo8v4/P3h44/NrQqfeALu3IF334UyZWD2bHMZijin8HA4e9b8ELNaNaujEREREUcoxRFLGQaEhJil7EuXwokT8edy5IDWrc1S9qZNwcvLsjDFSe3YsYPRo0ezatUqAAoVKsSHH34IQPny5a0MzSVVrWruovDjj+aHaYcOwauvwqxZ8N575l7rai7nXOyz6BUqQLZs1sYiIiIijlGSLpbYv99MzJcsMUtp7bJmhVatzMS8RQvw8bEuRnFe27ZtY/To0axevRoANzc3XnjhBV577TWLI3N9Nhu0bAlNmpiz6yNHwsGD8OST5rH33jO3OhTnYF+PrqZxIiIiGYeSdEk3hw/HJ+ahofHHfXzMX/A7djT/1GyPJMcwDNq3b8+KFSsAcHd3p3PnzgwfPpwyZcpYHF3m4ulp7q3eqRNMmGB2f1+71tyHu3t3GDsWCha0OkpR0zgREZGMR2vSJU0dO2Z2hq5WzWw2NXKkmaB7ecHTT8MXX5jN4JYtM5N0JehyLzabjdKlS+Pu7k63bt04fPgwCxcuVIJuody5YcoUcza9Qwez6eMnn0DZsjB+PNy+bXWEmZdhaPs1ERGRjEhJuqS6P/80m0rVrGk2lho2DPbsMZu8tWgBixbBX3/Bt9+as3A5clgdsTirTZs20aRJEzZt2hR3bNCgQRw5coQFCxZQunRpC6OTu5UqZfaV+PVXeOQRuHED3n4bypeHxYvN5F3S19mzcO6cmsaJiIhkNCp3l1Rx5gx8/bVZyr5tW/xxNzdo1MhcY96mjbl9msh/2bhxI6NHj+aXX34BzLJ2+/pzX19ffH19rQxP7uGxx2DrVvO9YMgQOHUKOnc2y+GnToW6da2OMPOwz6JXrGj2+xAREZGMQTPpct/++it+j/KiReH1180E3WYz9zWfPdvc/mftWnOPZSXo8l+Cg4Np2LAh9evX55dffsHT05OXX36Zjz76yOrQJAXc3OC558zu7xMmQPbs5troevWgfXtzGYykPa1HFxERyZg0ky4pcuECrFhhzpIFBycsYX3sMXPGvH17c19lkZTo2rUrn376KQCenp706NGDIUOGULx4cYsjk/uVJQsMHWo2khsxwlyrvnw5fPcd9O9vlsPnzm11lK7LPpOuJF1ERCRj0Uy6/KfLl2HBAmjWzOzW/Mor8MsvZoL+yCPw/vtmSeuvv0K/fkrQxTGGYRB716c8devWxcvLi969e/PHH38wZ84cJeguws8P5s41e1M0bQpRUeb7Rpky5h7rUVFWR+h6DEPbr4mIiGRUStIlSdeuweefw1NPmb9g9+gBa9ZATIy5xdKkSXD8OGzfDgMHmuXuIo4wDIOff/6ZevXqsWDBgrjjL774In/88QezZ8+mWLFiFkYoaaVyZfjpJ/jxR3Od9MWL5gd7VarAypVmYimp48wZc+cMd3eoWtXqaERERCQlVO4ucW7cgO+/N0vZf/wRIiPjz1WpYm6RFhhobq0kklKGYbB27VpGjx7Nli1bALhw4QI9evTAZrPh6elJUX3akyk0bw5PPGGWv48YAYcPm1syNmpkzrCrE/mDs8+iV6pkLjsQERGRjEMz6Znc7dvmGtGOHaFAAbPZU1CQmaDb9zU/cAD27jXXjypBl5QyDIOffvqJOnXq0KxZM7Zs2YKPjw/9+/dn3bp12Gw2q0MUC3h4QK9ecPQoDB4M3t7mMpqHHzYrd86etTrCjE1N40RERDIuzaRnQpGRsHq1OWP+3Xdw82b8udKlzdnywEBz9lz5kzyogQMHMn36dAB8fHzo1asXgwYNwl/NCwTIlctcPtOrl9lk7quvzB4YS5aYyfsbb8RvHxYTA5s2mbtG+Pub27m5u1sbv7OyN43TenQREZGMR0l6JnHnDvz8s/mLb1CQuebcrnjx+FL2hx9WYi4PxjAMIiMj8fHxAaBdu3bMnTuX3r1789Zbb1GwYEGLIxRnVKIE/O9/Ztf3gQPN7RxHjDAbzk2YYCbqr78Op0/H36dIEXP/9bZtLQvbKd3dNE4z6SIiIhmP5eXus2fPpmTJkvj4+FCjRg02bdqU7LXBwcHYbLZEX4cOHUrHiDOO6Oj4PcoLFoQnn4TPPjMT9MKFYcAA2LoVTpyAKVPMGRcl6HK/DMNg5cqVPPLII7z99ttxxx9//HFOnz7N+++/rwRd/lPt2rBlizmjXry42QCtSxfo0CFhgg7mufbtzW0hJV5YmLldpocHPPSQ1dGIiIhISlmapC9ZsoQBAwYwfPhwdu/eTd26dWnRogWnTp265/0OHz5MeHh43FdZLZSOExNj7l/euzcUKmRudzR/vrmNmp8f9O1rloueOgXTpkGtWkrM5cEYhsF3331HzZo1efrpp9m5cyefffYZERERcdfkzZvXwgglo7HZzMqeQ4fMWfTk3qPs3eAHDDDf+8Rkn0WvXBn+KWgRERGRDMTScvepU6fSo0cPXnrpJQCmT5/OTz/9xJw5c5g4cWKy9ytQoAC5c+dOpyidX2ysOfO0ZAksWwbnzsWf8/WFdu3MX3jr1dP6TUk9hmHw7bffMmbMGHbv3g1AtmzZ6Nu3L2+88UZcubvI/fLxMWfW77U1m2GYM8ebNkGDBukWmlOzr0dXqbuIiEjGZFmSfufOHXbt2sWQIUMSHG/atGnc9kzJqV69OhEREVSsWJG3336bhg0bJnttZGQkkXftJXbtn8XYUVFRREVFPcArSFsxMfDrr7a4BkmPP24QG2vGGxUVhWHAb7/Z+PprG8uXu3H6dPxUU+7cBs88Y9ChQywNGxp4/PNTjo01v8S12cd1Wo/vSZMmMWLECACyZ89O7969ef311/H19U2X55cHk17j5EGFhdlw5L+qsLBooqK00TrAb7+5A25UqxZDVNSDv+lnlLEi1tI4EUdonIgjXHWcpOT1WJakX7hwgZiYGPz8/BIc9/Pz49zdU8F38ff3Z968edSoUYPIyEg+//xzGjduTHBwMPXq1UvyPhMnTmT06NGJjq9Zs4as9pbBTmbrVn8++aQKFy/Gb26bL99tevTYj59fLj799AybNxfi/PlsceezZo3i0UfDeeyxM1St+jeengZRUbBmjRWvQJzB2rVrU/XxYmNjuXnzJjly5ACgUKFC5MyZk6ZNm/L000+TM2dOduzYkarPKWkvtcdJavvzz3zA4w5ct41Vqy6mfUBOzjBg27bmgDcREb+yatWVVHtsZx8r4hw0TsQRGifiCFcbJ7du3XL4Wpth3KuQMO2cPXuWwoULs2XLFmrXrh13fPz48Xz++ecON4Nr1aoVNpuN7777LsnzSc2kFy1alAsXLpAzZ84HexFp4JtvbDz7rPs/5Z13L8S0/5jij2XLZvDUU+aMedOmhtYeCmB+Srd27VqaNGmCp6fnAz9ebGwsK1asYMKECRQrVoygoKC4c5GRkXh7ez/wc0j6S+1xklZiYqBMGQ/OngXDSLw43WYzKFwYjh6N1nIe4ORJKFfOE09Pg0uXokmNf54ZZayItTROxBEaJ+IIVx0n165dw9fXl6tXr/5nHmrZTLqvry/u7u6JZs3Pnz+faHb9XmrVqsXixYuTPe/t7Z1kEuHp6el0P/SYGHNP4KQ/NrH/cmrQpo1Bp05utGxpI2tWG07QpF+c0IOO8djYWJYtW8aYMWM4cOAAAGFhYVy+fJkCBQrEPYdkbM74Xng3T0+YOdPs4m6zJX5/NAwbM2aAj4/zvob0tGeP+WeVKjayZ0/dvxNnHyviHDROxBEaJ+IIVxsnKXktlmV3Xl5e1KhRI1EZw9q1a6lTp47Dj7N79278/f1TOzxLbNqUeIuhxGz06RNL+/bmvsEiqS0mJoavvvqKKlWqEBgYyIEDB8iVKxcjR47kxIkTcQm6SHpp29Zsilm4cOJzbm5QrFj6x+Ss7E3jatSwNg4RERG5f5Z2dx84cCCdO3emZs2a1K5dm3nz5nHq1Cl69eoFwNChQzlz5gyfffYZYHZ/L1GiBJUqVeLOnTssXryY5cuXs3z5citfRqoJD0/d60Tux+LFi+natSsAuXPn5vXXX6d///7aUUEs1bYttG5tfphpb6g5Zw4sXQpdu5rJqVZexG+/ps7uIiIiGZelSXpgYCAXL15kzJgxhIeHU7lyZVatWkXx4sUBCA8PT7Bn+p07d3jzzTc5c+YMWbJkoVKlSvzwww+0bNnSqpeQqhwtCHCRwgFxEtHR0Zw+fZoSJUoA5r/L999/nw4dOtC/f39y5cplbYAi/3B3T7jNWuXKEBwMBw7AmDEwfrxVkTkHw9D2ayIiIq7A0iQdoE+fPvTp0yfJc4sWLUrw/aBBgxg0aFA6RGWNunWhSBE4cybpdek2m0G+fLd5/HHXWZsh1omOjubLL79k3LhxuLm5ceDAAdzd3fHx8WHPnj3YbImbdIk4E19fcza9XTuYPBnatMncyemJE3D5Mnh5mR9giIiISMakjmNOxN0dZswwb/87P7J/36PHfnUwlgcSHR3Np59+SoUKFejSpQtHjx7l77//5vDhw3HXKEGXjKJtW3j2WbPxZteucNdmHpmOfRb9oYfMRF1EREQyJiXpTia5BklFisBXX8VQu7YWpMv9iYqKYuHChQQEBNC1a1f++OMP8uXLx8SJEzl58iQVK1a0OkSR+/LBB1CggFn2Pnas1dFYx74eXU3jREREMjbLy90lsaQaJNWtC7GxBqtWWR2dZFSbN2+me/fugLkF4ltvvUWfPn3Inj27xZGJPJi7y94nTYJnnsmcZe9ajy4iIuIalKQ7qX83SAKIjbUkFMmgoqKi2Lt3LzX+mVarX78+bdq0oXbt2vTu3VvJubiUtm0hMBCWLIFu3cxZ5czU7d0wNJMuIiLiKlTuLuJi7ty5w5o1a6hYsSINGzbk0qVLgLnOfMWKFbz11ltK0MUlzZoF+fPD/v2Zr+z92DG4etX8YKJSJaujERERkQehJF3ERdy5c4e5c+dSsWJFZs+ezZ9//knWrFk5dOiQ1aGJpAt72TuYZe/28u/MQE3jREREXIeSdJEMLjIykjlz5lCmTBl69erFqVOnyJMnD++99x7Hjx+nTp06Vocokm7atTPL3jNbt3d7qbvWo4uIiGR8WpMuksGdPXuW/v37Ex0djb+/P2+99RaFCxemTZs2eHp6Wh2eSLqbNQt++SW+7H3cOKsjSntqGiciIuI6NJMuksFERESw6q42/yVLlmTQoEF88MEHHD9+nL59++KdmTpmifxLZit7j42Nf41qGiciIpLxKUkXySBu377NzJkzKV26NE8++ST79++POzd+/Hj69u2Lj4+PhRGKOI/MVPZ+7BhcuwY+PlCxotXRiIiIyINSki7i5G7fvs306dMpXbo0r732GmfPnqVo0aKEh4dbHZqIU/vgg/hu765c8m5fj161KmiFi4iISManJF3ESUVERDBt2jRKlizJ66+/Tnh4OMWKFeOjjz7i6NGjNGnSxOoQRZxa/vzxZe8TJ7pu2bvWo4uIiLgWJekiTiomJoaJEyfy119/Ubx4cebNm8fRo0d55ZVXtOZcxEHt2kHHjvFl73fuWB1R6rPPpGs9uoiIiGtQki7iJG7evMknn3xCbGwsANmyZWPy5Ml8/PHHHDlyhJ49e+KlDZBFUmzWrPiy97FjrY4mdcXGwu+/m7c1ky4iIuIalKSLWOzGjRtMmTKFkiVL0rNnT4KCguLOdevWjZdeeknJucgDyJ8fZs82b0+cGJ/UuoKjR+H6dciSBSpUsDoaERERSQ1K0kUscv36dSZNmkTJkiUZPHgwf//9N6VLl9be5iJpoH171yx7t5e6V6sGHh6WhiIiIiKpREm6SDqLiopi4sSJlChRgqFDh3LhwgVKly7NokWLOHToEK1atbI6RBGXZC9737fPdcre1TRORETE9ShJF0lnHh4eLF++nEuXLlG2bFk+/fRTDh06RJcuXfDQVJhImnHFsnc1jRMREXE9StJF0tjVq1eZNGkS165dA8BmszFlyhQ+//xzQkNDefHFF5Wci6QTVyp7j4mB3bvN25pJFxERcR3KDETSyJUrV5g5cybTpk3jypUrGIbB0KFDAWjUqJHF0YlkXrNmwfr1Ztn7uHEwZozVEd2fI0fgxg3ImhUCAqyORkRERFKLZtJFUtmVK1cYNWoUJUqUYOTIkVy5coWKFStSsWJFq0MTERKWvU+YkHHL3u2l7tWrg7u7tbGIiIhI6lGSLpJKDMNgzJgxlChRgtGjR3P16lUqVarEkiVL2LdvH61bt7Y6RBH5R/v20KFDxi57tzeN03p0ERER16IkXSSV2Gw2Dh8+zNWrV6lcuTJLly5l7969dOzYETc3/VMTcTYffgi+vvFl7xmNfSZd69FFRERcizIHkft08eJFhg8fzpEjR+KOjRw5kmXLlrFnzx46dOig5FzEiWXksve7m8ZpJl1ERMS1KIMQSaELFy4wdOhQSpQowYQJExh31xRcuXLlaNeunZJzkQyiQ4f4svdu3TJO2fuhQ3DrFmTLBuXLWx2NiIiIpCZlEiIO+vvvvxk8eDAlSpRg0qRJ3Lhxg2rVqtGuXTurQxORBzBrlln2vndvxil7t69Hf/hhNY0TERFxNUrSRRwwfvx4SpQowZQpU7h58ybVq1cnKCiI33//XQ3hRDK4AgUyXtm7fT26St1FRERcj5J0EQfExsZy69YtatSowXfffceuXbto3bo1NpvN6tBEJBVktLJ3+0y6msaJiIi4HiXpIv9y7tw53njjDdasWRN3rH///qxcuZLffvuNVq1aKTkXcUF3l72PH291NMmLjlbTOBEREVemJF3kH+Hh4bz++uuULFmSqVOn8s4772AYBgC5cuXiqaeeUnIu4sL+XfZuT4SdzcGDcPs2ZM8O5cpZHY2IiIikNiXpkumdPXuWAQMGUKpUKaZPn05ERAS1a9dmzJgxVocmIumsQwdo396cre7a1TnL3u9uGqeNJERERFyP/nuXTG3q1KmUKlWKGTNmEBERQZ06dVizZg2bN2+mWbNmmjkXyYQ+/NC5y97tTeO0Hl1ERMQ1KUmXTK1IkSJERkby+OOPs3btWn799VeaNGmi5FwkEytQwEzUwTnL3tU0TkRExLUpSZdMIywsjD59+jBr1qy4Y+3bt2fjxo1s3LiRJ554Qsm5iADQsaNzlr1HR0NIiHlbTeNERERck5J0cXmnTp2id+/elC5dmjlz5jBu3DgiIiIAcHNzo27dukrORSQRZyx7Dw2FiAjImRPKlLE6GhEREUkLStLFZZ08eZJXXnmFMmXK8NFHHxEVFUWDBg346quv8PHxsTo8EXFyzlj2bl+PrqZxIiIirkv/xYtLmjdvHmXLlmXevHlERUXRqFEjNmzYwPr162nQoIHV4YlIBuFsZe9ajy4iIuL6lKSLy7DvaQ7w6KOPEh0dTePGjdm4cSPr1q2jXr16FkYnIhnV3WXvEyZYG4t9Jl3r0UVERFyXknTJ8I4dO0b37t3p169f3LGqVasSGhrKzz//TN26dS2MTkQyurvL3sePj2/clt6iomDPHvO2ZtJFRERcl5J0ybD++OMPunXrRvny5Vm4cCHz5s3j/PnzcecrVKhgYXQi4ko6dIB27awtez9wACIjIVcuKF06/Z9fRERE0oeSdMlwjh49SpcuXQgICGDRokXExMTQvHlzNm7cSIECBawOT0RckM0Gs2dDvnzmbLYVZe93l7prQwoRERHXpSRdMpSvv/6agIAAPvvsM2JiYmjZsiXbtm3jxx9/pFatWlaHJyIuzOqydzWNExERyRyUpIvTi4qKirvdsGFDsmbNypNPPsn27dv54YcfePTRRy2MTkQyk44drSt7V9M4ERGRzEFJujitgwcP8vzzz9OsWbO4Y76+vhw9epTvv/+eRx55xMLoRCQzstnM2fT0Lnu/c8fsLg+aSRcREXF1StLF6YSGhvLcc89RqVIlvvzyS9avX8++ffvizhcsWNDC6EQks/PzS/+y9/37zUQ9Tx4oWTLtn09ERESsoyRdnMb+/fsJDAykcuXKfPXVVxiGQZs2bdi9ezdVqlSxOjwRkTjpXfZuX4+upnEiIiKuT0m6OIXg4GCqVKnC0qVLMQyDdu3aERISwooVK6hWrZrV4YmIJPDvsveJE9P2+bQeXUREJPNQki6WuXbtWtztxx9/nHLlytG+fXv27NnDsmXLqFq1qoXRiYjc291l7+PGpW3Zuz1J13p0ERER16ckXdJdSEgIbdu2pUqVKkRGRgLg4eHB77//ztdff81DDz1kcYQiIo7p2BHato0ve79rM4pUExkJ9rYcmkkXERFxfUrSJd38/vvvPPPMM1SvXp1vvvmGsLAwNm7cGHc+W7ZsFkYnIpJyNhvMnp223d737TOT/7x5oUSJ1H98ERERcS5K0iXN7dq1i6effpoaNWrw7bffYrPZeO6559i/fz9NmjSxOjwRkQfi5wezZpm3x40zk/XUZG8aV7OmmsaJiIhkBkrSJU0dOXKEmjVrsnLlStzc3Hj++ecJDQ3lyy+/pGLFilaHJyKSKgID067sXU3jREREMhcl6ZLqzpw5E3e7XLlyPPnkk7zwwguEhoayePFiAgICLIxORCT13V32HhKSumXvd8+ki4iIiOtTki6pZvv27bRs2ZIyZcoQHh4ed/zbb7/l888/p3z58hZGJyKSttKi7D0iQk3jREREMhsl6fLAtm7dSvPmzalVqxY//vgjUVFRrF+/Pu68u7u7hdGJiKSfwEBo0yb1yt737jUfy9cXihVLlRBFRETEySlJl/u2efNmmjZtSp06dfjpp59wd3ene/fuHD58mE6dOlkdnohIurPZYM6c+LL3iRMf7PHspe41aqhpnIiISGahJF3uy6VLl3jiiSdYu3YtHh4e9OjRgyNHjjB//nxKly5tdXgiIpa5u+x97NgHK3u3N43TenQREZHMQ0m6OGzPXb9p5s2bl379+tGzZ0+OHDnCJ598QqlSpSyMTkTEeaRW2buaxomIiGQ+StLlPwUHB9OwYUOqVavGtm3b4o5PnjyZefPmUbJkSQujExFxPvay97x577/s/fZt2L/fvK2mcSIiIpmHknRJkmEYrF+/nvr169OwYUOCg4Px9PRk9+7dcdfYtEBSRCRZD1r2vncvxMRAgQJQpEjqxyciIiLOyfIkffbs2ZQsWRIfHx9q1KjBpk2bHLrf5s2b8fDwoFq1amkbYCZjGAbr1q2jfv36NGrUiI0bN+Ll5UWfPn04duwYvXv3tjpEEZEM49ln48veu3VLWdm7fT26msaJiIhkLpYm6UuWLGHAgAEMHz6c3bt3U7duXVq0aMGpU6fueb+rV6/y4osv0rhx43SKNPOIjo6me/fubNq0CS8vL1599VWOHTvGhx9+SNGiRa0OT0QkQ7HZYPZss+x99+6Ulb1rPbqIiEjmZGmSPnXqVHr06MFLL71EhQoVmD59OkWLFmXOnDn3vN8rr7xCp06dqF27djpF6roMw+CXX34h6p/pHU9PT0aOHEm/fv04fvw4s2bNoojqLEVE7lvBgvdX9n73TLqIiIhkHh5WPfGdO3fYtWsXQ4YMSXC8adOmbNmyJdn7LVy4kGPHjrF48WLGjRv3n88TGRlJZGRk3PfXrl0DICoqKi4xzSjs8aZG3IZhsGbNGsaNG8f27dv55JNPePHFFwHo3LkznTt3TrXnkvSVmuNEXJfGSfpq1w6eftqd775zo2tXg82bo/H0TP76W7fgwAEPwEbVqlH33R0+NWisiCM0TsQRGifiCFcdJyl5PZYl6RcuXCAmJgY/P78Ex/38/Dh37lyS9zl69ChDhgxh06ZNeHg4FvrEiRMZPXp0ouNr1qwha9asKQ/cCaxdu/a+72sYBr///jtLlizhyJEjAHh5ebFp0yZ8fX1TK0RxAg8yTiTz0DhJP23aeLN+fSNCQrx46aU/CAw8kuy1hw7lITa2HrlzRxAS8tMD7bWeWjRWxBEaJ+IIjRNxhKuNk1u3bjl8rWVJut2/O4QbhpFk1/CYmBg6derE6NGjKVeunMOPP3ToUAYOHBj3/bVr1yhatChNmzYlZ86c9x+4BaKioli7di1NmjTB815TMEkwDIMff/yR8ePHs/OfGsosWbLw8ssvM3DgQPz9/dMiZLHAg4wTyTw0Tqzh7m7jxRdh2bIA3nijDA89lPR1J06Yq9Hq1PHiySdbpmOEiWmsiCM0TsQRGifiCFcdJ/aKbkdYlqT7+vri7u6eaNb8/PnziWbXAa5fv87OnTvZvXs3ffv2BSA2NhbDMPDw8GDNmjU0atQo0f28vb3x9vZOdNzT0zPD/tDvN/Zp06axc+dOsmTJQp8+fXjrrbeS/LsW15CRx7ikH42T9PXCC7BiBQQF2ejZ05Pt20my7D0kxPzz//7PDU9PyzdiATRWxDEaJ+IIjRNxhKuNk5S8Fsv+5/fy8qJGjRqJyhjWrl1LnTp1El2fM2dO9u3bR0hISNxXr169KF++PCEhITz66KPpFXqGYBgG3333HRcuXIg7NmbMGN58801OnDjBe++9pwRdRCSd2WwwZ058t/dJk5K+Tk3jREREMi9LP54fOHAgn3zyCQsWLODgwYO8/vrrnDp1il69egFmqbq9mZmbmxuVK1dO8FWgQAF8fHyoXLky2bJls/KlOA3DMAgKCqJGjRq0bt2a999/P+5cvXr1ePfdd5Wci4hYqGBB+OAD8/bYsbB3b8LzN2/CwYPmbSXpIiIimY+la9IDAwO5ePEiY8aMITw8nMqVK7Nq1SqKFy8OQHh4+H/umS6m2NhYgoKCGDNmDHv+6TCUPXt2smfPbnFkIiLyb889B19/DUFB0LUrCcreQ0IgNhb8/aFQIQuDFBEREUtYvtCtT58+nDx5ksjISHbt2kW9evXizi1atIjg4OBk7ztq1ChC7Av3MrGgoCCqV69Ou3bt2LNnDzly5GDYsGGcPHmS4cOHWx2eiIj8y73K3nftMv+sWdOa2ERERMRalifp8uBWr17N3r17yZEjB2+//TYnT55k/Pjx5MuXz+rQREQkGcmVvWs9uoiISOZm+RZskjIxMTEsXbqUhx56iCpVqgDm2v0CBQowYMAA8ubNa3GEIiLiqOeeg6VL4dtvoUsXePddWLfOPFe9urWxiYiIiDWUpGcQMTExLFmyhKFDh3L69GmeeeYZvvnmGwCKFy/OmDFjLI5QRERSymaDjz4yE/OQEGjSJP5cr14QHQ1t21oWnoiIiFhA5e5OLiYmhi+//JLKlSvTuXNnTp8+Te7cualevTqGYVgdnoiIPKAtW+DGjcTHz52D9u3NfdVFREQk89BMuhMLCgpiyJAhHD58GIDcuXPTokULZs6cia+vr8XRiYjIg4qJgddeS/qcYZgz7QMGQOvW4O6erqGJiIiIRTST7sROnjzJ4cOHyZMnD2PHjuXo0aMEBgaSK1cuq0MTEZFUsGkTnD6d/HnDgLAw8zoRERHJHDST7sReeeUVoqOjefnll8mZMydRUVFWhyQiIqkoPDx1rxMREZGMT0m6E8uSJQtvvvmm1WGIiEga8fdP3etEREQk41O5u4iIiEXq1oUiRcy150mx2aBoUfM6ERERyRyUpIuIiFjE3R1mzDBv/ztRt38/fbqaxomIiGQmStJFREQs1LYtLFsGhQsnPF6kiHlc+6SLiIhkLlqTLiIiYrG2bc1t1jZtMpvE+fubJe6aQRcREcl8lKSLiIg4AXd3aNDA6ihERETEaip3FxEREREREXESStJFREREREREnISSdBEREREREREnoSRdRERERERExEkoSRcRERERERFxEkrSRURERERERJyEknQRERERERERJ6EkXURERERERMRJKEkXERERERERcRJK0kVERERERESchJJ0ERERERERESehJF1ERERERETESShJFxEREREREXESHlYHkN4MwwDg2rVrFkeSclFRUdy6dYtr167h6elpdTjipDROxBEaJ+IojRVxhMaJOELjRBzhquPEnn/a89F7yXRJ+vXr1wEoWrSoxZGIiIiIiIhIZnL9+nVy5cp1z2tshiOpvAuJjY3l7Nmz5MiRA5vNZnU4KXLt2jWKFi1KWFgYOXPmtDoccVIaJ+IIjRNxlMaKOELjRByhcSKOcNVxYhgG169fp1ChQri53XvVeaabSXdzc6NIkSJWh/FAcubM6VIDVtKGxok4QuNEHKWxIo7QOBFHaJyII1xxnPzXDLqdGseJiIiIiIiIOAkl6SIiIiIiIiJOQkl6BuLt7c3IkSPx9va2OhRxYhon4giNE3GUxoo4QuNEHKFxIo7QOMmEjeNEREREREREnJVm0kVERERERESchJJ0ERERERERESehJF1ERERERETESShJFxEREREREXESStKd2Pjx46lTpw5Zs2Yld+7cDt2na9eu2Gy2BF+1atVK20DFcvczVgzDYNSoURQqVIgsWbLQoEEDDhw4kLaBiqUuX75M586dyZUrF7ly5aJz585cuXLlnvfRe4rrmz17NiVLlsTHx4caNWqwadOme16/YcMGatSogY+PD6VKleKjjz5Kp0jFaikZK8HBwYneO2w2G4cOHUrHiCW9bdy4kVatWlGoUCFsNhtBQUH/eR+9p2Q+KR0nmfH9REm6E7tz5w4dOnSgd+/eKbpf8+bNCQ8Pj/tatWpVGkUozuJ+xsqUKVOYOnUqs2bN4rfffqNgwYI0adKE69evp2GkYqVOnToREhLC6tWrWb16NSEhIXTu3Pk/76f3FNe1ZMkSBgwYwPDhw9m9ezd169alRYsWnDp1KsnrT5w4QcuWLalbty67d+9m2LBh9O/fn+XLl6dz5JLeUjpW7A4fPpzg/aNs2bLpFLFY4ebNm1StWpVZs2Y5dL3eUzKnlI4Tu0z1fmKI01u4cKGRK1cuh67t0qWL0bp16zSNR5yXo2MlNjbWKFiwoDFp0qS4YxEREUauXLmMjz76KA0jFKuEhoYagLFt27a4Y1u3bjUA49ChQ8neT+8pru2RRx4xevXqleBYQECAMWTIkCSvHzRokBEQEJDg2CuvvGLUqlUrzWIU55DSsbJ+/XoDMC5fvpwO0YkzAoxvvvnmntfoPUUcGSeZ8f1EM+kuKDg4mAIFClCuXDl69uzJ+fPnrQ5JnMyJEyc4d+4cTZs2jTvm7e1N/fr12bJli4WRSVrZunUruXLl4tFHH407VqtWLXLlyvWfP3O9p7imO3fusGvXrgTvAwBNmzZNdkxs3bo10fXNmjVj586dREVFpVmsYq37GSt21atXx9/fn8aNG7N+/fq0DFMyIL2nSEpkpvcTJekupkWLFnzxxRf88ssvvP/++/z22280atSIyMhIq0MTJ3Lu3DkA/Pz8Ehz38/OLOyeu5dy5cxQoUCDR8QIFCtzzZ673FNd14cIFYmJiUvQ+cO7cuSSvj46O5sKFC2kWq1jrfsaKv78/8+bNY/ny5axYsYLy5cvTuHFjNm7cmB4hSwah9xRxRGZ8P/GwOoDMZtSoUYwePfqe1/z222/UrFnzvh4/MDAw7nblypWpWbMmxYsX54cffqBt27b39ZhijbQeKwA2my3B94ZhJDomzs3RcQKJf97w3z9zvae4vpS+DyR1fVLHxfWkZKyUL1+e8uXLx31fu3ZtwsLCeO+996hXr16axikZi95T5L9kxvcTJenprG/fvjz77LP3vKZEiRKp9nz+/v4UL16co0ePptpjSvpIy7FSsGBBwPwE29/fP+74+fPnE32iLc7N0XGyd+9e/vrrr0Tn/v777xT9zPWe4jp8fX1xd3dPNBN6r/eBggULJnm9h4cH+fLlS7NYxVr3M1aSUqtWLRYvXpza4UkGpvcUuV+u/n6iJD2d+fr64uvrm27Pd/HiRcLCwhIkYpIxpOVYKVmyJAULFmTt2rVUr14dMNccbtiwgcmTJ6fJc0racHSc1K5dm6tXr7Jjxw4eeeQRALZv387Vq1epU6eOw8+n9xTX4eXlRY0aNVi7di1t2rSJO7527Vpat26d5H1q167NypUrExxbs2YNNWvWxNPTM03jFevcz1hJyu7du/XeIQnoPUXul6u/n2hNuhM7deoUISEhnDp1ipiYGEJCQggJCeHGjRtx1wQEBPDNN98AcOPGDd588022bt3KyZMnCQ4OplWrVvj6+ib4T1VcT0rHis1mY8CAAUyYMIFvvvmG/fv307VrV7JmzUqnTp2sehmShipUqEDz5s3p2bMn27ZtY9u2bfTs2ZOnnnoqQQmZ3lMyl4EDB/LJJ5+wYMECDh48yOuvv86pU6fo1asXAEOHDuXFF1+Mu75Xr178+eefDBw4kIMHD7JgwQLmz5/Pm2++adVLkHSS0rEyffp0goKCOHr0KAcOHGDo0KEsX76cvn37WvUSJB3cuHEj7ncQMBvV2n8/Ab2niCml4yRTvp9Y2Vpe7q1Lly4GkOhr/fr1cdcAxsKFCw3DMIxbt24ZTZs2NfLnz294enoaxYoVM7p06WKcOnXKmhcg6SalY8UwzG3YRo4caRQsWNDw9vY26tWrZ+zbty/9g5d0c/HiReP55583cuTIYeTIkcN4/vnnE21noveUzOfDDz80ihcvbnh5eRkPP/ywsWHDhrhzXbp0MerXr5/g+uDgYKN69eqGl5eXUaJECWPOnDnpHLFYJSVjZfLkyUbp0qUNHx8fI0+ePMbjjz9u/PDDDxZELenJvlXWv7+6dOliGIbeU8SU0nGSGd9PbIbxT3cGEREREREREbGUyt1FREREREREnISSdBEREREREREnoSRdRERERERExEkoSRcRERERERFxEkrSRURERERERJyEknQRERERERERJ6EkXURERERERMRJKEkXERERERERcRJK0kVERCw2atQoqlWrFvd9165deeaZZ9I9jpMnT2Kz2QgJCUm3x0mt5xQREXEVStJFRESS0LVrV2w2GzabDU9PT0qVKsWbb77JzZs30/y5Z8yYwaJFixy6Nr2T3AYNGsT9vXh5eVG6dGmGDh1KZGRk3DVFixYlPDycypUrp0kMN2/eZPDgwZQqVQofHx/y589PgwYN+P7779Pk+URERNKTh9UBiIiIOKvmzZuzcOFCoqKi2LRpEy+99BI3b95kzpw5ia6NiorC09MzVZ43V65cqfI4aaVnz56MGTOGO3fu8Ntvv9GtWzcAJk6cCIC7uzsFCxZMs+fv1asXO3bsYNasWVSsWJGLFy+yZcsWLl68mGbPeefOHby8vNLs8UVEROw0ky4iIpIMb29vChYsSNGiRenUqRPPP/88QUFBQHyJ+oIFCyhVqhTe3t4YhsHVq1d5+eWXKVCgADlz5qRRo0bs2bMnweNOmjQJPz8/cuTIQY8ePYiIiEhw/t/l7rGxsUyePJkyZcrg7e1NsWLFGD9+PAAlS5YEoHr16thsNho0aBB3v4ULF1KhQgV8fHwICAhg9uzZCZ5nx44dVK9eHR8fH2rWrMnu3bsd+nvJmjUrBQsWpFixYrRr144mTZqwZs2auPP/nt2/fPkyzz//PPnz5ydLliyULVuWhQsXJvnYsbGx9OzZk3LlyvHnn38mec3KlSsZNmwYLVu2pESJEtSoUYN+/frRpUuXuGsiIyMZNGgQRYsWxdvbm7JlyzJ//vy48xs2bOCRRx7B29sbf39/hgwZQnR0dNz5Bg0a0LdvXwYOHIivry9NmjQBIDQ0lJYtW5I9e3b8/Pzo3LkzFy5ccOjvTURExBFK0kVERByUJUsWoqKi4r7/448/WLp0KcuXL49LSJ988knOnTvHqlWr2LVrFw8//DCNGzfm0qVLACxdupSRI0cyfvx4du7cib+/f6Lk+d+GDh3K5MmTeeeddwgNDeXLL7/Ez88PMBNtgJ9//pnw8HBWrFgBwMcff8zw4cMZP348Bw8eZMKECbzzzjt8+umngFky/tRTT1G+fHl27drFqFGjePPNN1P8d7Jnzx42b958zyoCe9w//vgjBw8eZM6cOfj6+ia67s6dO3Ts2JGdO3fy66+/Urx48SQfr2DBgqxatYrr168n+5wvvvgiX331FTNnzuTgwYN89NFHZM+eHYAzZ87QsmVL/u///o89e/YwZ84c5s+fz7hx4xI8xqeffoqHhwebN29m7ty5hIeHU79+fapVq8bOnTtZvXo1f/31Fx07dnTkr0pERMQxhoiIiCTSpUsXo3Xr1nHfb9++3ciXL5/RsWNHwzAMY+TIkYanp6dx/vz5uGvWrVtn5MyZ04iIiEjwWKVLlzbmzp1rGIZh1K5d2+jVq1eC848++qhRtWrVJJ/72rVrhre3t/Hxxx8nGeeJEycMwNi9e3eC40WLFjW+/PLLBMfGjh1r1K5d2zAMw5g7d66RN29e4+bNm3Hn58yZk+Rj3a1+/fqGp6enkS1bNsPLy8sADDc3N2PZsmXJxtSqVSujW7du94x/06ZNxhNPPGE89thjxpUrV5J9fsMwjA0bNhhFihQxPD09jZo1axoDBgwwfv3117jzhw8fNgBj7dq1Sd5/2LBhRvny5Y3Y2Ni4Yx9++KGRPXt2IyYmJu51VqtWLcH93nnnHaNp06YJjoWFhRmAcfjw4XvGLCIi4ijNpIuIiCTj+++/J3v27Pj4+FC7dm3q1avHBx98EHe+ePHi5M+fP+77Xbt2cePGDfLly0f27Nnjvk6cOMGxY8cAOHjwILVr107wPP/+/m4HDx4kMjKSxo0bOxz333//TVhYGD169EgQx7hx4xLEUbVqVbJmzepQHHd7/vnnCQkJYevWrXTs2JHu3bvTrl27ZK/v3bs3X331FdWqVWPQoEFs2bIl0TXPPfccN27cYM2aNf+5Jr9evXocP36cdevW0a5dOw4cOEDdunUZO3YsACEhIbi7u1O/fv0k72//Gdhstrhjjz32GDdu3OD06dNxx2rWrJngfrt27WL9+vUJ/k4DAgIA4v5eRUREHpQax4mIiCSjYcOGzJkzB09PTwoVKpSopDtbtmwJvo+NjcXf35/g4OBEj5U7d+77iiFLliwpvk9sbCxglrw/+uijCc65u7sDYBjGfcUDZmO7MmXKALB48WIqVarE/Pnz6dGjR5LXt2jRgj///JMffviBn3/+mcaNG/Pqq6/y3nvvxV3TsmVLFi9ezLZt22jUqNF/xuDp6UndunWpW7cuQ4YMYdy4cYwZM4bBgwf/59+ZYRgJEnT7MSDB8aR+vq1atWLy5MmJHtPf3/8/YxYREXGEZtJFRESSkS1bNsqUKUPx4sUd6tz+8MMPc+7cOTw8PChTpkyCL/sa7AoVKrBt27YE9/v393crW7YsWbJkYd26dUmet3ccj4mJiTvm5+dH4cKFOX78eKI47I3mKlasyJ49e7h9+7ZDcSTH09OTYcOG8fbbb3Pr1q1kr8ufPz9du3Zl8eLFTJ8+nXnz5iU437t3byZNmsTTTz/Nhg0bUhxHxYoViY6OJiIigipVqhAbG5vs41SsWJEtW7Yk+KBiy5Yt5MiRg8KFCyf7HA8//DAHDhygRIkSif5e/53Qi4iI3C8l6SIiIqnkiSeeoHbt2jzzzDP89NNPnDx5ki1btvD222+zc+dOAF577TUWLFjAggULOHLkCCNHjuTAgQPJPqaPjw+DBw9m0KBBfPbZZxw7doxt27bFdSovUKAAWbJkiWtidvXqVcDsPj9x4kRmzJjBkSNH2LdvHwsXLmTq1KkAdOrUCTc3N3r06EFoaCirVq1KMLOdEp06dcJmsyXbAG/EiBF8++23/PHHHxw4cIDvv/+eChUqJLquX79+jBs3jqeeeopff/012edr0KABc+fOZdeuXZw8eZJVq1YxbNgwGjZsSM6cOSlRogRdunShe/fuBAUFceLECYKDg1m6dCkAffr0ISwsjH79+nHo0CG+/fZbRo4cycCBA3FzS/5Xo1dffZVLly7x3HPPsWPHDo4fP86aNWvo3r17gg9JREREHoSSdBERkVRis9lYtWoV9erVo3v37pQrV45nn32WkydPxnVjDwwMZMSIEQwePJgaNWrw559/0rt373s+7jvvvMMbb7zBiBEjqFChAoGBgZw/fx4ADw8PZs6cydy5cylUqBCtW7cG4KWXXuKTTz5h0aJFVKlShfr167No0aK4mfTs2bOzcuVKQkNDqV69OsOHD0+yjNsRXl5e9O3blylTpnDjxo0kzw8dOpSHHnqIevXq4e7uzldffZXkYw0YMIDRo0fTsmXLJNeuAzRr1oxPP/2Upk2bUqFCBfr160ezZs3iknCAOXPm0L59e/r06UNAQAA9e/bk5s2bABQuXJhVq1axY8cOqlatSq9evejRowdvv/32PV9noUKF2Lx5MzExMTRr1ozKlSvz2muvkStXrnsm9yIiIilhMx5kUZqIiIiIiIiIpBp97CsiIiIiIiLiJJSki4iIiIiIiDgJJekiIiIiIiIiTkJJuoiIiIiIiIiTUJIuIiIiIiIi4iSUpIuIiIiIiIg4CSXpIiIiIiIiIk5CSbqIiIiIiIiIk1CSLiIiIiIiIuIklKSLiIiIiIiIOAkl6SIiIiIiIiJO4v8B9BL/ptXXd9AAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import ClippedAdam\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from lifelines import KaplanMeierFitter\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    \"max_epochs\": 5000,\n",
    "    \"batch_size\": 256,\n",
    "    \"initial_lr\": 1e-3,\n",
    "    \"lr_decay\": 0.1,\n",
    "    \"decay_step\": 1000,\n",
    "    \"clip_norm\": 10.0,\n",
    "    \"early_stop_patience\": 200,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"precision\": torch.float32,\n",
    "    \"log_freq\": 100,\n",
    "    \"checkpoint_freq\": 500\n",
    "}\n",
    "\n",
    "# Set up GPU if available\n",
    "if config[\"device\"] == \"cuda\":\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "\n",
    "def load_and_preprocess(path):\n",
    "    start_time = time.time()\n",
    "    data = pd.read_csv(path)\n",
    "    print(f\"Data loading time: {time.time()-start_time:.2f}s\")\n",
    "    \n",
    "    # Extract features and survival data\n",
    "    X = data.iloc[:, 1:-2].values  # Skip ID, time, event\n",
    "    time_values = data['time'].values\n",
    "    event_values = data['event'].values\n",
    "    \n",
    "    # Handle missing values and standardize\n",
    "    X = (X - np.nanmean(X, axis=0)) / (np.nanstd(X, axis=0) + 1e-8)\n",
    "    X = np.nan_to_num(X)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_tensor = torch.tensor(X, dtype=config[\"precision\"], device=config[\"device\"])\n",
    "    time_tensor = torch.tensor(time_values, dtype=config[\"precision\"], device=config[\"device\"])\n",
    "    event_tensor = torch.tensor(event_values, dtype=config[\"precision\"], device=config[\"device\"])\n",
    "    \n",
    "    # Sort by survival time\n",
    "    sort_idx = torch.argsort(time_tensor)\n",
    "    return X_tensor[sort_idx], time_tensor[sort_idx], event_tensor[sort_idx]\n",
    "\n",
    "class CoxPartialLikelihood(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-8\n",
    "        self.max_exp = 20.0\n",
    "        \n",
    "    def forward(self, X_beta, survival_time, event):\n",
    "        event_mask = event == 1\n",
    "        n_events = event_mask.sum()\n",
    "        \n",
    "        if n_events < 1:\n",
    "            return torch.tensor(0.0)\n",
    "        \n",
    "        # Numerical stability\n",
    "        X_beta = X_beta - X_beta.max()\n",
    "        exp_Xb = torch.clamp(X_beta.exp(), max=torch.exp(torch.tensor(self.max_exp)))\n",
    "        \n",
    "        # Vectorized computation\n",
    "        risk_matrix = (survival_time.unsqueeze(0) >= survival_time[event_mask].unsqueeze(1)).float()\n",
    "        sum_exp = (risk_matrix * exp_Xb.unsqueeze(0)).sum(dim=1)\n",
    "        log_sum_exp = torch.log(sum_exp + self.eps)\n",
    "        \n",
    "        return (X_beta[event_mask] - log_sum_exp).sum() / X_beta.size(0)\n",
    "\n",
    "def model(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    alpha = pyro.sample(\"alpha\", dist.Beta(1., 100.))\n",
    "    \n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        z = pyro.sample(\"z\", dist.Bernoulli(alpha))\n",
    "        tau = pyro.sample(\"tau\", dist.HalfNormal(0.05))\n",
    "        theta = pyro.sample(\"theta\", dist.Laplace(0., 1/(tau + 1e-8)))\n",
    "        beta = z * theta\n",
    "    \n",
    "    cox_likelihood = CoxPartialLikelihood()\n",
    "    log_pl = cox_likelihood(X @ beta, survival_time, event)\n",
    "    pyro.factor(\"log_pl\", log_pl)\n",
    "\n",
    "def guide(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    alpha_a = pyro.param(\"alpha_a\", torch.tensor(1.), constraint=constraints.positive)\n",
    "    alpha_b = pyro.param(\"alpha_b\", torch.tensor(100.), constraint=constraints.positive)\n",
    "    pyro.sample(\"alpha\", dist.Beta(alpha_a, alpha_b))\n",
    "    \n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        q_z = pyro.param(\"q_z\", torch.ones(p)*0.01, constraint=constraints.interval(0., 1.))\n",
    "        pyro.sample(\"z\", dist.Bernoulli(q_z))\n",
    "        \n",
    "        tau_loc = pyro.param(\"tau_loc\", torch.zeros(p))\n",
    "        tau_scale = pyro.param(\"tau_scale\", torch.ones(p)*0.01, constraint=constraints.positive)\n",
    "        pyro.sample(\"tau\", dist.LogNormal(tau_loc, tau_scale))\n",
    "        \n",
    "        theta_loc = pyro.param(\"theta_loc\", torch.zeros(p))\n",
    "        theta_scale = pyro.param(\"theta_scale\", torch.ones(p)*0.1, constraint=constraints.positive)\n",
    "        pyro.sample(\"theta\", dist.Laplace(theta_loc, theta_scale))\n",
    "\n",
    "def main():\n",
    "    # Load and prepare data\n",
    "    # Load and prepare data\n",
    "    data_path = r\"D:\\cox-model-imputation\\error-in-r-code-for-mcar\\datasets\\vb-cox\\realistic_cox_data.csv\"\n",
    "    X, survival_time, event = load_and_preprocess(data_path)\n",
    "    \n",
    "    # Create data loader\n",
    "    dataset = TensorDataset(X, survival_time, event)\n",
    "    loader = DataLoader(dataset, \n",
    "                      batch_size=config[\"batch_size\"], \n",
    "                      shuffle=True,\n",
    "                      pin_memory=config[\"device\"] == \"cuda\")\n",
    "    \n",
    "    # Initialize model\n",
    "    pyro.clear_param_store()\n",
    "    \n",
    "    optimizer = ClippedAdam({\n",
    "        \"lr\": config[\"initial_lr\"],\n",
    "        \"clip_norm\": config[\"clip_norm\"],\n",
    "        \"weight_decay\": 1e-4\n",
    "    })\n",
    "    \n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO(num_particles=1))\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "    epoch_times = []\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(config[\"max_epochs\"]):\n",
    "            epoch_start = time.time()\n",
    "            total_loss = 0.0\n",
    "            \n",
    "            for X_batch, t_batch, e_batch in loader:\n",
    "                loss = svi.step(X_batch, t_batch, e_batch)\n",
    "                total_loss += loss\n",
    "            \n",
    "            avg_loss = total_loss / len(loader)\n",
    "            losses.append(avg_loss)\n",
    "            \n",
    "            # Manually update learning rate at specific epochs\n",
    "            if epoch % config[\"decay_step\"] == 0 and epoch > 0:\n",
    "                current_lr = config[\"initial_lr\"] * (config[\"lr_decay\"] ** (epoch // config[\"decay_step\"]))\n",
    "                optimizer.set_state({'lr': current_lr})\n",
    "                print(f\"Learning rate decreased to {current_lr:.2e}\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                patience = 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= config[\"early_stop_patience\"]:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "            \n",
    "            # Logging\n",
    "            epoch_time = time.time() - epoch_start\n",
    "            epoch_times.append(epoch_time)\n",
    "            if epoch % config[\"log_freq\"] == 0:\n",
    "                print(f\"Epoch {epoch:04d} | Loss: {avg_loss:.2f} | Time: {epoch_time:.2f}s\")\n",
    "            \n",
    "            # Checkpointing\n",
    "            if epoch % config[\"checkpoint_freq\"] == 0 and epoch > 0:\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'losses': losses,\n",
    "                    'params': pyro.get_param_store().get_state()\n",
    "                }\n",
    "                torch.save(checkpoint, f\"checkpoint_epoch_{epoch}.pt\")\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTraining interrupted by user\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {total_time/3600:.2f} hours\")\n",
    "    print(f\"Average epoch time: {np.mean(epoch_times):.2f}s\")\n",
    "    \n",
    "    # Save final model\n",
    "    final_state = {\n",
    "        'params': pyro.get_param_store().get_state(),\n",
    "        'losses': losses,\n",
    "        'config': config\n",
    "    }\n",
    "    torch.save(final_state, \"final_model.pt\")\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"Training Loss (Negative ELBO)\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"training_loss.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature analysis\n",
    "    q_z = pyro.param(\"q_z\").detach().cpu().numpy()\n",
    "    theta_loc = pyro.param(\"theta_loc\").detach().cpu().numpy()\n",
    "    posterior_means = q_z * theta_loc\n",
    "    \n",
    "    print(\"\\nTop 10 Features:\")\n",
    "    top_idx = np.argsort(-q_z)[:10]\n",
    "    for i, idx in enumerate(top_idx):\n",
    "        print(f\"{i+1:2d}. Feature {idx:4d} | Prob: {q_z[idx]:0.4f} | Coef: {posterior_means[idx]:0.6f}\")\n",
    "    \n",
    "    # Predictive Performance\n",
    "    X_np = X.cpu().numpy()\n",
    "    time_np = survival_time.cpu().numpy()\n",
    "    event_np = event.cpu().numpy()\n",
    "    risk_scores = X_np @ posterior_means\n",
    "    \n",
    "    # Concordance Index\n",
    "    c_index = concordance_index(time_np, -risk_scores, event_np)\n",
    "    print(f\"\\nConcordance Index (C-Index): {c_index:.4f}\")\n",
    "    \n",
    "    # Time-Dependent ROC Curves\n",
    "    times = np.percentile(time_np[event_np == 1], [25, 50, 75])\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for t in times:\n",
    "        fpr, tpr, _ = roc_curve(event_np, risk_scores, pos_label=1)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'Time {t} (AUC = {roc_auc:.2f})')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Time-Dependent ROC Curves')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(\"time_dependent_roc.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Calibration Plots with corrected implementation\n",
    "    # Create risk groups\n",
    "    n_groups = 10\n",
    "    risk_groups = pd.qcut(risk_scores, n_groups)\n",
    "    mean_risks = pd.Series(risk_scores).groupby(risk_groups).mean()\n",
    "\n",
    "    # Calculate observed survival for each group\n",
    "    observed_survival = []\n",
    "    for group in risk_groups.unique():\n",
    "        mask = risk_groups == group\n",
    "        kmf_group = KaplanMeierFitter()\n",
    "        kmf_group.fit(time_np[mask], event_np[mask])\n",
    "        # Use median follow-up time for evaluation\n",
    "        median_time = np.median(time_np)\n",
    "        observed_survival.append(kmf_group.survival_function_at_times(median_time).iloc[0])\n",
    "\n",
    "    # Convert to numpy arrays for plotting\n",
    "    mean_risks = np.array(mean_risks)\n",
    "    observed_survival = np.array(observed_survival)\n",
    "\n",
    "    # Plot calibration\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(mean_risks, observed_survival, 'bo-', label='Calibration curve')\n",
    "    plt.plot([mean_risks.min(), mean_risks.max()],\n",
    "             [observed_survival.min(), observed_survival.max()],\n",
    "             'k--', label='Perfect calibration')\n",
    "    plt.xlabel('Predicted Risk Score')\n",
    "    plt.ylabel('Observed Survival Probability')\n",
    "    plt.title('Calibration Plot')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"calibration_plot.png\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebcd89c-89f8-418a-8c59-68ac4b336664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf23ad8c-8702-4ba1-9cd4-d2623dc63d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1140d5-fbd9-4daf-8695-d01df22b2484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67f341fc-baab-4882-b156-a446864fe154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CHIKOM~1\\ANACON~1\\envs\\vb_cox_pymc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\CHIKOM~1\\ANACON~1\\envs\\vb_cox_pymc\\lib\\site-packages\\torch\\__init__.py:955: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\tensor\\python_tensor.cpp:434.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading time: 0.24s\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected a 'cuda' device type for generator but found 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 271\u001b[0m\n\u001b[0;32m    268\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 271\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 161\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m    160\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X_batch, t_batch, e_batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m    162\u001b[0m         loss \u001b[38;5;241m=\u001b[39m svi\u001b[38;5;241m.\u001b[39mstep(X_batch, t_batch, e_batch)\n\u001b[0;32m    163\u001b[0m         epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[1;32mC:\\Users\\CHIKOM~1\\ANACON~1\\envs\\vb_cox_pymc\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mC:\\Users\\CHIKOM~1\\ANACON~1\\envs\\vb_cox_pymc\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:672\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[1;32mC:\\Users\\CHIKOM~1\\ANACON~1\\envs\\vb_cox_pymc\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:620\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\CHIKOM~1\\ANACON~1\\envs\\vb_cox_pymc\\lib\\site-packages\\torch\\utils\\data\\sampler.py:288\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[0;32m    287\u001b[0m idx_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 288\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler:\n\u001b[0;32m    289\u001b[0m     batch[idx_in_batch] \u001b[38;5;241m=\u001b[39m idx\n\u001b[0;32m    290\u001b[0m     idx_in_batch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mC:\\Users\\CHIKOM~1\\ANACON~1\\envs\\vb_cox_pymc\\lib\\site-packages\\torch\\utils\\data\\sampler.py:168\u001b[0m, in \u001b[0;36mRandomSampler.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n):\n\u001b[1;32m--> 168\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandperm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandperm(n, generator\u001b[38;5;241m=\u001b[39mgenerator)\u001b[38;5;241m.\u001b[39mtolist()[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m%\u001b[39m n]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected a 'cuda' device type for generator but found 'cpu'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from pyro.optim import ClippedAdam\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    \"max_epochs\": 5000,\n",
    "    \"batch_size\": 128,\n",
    "    \"initial_lr\": 5e-4,\n",
    "    \"lr_decay\": 0.2,\n",
    "    \"decay_step\": 500,\n",
    "    \"clip_norm\": 10.0,\n",
    "    \"early_stop_patience\": 200,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"precision\": torch.float32,\n",
    "    \"log_freq\": 100,\n",
    "    \"checkpoint_freq\": 500,\n",
    "}\n",
    "\n",
    "# Set up GPU if available\n",
    "if config[\"device\"] == \"cuda\":\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "\n",
    "def load_and_preprocess(path):\n",
    "    start_time = time.time()\n",
    "    data = pd.read_csv(path)\n",
    "    print(f\"Data loading time: {time.time()-start_time:.2f}s\")\n",
    "    \n",
    "    # Extract features and survival data\n",
    "    X = data.iloc[:, 1:-2].values  # Skip ID, time, event\n",
    "    time_values = data['time'].values\n",
    "    event_values = data['event'].values\n",
    "    \n",
    "    # Handle missing values and standardize\n",
    "    X = (X - np.nanmean(X, axis=0)) / (np.nanstd(X, axis=0) + 1e-8)\n",
    "    X = np.nan_to_num(X)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_tensor = torch.tensor(X, dtype=config[\"precision\"], device=config[\"device\"])\n",
    "    time_tensor = torch.tensor(time_values, dtype=config[\"precision\"], device=config[\"device\"])\n",
    "    event_tensor = torch.tensor(event_values, dtype=config[\"precision\"], device=config[\"device\"])\n",
    "    \n",
    "    return X_tensor, time_tensor, event_tensor, X, time_values, event_values\n",
    "\n",
    "class CoxPartialLikelihood(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-8\n",
    "        self.max_exp = 20.0\n",
    "        \n",
    "    def forward(self, X_beta, survival_time, event):\n",
    "        event_mask = event == 1\n",
    "        n_events = event_mask.sum()\n",
    "        \n",
    "        if n_events < 1:\n",
    "            return torch.tensor(0.0)\n",
    "        \n",
    "        X_beta = X_beta - X_beta.max()\n",
    "        exp_Xb = torch.clamp(X_beta.exp(), max=torch.exp(torch.tensor(self.max_exp)))\n",
    "        \n",
    "        risk_matrix = (survival_time.unsqueeze(0) >= survival_time[event_mask].unsqueeze(1)).float()\n",
    "        sum_exp = (risk_matrix * exp_Xb.unsqueeze(0)).sum(dim=1)\n",
    "        log_sum_exp = torch.log(sum_exp + self.eps)\n",
    "        \n",
    "        return (X_beta[event_mask] - log_sum_exp).sum() / X_beta.size(0)\n",
    "\n",
    "def model(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    alpha = pyro.sample(\"alpha\", dist.Beta(0.5, 200.))\n",
    "    \n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        z = pyro.sample(\"z\", dist.Bernoulli(alpha))\n",
    "        tau = pyro.sample(\"tau\", dist.HalfNormal(0.01))\n",
    "        theta = pyro.sample(\"theta\", dist.Laplace(0., 1/(tau + 1e-8)))\n",
    "        beta = z * theta\n",
    "    \n",
    "    cox_likelihood = CoxPartialLikelihood()\n",
    "    log_pl = cox_likelihood(X @ beta, survival_time, event)\n",
    "    pyro.factor(\"log_pl\", log_pl)\n",
    "    return beta\n",
    "\n",
    "def guide(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    alpha_a = pyro.param(\"alpha_a\", torch.tensor(0.5), constraint=constraints.positive)\n",
    "    alpha_b = pyro.param(\"alpha_b\", torch.tensor(200.), constraint=constraints.positive)\n",
    "    pyro.sample(\"alpha\", dist.Beta(alpha_a, alpha_b))\n",
    "    \n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        q_z = pyro.param(\"q_z\", torch.ones(p)*0.01, constraint=constraints.interval(0., 1.))\n",
    "        pyro.sample(\"z\", dist.Bernoulli(q_z))\n",
    "        \n",
    "        tau_loc = pyro.param(\"tau_loc\", torch.zeros(p))\n",
    "        tau_scale = pyro.param(\"tau_scale\", torch.ones(p)*0.01, constraint=constraints.positive)\n",
    "        pyro.sample(\"tau\", dist.LogNormal(tau_loc, tau_scale))\n",
    "        \n",
    "        theta_loc = pyro.param(\"theta_loc\", torch.zeros(p))\n",
    "        theta_scale = pyro.param(\"theta_scale\", torch.ones(p)*0.1, constraint=constraints.positive)\n",
    "        pyro.sample(\"theta\", dist.Laplace(theta_loc, theta_scale))\n",
    "\n",
    "def calculate_time_dependent_auc(times, risk_scores, survival_time, event):\n",
    "    aucs = []\n",
    "    for t in times:\n",
    "        status = (survival_time <= t) & (event == 1)\n",
    "        if sum(status) > 0:\n",
    "            fpr, tpr, _ = roc_curve(status, risk_scores)\n",
    "            aucs.append(auc(fpr, tpr))\n",
    "    return np.array(aucs)\n",
    "\n",
    "def main():\n",
    "    # Create results directory\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    results_dir = f\"results_{timestamp}\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    data_path = r\"D:\\cox-model-imputation\\error-in-r-code-for-mcar\\datasets\\vb-cox\\realistic_cox_data.csv\"\n",
    "    X_tensor, time_tensor, event_tensor, X_np, time_np, event_np = load_and_preprocess(data_path)\n",
    "    \n",
    "    # Create data loader\n",
    "    dataset = TensorDataset(X_tensor, time_tensor, event_tensor)\n",
    "    loader = DataLoader(dataset, \n",
    "                      batch_size=config[\"batch_size\"], \n",
    "                      shuffle=True,\n",
    "                      pin_memory=config[\"device\"] == \"cuda\")\n",
    "    \n",
    "    # Initialize model\n",
    "    pyro.clear_param_store()\n",
    "    optimizer = ClippedAdam({\n",
    "        \"lr\": config[\"initial_lr\"],\n",
    "        \"clip_norm\": config[\"clip_norm\"],\n",
    "        \"weight_decay\": 1e-4\n",
    "    })\n",
    "    \n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO(num_particles=1))\n",
    "    \n",
    "    # Training loop\n",
    "    best_loss = float('inf')\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "    patience = 0\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(config[\"max_epochs\"]):\n",
    "            epoch_loss = 0.0\n",
    "            for X_batch, t_batch, e_batch in loader:\n",
    "                loss = svi.step(X_batch, t_batch, e_batch)\n",
    "                epoch_loss += loss\n",
    "            \n",
    "            avg_loss = epoch_loss / len(loader)\n",
    "            losses.append(avg_loss)\n",
    "            \n",
    "            if epoch % config[\"log_freq\"] == 0:\n",
    "                print(f\"Epoch {epoch:04d} | Loss: {avg_loss:.2f}\")\n",
    "            \n",
    "            # Learning rate decay\n",
    "            if epoch % config[\"decay_step\"] == 0 and epoch > 0:\n",
    "                current_lr = config[\"initial_lr\"] * (config[\"lr_decay\"] ** (epoch // config[\"decay_step\"]))\n",
    "                optimizer.set_state({'lr': current_lr})\n",
    "                print(f\"Learning rate decreased to {current_lr:.2e}\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                patience = 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= config[\"early_stop_patience\"]:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "            \n",
    "            # Save checkpoint\n",
    "            if epoch % config[\"checkpoint_freq\"] == 0:\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state': pyro.get_param_store().get_state(),\n",
    "                    'loss': avg_loss,\n",
    "                }\n",
    "                torch.save(checkpoint, os.path.join(results_dir, f'checkpoint_epoch_{epoch}.pt'))\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTraining interrupted by user\")\n",
    "    \n",
    "    # Save final model state\n",
    "    final_state = {\n",
    "        'model_state': pyro.get_param_store().get_state(),\n",
    "        'losses': losses,\n",
    "    }\n",
    "    torch.save(final_state, os.path.join(results_dir, 'final_model.pt'))\n",
    "    \n",
    "    # Analysis and visualization\n",
    "    q_z = pyro.param(\"q_z\").detach().cpu().numpy()\n",
    "    theta_loc = pyro.param(\"theta_loc\").detach().cpu().numpy()\n",
    "    posterior_means = q_z * theta_loc\n",
    "    \n",
    "    # Calculate risk scores\n",
    "    risk_scores = X_np @ posterior_means\n",
    "    \n",
    "    # Compute C-index\n",
    "    c_index = concordance_index(time_np, -risk_scores, event_np)\n",
    "    print(f\"\\nConcordance Index: {c_index:.4f}\")\n",
    "    \n",
    "    # Plot loss curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(losses)\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig(os.path.join(results_dir, 'training_loss.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Feature importance\n",
    "    importance = np.abs(posterior_means)\n",
    "    top_features = np.argsort(-importance)[:20]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(20), importance[top_features])\n",
    "    plt.title('Top 20 Feature Importances')\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Absolute Coefficient Value')\n",
    "    plt.savefig(os.path.join(results_dir, 'feature_importance.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Time-dependent ROC curves\n",
    "    times = np.percentile(time_np[event_np == 1], [25, 50, 75])\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for t in times:\n",
    "        status = (time_np <= t) & (event_np == 1)\n",
    "        if sum(status) > 0:\n",
    "            fpr, tpr, _ = roc_curve(status, risk_scores)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f'Time {t:.1f} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Time-Dependent ROC Curves')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(results_dir, 'time_dependent_roc.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Save results summary\n",
    "    results = {\n",
    "        'c_index': c_index,\n",
    "        'final_loss': losses[-1],\n",
    "        'training_time': time.time() - start_time,\n",
    "        'n_epochs': len(losses),\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(results_dir, 'results_summary.txt'), 'w') as f:\n",
    "        for key, value in results.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab2e4c-761e-40a1-8f39-d214c3d8aa2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "525867b0-d02d-4089-92cf-47412c9ef3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to see if C-index omproves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e02ca2-fac9-4d32-aa8d-923ac84315be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf4878-d768-4207-8348-8f52f380dfca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80da6768-0c26-4534-8b90-91dcb02e3fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce766f-74da-43b6-8c9f-9dfe7b4fdeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764b46b-5c3b-485c-81b9-76831c01b677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66fde3c3-fed3-44ef-a863-326d61714d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADDED VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f55e1-564c-4696-8b8e-fe31b85fb5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf47aa-c46e-44ac-bc02-55137a40eb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dec243-0126-4cce-9dec-b6b92865b654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9476c0f7-e681-4d4b-84d2-65d5816b24cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd4ee4-b185-4bb0-9291-0cce655cb7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4037897-7560-448d-a73c-377535fba5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADDED VISUALIZATIONS AND CONVERGENCE PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c40573ee-b9b9-4683-a1fb-95d7d70420e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU Information:\n",
      "PyTorch version: 2.4.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "Device: NVIDIA GeForce GTX 1650\n",
      "Device count: 1\n",
      "Current device: 0\n",
      "\n",
      "GPU Memory Usage:\n",
      "Allocated: 0.02 MB\n",
      "Cached: 22.00 MB\n",
      "Loading data from: D:\\cox-model-imputation\\error-in-r-code-for-mcar\\datasets\\vb-cox\\realistic_cox_data.csv\n",
      "Data shape: (800, 1003)\n",
      "Data loading time: 0.25s\n",
      "Data loaded on: cuda:0\n",
      "Number of features: 1000\n",
      "Number of samples: 800\n",
      "Event rate: 58.88%\n",
      "\n",
      "Training fold 1/5\n",
      "\n",
      "GPU Memory Status:\n",
      "Allocated: 22.93 MB\n",
      "Cached: 42.00 MB\n",
      "Error during training: 'global_scale_loc'\n",
      "Error during model training: 'global_scale_loc'\n",
      "\n",
      "Error in main execution: 'global_scale_loc'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from pyro.optim import ClippedAdam\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    # Training parameters\n",
    "    \"max_epochs\": 5000,\n",
    "    \"batch_size\": 128,\n",
    "    \"initial_lr\": 5e-4,\n",
    "    \"lr_decay\": 0.2,\n",
    "    \"decay_step\": 500,\n",
    "    \"clip_norm\": 10.0,\n",
    "    \"early_stop_patience\": 200,\n",
    "    \n",
    "    # Device and precision\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"precision\": torch.float32,\n",
    "    \"pin_memory\": False if torch.cuda.is_available() else True,  # Only pin if using CPU\n",
    "    \"num_workers\": 0,  # Set to 0 for Windows\n",
    "    \"cuda_deterministic\": False,\n",
    "    \n",
    "    # Model parameters\n",
    "    \"elbo_particles\": 10,\n",
    "    \"warmup_epochs\": 100,\n",
    "    \"n_folds\": 5,\n",
    "    \n",
    "    # Logging and checkpointing\n",
    "    \"log_freq\": 100,\n",
    "    \"checkpoint_freq\": 500,\n",
    "    \n",
    "    # Paths\n",
    "    \"data_path\": r\"D:\\cox-model-imputation\\error-in-r-code-for-mcar\\datasets\\vb-cox\\realistic_cox_data.csv\",\n",
    "    \"results_dir\": f\"results_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "}\n",
    "\n",
    "def setup_gpu():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        \n",
    "        # Set the default generator to CUDA and set seeds for reproducibility\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "        \n",
    "        print(\"\\nGPU Information:\")\n",
    "        print(f\"PyTorch version: {torch.__version__}\")\n",
    "        print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "        \n",
    "        print(\"\\nGPU Memory Usage:\")\n",
    "        print(f\"Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")\n",
    "        print(f\"Cached: {torch.cuda.memory_reserved(0)/1024**2:.2f} MB\")\n",
    "        \n",
    "        # Set for reproducibility\n",
    "        torch.backends.cudnn.deterministic = config[\"cuda_deterministic\"]\n",
    "        torch.backends.cudnn.benchmark = not config[\"cuda_deterministic\"]\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(\"\\nNo GPU available, using CPU\")\n",
    "        return False\n",
    "\n",
    "def memory_status():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"\\nGPU Memory Status:\")\n",
    "        print(f\"Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")\n",
    "        print(f\"Cached: {torch.cuda.memory_reserved(0)/1024**2:.2f} MB\")\n",
    "\n",
    "def load_and_preprocess(path, config):\n",
    "    print(f\"Loading data from: {path}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(path)\n",
    "        print(f\"Data shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Extract features and survival data\n",
    "    X = data.iloc[:, 1:-2].values  # Skip ID, time, event\n",
    "    time_values = data['time'].values\n",
    "    event_values = data['event'].values\n",
    "    \n",
    "    # Handle missing values and standardize\n",
    "    X = (X - np.nanmean(X, axis=0)) / (np.nanstd(X, axis=0) + 1e-8)\n",
    "    X = np.nan_to_num(X)\n",
    "    \n",
    "    # Convert to tensors and move to GPU if available\n",
    "    X_tensor = torch.tensor(X, dtype=config[\"precision\"]).to(config[\"device\"])\n",
    "    time_tensor = torch.tensor(time_values, dtype=config[\"precision\"]).to(config[\"device\"])\n",
    "    event_tensor = torch.tensor(event_values, dtype=config[\"precision\"]).to(config[\"device\"])\n",
    "    \n",
    "    print(f\"Data loading time: {time.time()-start_time:.2f}s\")\n",
    "    print(f\"Data loaded on: {X_tensor.device}\")\n",
    "    print(f\"Number of features: {X_tensor.shape[1]}\")\n",
    "    print(f\"Number of samples: {X_tensor.shape[0]}\")\n",
    "    print(f\"Event rate: {event_tensor.mean().item():.2%}\")\n",
    "    \n",
    "    return X_tensor, time_tensor, event_tensor\n",
    "\n",
    "class CoxPartialLikelihood(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-8\n",
    "        self.max_exp = 20.0\n",
    "        \n",
    "    def forward(self, X_beta, survival_time, event):\n",
    "        event_mask = event == 1\n",
    "        n_events = event_mask.sum()\n",
    "        \n",
    "        if n_events < 1:\n",
    "            return torch.tensor(0.0, device=X_beta.device)\n",
    "        \n",
    "        X_beta = X_beta - X_beta.max()\n",
    "        exp_Xb = torch.clamp(X_beta.exp(), max=torch.exp(torch.tensor(self.max_exp, device=X_beta.device)))\n",
    "        \n",
    "        risk_matrix = (survival_time.unsqueeze(0) >= survival_time[event_mask].unsqueeze(1)).float()\n",
    "        sum_exp = (risk_matrix * exp_Xb.unsqueeze(0)).sum(dim=1)\n",
    "        log_sum_exp = torch.log(sum_exp + self.eps)\n",
    "        \n",
    "        return (X_beta[event_mask] - log_sum_exp).sum() / X_beta.size(0)\n",
    "\n",
    "def model(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    device = X.device\n",
    "    \n",
    "    # Global shrinkage parameter\n",
    "    global_scale = pyro.sample(\"global_scale\", \n",
    "                             dist.HalfCauchy(torch.tensor(1.0, device=device)))\n",
    "    \n",
    "    # Use a single Normal distribution instead of a mixture for simplicity\n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        # Local shrinkage parameters\n",
    "        local_scale = pyro.sample(\"local_scale\", \n",
    "                                dist.HalfCauchy(torch.tensor(1.0, device=device)))\n",
    "        \n",
    "        # Use a single shrinkage prior\n",
    "        scale = global_scale * local_scale\n",
    "        beta = pyro.sample(\"beta\", dist.Normal(torch.zeros(p, device=device), scale))\n",
    "    \n",
    "    # Compute likelihood\n",
    "    cox_likelihood = CoxPartialLikelihood()\n",
    "    log_pl = cox_likelihood(X @ beta, survival_time, event)\n",
    "    pyro.factor(\"log_pl\", log_pl)\n",
    "    \n",
    "    return beta\n",
    "\n",
    "def guide(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    device = X.device\n",
    "    \n",
    "    # Global scale parameter\n",
    "    global_scale_loc = pyro.param(\"global_scale_loc\", \n",
    "                                torch.tensor(1.0, device=device),\n",
    "                                constraint=constraints.positive)\n",
    "    global_scale_scale = pyro.param(\"global_scale_scale\",\n",
    "                                  torch.tensor(0.1, device=device),\n",
    "                                  constraint=constraints.positive)\n",
    "    \n",
    "    pyro.sample(\"global_scale\",\n",
    "               dist.LogNormal(global_scale_loc.log(), global_scale_scale))\n",
    "    \n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        # Local scale parameters\n",
    "        local_scale_loc = pyro.param(\"local_scale_loc\",\n",
    "                                   torch.ones(p, device=device),\n",
    "                                   constraint=constraints.positive)\n",
    "        local_scale_scale = pyro.param(\"local_scale_scale\",\n",
    "                                     torch.ones(p, device=device) * 0.1,\n",
    "                                     constraint=constraints.positive)\n",
    "        \n",
    "        pyro.sample(\"local_scale\",\n",
    "                   dist.LogNormal(local_scale_loc.log(), local_scale_scale))\n",
    "        \n",
    "        # Beta parameters\n",
    "        beta_loc = pyro.param(\"beta_loc\", torch.zeros(p, device=device))\n",
    "        beta_scale = pyro.param(\"beta_scale\",\n",
    "                              torch.ones(p, device=device) * 0.1,\n",
    "                              constraint=constraints.positive)\n",
    "        \n",
    "        pyro.sample(\"beta\", dist.Normal(beta_loc, beta_scale))\n",
    "\n",
    "class BayesianCoxModel:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = config[\"device\"]\n",
    "        pyro.clear_param_store()\n",
    "\n",
    "    def train(self, train_loader, val_loader=None):\n",
    "        optimizer = ClippedAdam({\n",
    "            \"lr\": self.config[\"initial_lr\"],\n",
    "            \"clip_norm\": self.config[\"clip_norm\"],\n",
    "            \"weight_decay\": 1e-4\n",
    "        })\n",
    "        \n",
    "        svi = SVI(model, guide, optimizer, \n",
    "                 loss=Trace_ELBO(num_particles=self.config[\"elbo_particles\"]))\n",
    "        \n",
    "        best_loss = float('inf')\n",
    "        losses = []\n",
    "        val_losses = []\n",
    "        patience = 0\n",
    "        param_trajectories = {name: [] for name in pyro.get_param_store().keys()}\n",
    "        \n",
    "        try:\n",
    "            for epoch in range(self.config[\"max_epochs\"]):\n",
    "                epoch_loss = 0.0\n",
    "                for batch_idx, (X_batch, t_batch, e_batch) in enumerate(train_loader):\n",
    "                    # Ensure data is on the correct device\n",
    "                    X_batch = X_batch.to(self.device)\n",
    "                    t_batch = t_batch.to(self.device)\n",
    "                    e_batch = e_batch.to(self.device)\n",
    "                    \n",
    "                    loss = svi.step(X_batch, t_batch, e_batch)\n",
    "                    epoch_loss += loss\n",
    "                    \n",
    "                    if batch_idx % 10 == 0:\n",
    "                        memory_status()\n",
    "                \n",
    "                avg_loss = epoch_loss / len(train_loader)\n",
    "                losses.append(avg_loss)\n",
    "                \n",
    "                # Store parameter trajectories\n",
    "                for name, param in pyro.get_param_store().items():\n",
    "                    param_trajectories[name].append(param.detach().cpu().numpy())\n",
    "                \n",
    "                # Validation loss\n",
    "                if val_loader is not None:\n",
    "                    val_loss = self.evaluate(svi, val_loader)\n",
    "                    val_losses.append(val_loss)\n",
    "                    \n",
    "                    if val_loss < best_loss:\n",
    "                        best_loss = val_loss\n",
    "                        patience = 0\n",
    "                        # Save best model parameters\n",
    "                        self.save_checkpoint(epoch, val_loss)\n",
    "                    else:\n",
    "                        patience += 1\n",
    "                        \n",
    "                    if patience >= self.config[\"early_stop_patience\"]:\n",
    "                        print(f\"Early stopping at epoch {epoch}\")\n",
    "                        break\n",
    "                \n",
    "                # Learning rate decay\n",
    "                if epoch % self.config[\"decay_step\"] == 0 and epoch > 0:\n",
    "                    current_lr = self.config[\"initial_lr\"] * \\\n",
    "                               (self.config[\"lr_decay\"] ** (epoch // self.config[\"decay_step\"]))\n",
    "                    optimizer.set_state({'lr': current_lr})\n",
    "                    \n",
    "                if epoch % self.config[\"log_freq\"] == 0:\n",
    "                    print(f\"Epoch {epoch}: Loss = {avg_loss:.4f}\")\n",
    "                    if val_loader is not None:\n",
    "                        print(f\"Validation Loss = {val_losses[-1]:.4f}\")\n",
    "                    memory_status()\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nTraining interrupted by user\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during training: {e}\")\n",
    "            raise\n",
    "        \n",
    "        return losses, val_losses, param_trajectories\n",
    "    \n",
    "    def evaluate(self, svi, loader):\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, t_batch, e_batch in loader:\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                t_batch = t_batch.to(self.device)\n",
    "                e_batch = e_batch.to(self.device)\n",
    "                val_loss += svi.evaluate_loss(X_batch, t_batch, e_batch)\n",
    "        return val_loss / len(loader)\n",
    "    \n",
    "    def save_checkpoint(self, epoch, val_loss):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss,\n",
    "            'param_store': pyro.get_param_store().get_state()\n",
    "        }\n",
    "        torch.save(checkpoint, \n",
    "                  os.path.join(self.config[\"results_dir\"], f'best_model.pth'))\n",
    "\n",
    "def cross_validate(model_class, X_tensor, time_tensor, event_tensor, config):\n",
    "    device = config[\"device\"]\n",
    "    # Use CPU for KFold as sklearn expects numpy arrays\n",
    "    kf = KFold(n_splits=config[\"n_folds\"], shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    \n",
    "    # Create array for KFold splitting (on CPU)\n",
    "    X_np = X_tensor.cpu().numpy()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_np)):\n",
    "        print(f\"\\nTraining fold {fold + 1}/{config['n_folds']}\")\n",
    "        \n",
    "        # Convert indices to torch tensors and move to GPU\n",
    "        train_idx = torch.tensor(train_idx, device=device)\n",
    "        val_idx = torch.tensor(val_idx, device=device)\n",
    "        \n",
    "        # Create data loaders for this fold\n",
    "        train_loader = DataLoader(\n",
    "            TensorDataset(X_tensor[train_idx], time_tensor[train_idx], event_tensor[train_idx]),\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            pin_memory=False,  # Don't pin CUDA tensors\n",
    "            generator=torch.Generator(device=device)  # Use CUDA generator for shuffling\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            TensorDataset(X_tensor[val_idx], time_tensor[val_idx], event_tensor[val_idx]),\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            pin_memory=False,  # Don't pin CUDA tensors\n",
    "            generator=torch.Generator(device=device)  # Use CUDA generator\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        model = model_class(config)\n",
    "        losses, val_losses, param_trajectories = model.train(train_loader, val_loader)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        with torch.no_grad():\n",
    "            beta = pyro.param(\"beta_loc\").detach()\n",
    "            risk_scores = X_tensor[val_idx] @ beta\n",
    "            \n",
    "            metrics = {\n",
    "                'c_index': concordance_index(\n",
    "                    time_tensor[val_idx].cpu().numpy(),\n",
    "                    -risk_scores.cpu().numpy(),\n",
    "                    event_tensor[val_idx].cpu().numpy()\n",
    "                ),\n",
    "                'final_loss': float(losses[-1]),\n",
    "                'param_trajectories': param_trajectories\n",
    "            }\n",
    "            \n",
    "            fold_results.append(metrics)\n",
    "        \n",
    "        # Clear GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "def plot_diagnostics(results_dir, fold_results, losses, param_trajectories):\n",
    "    # Create diagnostic plots directory\n",
    "    plots_dir = os.path.join(results_dir, 'plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. ELBO convergence plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(losses)\n",
    "    plt.title('ELBO Loss Convergence')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('ELBO Loss')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig(os.path.join(plots_dir, 'elbo_convergence.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Parameter trajectories\n",
    "    for param_name, trajectories in param_trajectories.items():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        trajectories_array = np.array(trajectories)\n",
    "        \n",
    "        if len(trajectories_array.shape) == 2:\n",
    "            for i in range(min(10, trajectories_array.shape[1])):\n",
    "                plt.plot(trajectories_array[:, i], alpha=0.5, label=f'Dim {i}')\n",
    "        else:\n",
    "            plt.plot(trajectories_array)\n",
    "            \n",
    "        plt.title(f'{param_name} Convergence')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(plots_dir, f'{param_name}_convergence.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    # 3. Cross-validation results\n",
    "    c_indices = [result['c_index'] for result in fold_results]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot(c_indices)\n",
    "    plt.title('Cross-validation C-index Distribution')\n",
    "    plt.ylabel('C-index')\n",
    "    plt.savefig(os.path.join(plots_dir, 'cv_c_index.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Feature importance and stability\n",
    "    beta_samples = np.stack([result['param_trajectories']['beta_loc'][-1] \n",
    "                           for result in fold_results])\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(beta_samples, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Coefficient Stability Across Folds')\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Fold')\n",
    "    plt.savefig(os.path.join(plots_dir, 'feature_stability.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Correlation analysis\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    corr_matrix = np.corrcoef(beta_samples.T)\n",
    "    sns.heatmap(corr_matrix, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.savefig(os.path.join(plots_dir, 'feature_correlation.png'))\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Setup GPU\n",
    "    setup_gpu()\n",
    "    \n",
    "    # Create results directory\n",
    "    os.makedirs(config[\"results_dir\"], exist_ok=True)\n",
    "    \n",
    "    # Save configuration\n",
    "    with open(os.path.join(config[\"results_dir\"], 'config.json'), 'w') as f:\n",
    "        json.dump({k: str(v) if isinstance(v, (torch.dtype, type)) else v \n",
    "                  for k, v in config.items()}, f, indent=2)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    try:\n",
    "        X_tensor, time_tensor, event_tensor = load_and_preprocess(config[\"data_path\"], config)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in data preprocessing: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    try:\n",
    "        fold_results = cross_validate(BayesianCoxModel, X_tensor, time_tensor, event_tensor, config)\n",
    "        \n",
    "        # Print memory status after cross-validation\n",
    "        memory_status()\n",
    "        \n",
    "        # Train final model on full dataset\n",
    "        dataset = TensorDataset(X_tensor, time_tensor, event_tensor)\n",
    "        train_loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            pin_memory=False,  # Don't pin CUDA tensors\n",
    "            generator=torch.Generator(device=config[\"device\"])  # Use CUDA generator\n",
    "        )\n",
    "        \n",
    "        final_model = BayesianCoxModel(config)\n",
    "        losses, _, param_trajectories = final_model.train(train_loader)\n",
    "        \n",
    "        # Plot diagnostics\n",
    "        plot_diagnostics(config[\"results_dir\"], fold_results, losses, param_trajectories)\n",
    "        \n",
    "        # Save results summary\n",
    "        results_summary = {\n",
    "            'mean_c_index': float(np.mean([r['c_index'] for r in fold_results])),\n",
    "            'std_c_index': float(np.std([r['c_index'] for r in fold_results])),\n",
    "            'final_loss': float(losses[-1]),\n",
    "            'n_epochs': len(losses),\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'user': config.get('user', 'unknown')\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(config[\"results_dir\"], 'results_summary.json'), 'w') as f:\n",
    "            json.dump(results_summary, f, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training: {e}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        raise\n",
    "    \n",
    "    finally:\n",
    "        # Clean up\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nProcess interrupted by user\")\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in main execution: {e}\")\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce7251a-5f7a-4b3e-b1ed-3c4f0191dab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CHIKOM~1\\ANACON~1\\envs\\vb_cox_pymc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU Information:\n",
      "PyTorch version: 2.4.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "Device: NVIDIA GeForce GTX 1650\n",
      "Device count: 1\n",
      "Current device: 0\n",
      "Initial GPU Memory: 0.00 MB allocated, 0.00 MB reserved\n",
      "Loading data from: D:\\cox-model-imputation\\error-in-r-code-for-mcar\\datasets\\vb-cox\\realistic_cox_data.csv\n",
      "Data shape: (800, 1003)\n",
      "Data loading time: 0.32s\n",
      "Data loaded on: cuda:0\n",
      "Number of features: 1000\n",
      "Number of samples: 800\n",
      "Event rate: 58.88%\n",
      "\n",
      "Training fold 1/5\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 3834.0459\n",
      "Validation Loss = 3799.5961\n",
      "Epoch 100: Loss = 2910.4209\n",
      "Validation Loss = 2907.9669\n",
      "Epoch 200: Loss = 2110.2659\n",
      "Validation Loss = 2145.0293\n",
      "Epoch 300: Loss = 1573.8250\n",
      "Validation Loss = 1557.5415\n",
      "Epoch 400: Loss = 1265.3036\n",
      "Validation Loss = 1254.2033\n",
      "Epoch 500: Loss = 1064.8907\n",
      "Validation Loss = 1056.8585\n",
      "Epoch 600: Loss = 920.8441\n",
      "Validation Loss = 910.7724\n",
      "Epoch 700: Loss = 837.8611\n",
      "Validation Loss = 840.9002\n",
      "Epoch 800: Loss = 798.3001\n",
      "Validation Loss = 792.7463\n",
      "Epoch 900: Loss = 776.0182\n",
      "Validation Loss = 775.0873\n",
      "Epoch 1000: Loss = 769.5976\n",
      "Validation Loss = 758.3886\n",
      "Epoch 1100: Loss = 785.7210\n",
      "Validation Loss = 764.1475\n",
      "Epoch 1200: Loss = 768.5822\n",
      "Validation Loss = 764.9905\n",
      "Epoch 1300: Loss = 762.2175\n",
      "Validation Loss = 765.3275\n",
      "Epoch 1400: Loss = 770.4969\n",
      "Validation Loss = 781.0042\n",
      "Epoch 1500: Loss = 765.8458\n",
      "Validation Loss = 756.8632\n",
      "Early stopping at epoch 1516\n",
      "\n",
      "Training fold 2/5\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 3875.8578\n",
      "Validation Loss = 3822.4972\n",
      "Epoch 100: Loss = 2896.5505\n",
      "Validation Loss = 2897.1375\n",
      "Epoch 200: Loss = 2098.5758\n",
      "Validation Loss = 2105.4426\n",
      "Epoch 300: Loss = 1574.1641\n",
      "Validation Loss = 1558.9283\n",
      "Epoch 400: Loss = 1261.8223\n",
      "Validation Loss = 1267.1739\n",
      "Epoch 500: Loss = 1060.4364\n",
      "Validation Loss = 1056.6886\n",
      "Epoch 600: Loss = 921.8889\n",
      "Validation Loss = 921.0410\n",
      "Epoch 700: Loss = 842.4672\n",
      "Validation Loss = 840.8614\n",
      "Epoch 800: Loss = 795.9610\n",
      "Validation Loss = 804.1849\n",
      "Epoch 900: Loss = 780.1650\n",
      "Validation Loss = 797.1129\n",
      "Epoch 1000: Loss = 778.5764\n",
      "Validation Loss = 767.5205\n",
      "Epoch 1100: Loss = 766.4206\n",
      "Validation Loss = 771.4101\n",
      "Epoch 1200: Loss = 772.3343\n",
      "Validation Loss = 774.8576\n",
      "Epoch 1300: Loss = 765.7747\n",
      "Validation Loss = 783.1495\n",
      "Epoch 1400: Loss = 763.0761\n",
      "Validation Loss = 760.5632\n",
      "Epoch 1500: Loss = 773.0209\n",
      "Validation Loss = 771.8554\n",
      "Epoch 1600: Loss = 767.7302\n",
      "Validation Loss = 754.7571\n",
      "Epoch 1700: Loss = 771.6658\n",
      "Validation Loss = 771.1036\n",
      "Early stopping at epoch 1765\n",
      "\n",
      "Training fold 3/5\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 3830.4877\n",
      "Validation Loss = 3894.1523\n",
      "Epoch 100: Loss = 2928.0641\n",
      "Validation Loss = 2909.4076\n",
      "Epoch 200: Loss = 2129.3345\n",
      "Validation Loss = 2093.6356\n",
      "Epoch 300: Loss = 1566.2977\n",
      "Validation Loss = 1572.8042\n",
      "Epoch 400: Loss = 1264.7302\n",
      "Validation Loss = 1261.9555\n",
      "Epoch 500: Loss = 1058.4560\n",
      "Validation Loss = 1048.1507\n",
      "Epoch 600: Loss = 916.3417\n",
      "Validation Loss = 921.0665\n",
      "Epoch 700: Loss = 843.2460\n",
      "Validation Loss = 836.8878\n",
      "Epoch 800: Loss = 795.5470\n",
      "Validation Loss = 797.6503\n",
      "Epoch 900: Loss = 778.7378\n",
      "Validation Loss = 779.7266\n",
      "Epoch 1000: Loss = 764.1795\n",
      "Validation Loss = 780.9416\n",
      "Epoch 1100: Loss = 776.2319\n",
      "Validation Loss = 767.3536\n",
      "Epoch 1200: Loss = 774.2800\n",
      "Validation Loss = 769.0010\n",
      "Epoch 1300: Loss = 767.9256\n",
      "Validation Loss = 759.3557\n",
      "Epoch 1400: Loss = 760.7093\n",
      "Validation Loss = 768.2097\n",
      "Epoch 1500: Loss = 768.8606\n",
      "Validation Loss = 763.7763\n",
      "Epoch 1600: Loss = 764.5430\n",
      "Validation Loss = 768.0842\n",
      "Early stopping at epoch 1699\n",
      "\n",
      "Training fold 4/5\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 3839.3233\n",
      "Validation Loss = 3831.4257\n",
      "Epoch 100: Loss = 2899.9870\n",
      "Validation Loss = 2896.9269\n",
      "Epoch 200: Loss = 2120.0250\n",
      "Validation Loss = 2130.6866\n",
      "Epoch 300: Loss = 1570.1325\n",
      "Validation Loss = 1576.4841\n",
      "Epoch 400: Loss = 1260.8123\n",
      "Validation Loss = 1260.6245\n",
      "Epoch 500: Loss = 1051.8183\n",
      "Validation Loss = 1064.9709\n",
      "Epoch 600: Loss = 916.1429\n",
      "Validation Loss = 916.7009\n",
      "Epoch 700: Loss = 839.3019\n",
      "Validation Loss = 838.4904\n",
      "Epoch 800: Loss = 794.7911\n",
      "Validation Loss = 804.6986\n",
      "Epoch 900: Loss = 777.8385\n",
      "Validation Loss = 774.9373\n",
      "Epoch 1000: Loss = 775.9885\n",
      "Validation Loss = 758.4670\n",
      "Epoch 1100: Loss = 778.1878\n",
      "Validation Loss = 769.5781\n",
      "Epoch 1200: Loss = 772.2653\n",
      "Validation Loss = 751.3988\n",
      "Epoch 1300: Loss = 770.3794\n",
      "Validation Loss = 780.1401\n",
      "Epoch 1400: Loss = 770.9850\n",
      "Validation Loss = 763.2800\n",
      "Early stopping at epoch 1410\n",
      "\n",
      "Training fold 5/5\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 3827.6663\n",
      "Validation Loss = 3857.0546\n",
      "Epoch 100: Loss = 2924.5467\n",
      "Validation Loss = 2906.3504\n",
      "Epoch 200: Loss = 2134.8005\n",
      "Validation Loss = 2108.7485\n",
      "Epoch 300: Loss = 1577.6656\n",
      "Validation Loss = 1568.3630\n",
      "Epoch 400: Loss = 1263.6080\n",
      "Validation Loss = 1262.8399\n",
      "Epoch 500: Loss = 1059.4852\n",
      "Validation Loss = 1054.0010\n",
      "Epoch 600: Loss = 914.5776\n",
      "Validation Loss = 928.4338\n",
      "Epoch 700: Loss = 843.3369\n",
      "Validation Loss = 841.4167\n",
      "Epoch 800: Loss = 800.2594\n",
      "Validation Loss = 804.0987\n",
      "Epoch 900: Loss = 779.2971\n",
      "Validation Loss = 793.2203\n",
      "Epoch 1000: Loss = 770.6463\n",
      "Validation Loss = 789.8004\n",
      "Epoch 1100: Loss = 768.0081\n",
      "Validation Loss = 779.9086\n",
      "Epoch 1200: Loss = 782.2681\n",
      "Validation Loss = 756.4585\n",
      "Epoch 1300: Loss = 770.9623\n",
      "Validation Loss = 763.2623\n",
      "Epoch 1400: Loss = 767.4668\n",
      "Validation Loss = 760.9836\n",
      "Epoch 1500: Loss = 773.2810\n",
      "Validation Loss = 778.2980\n",
      "Early stopping at epoch 1562\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 3857.2761\n",
      "Epoch 100: Loss = 2566.5076\n",
      "Epoch 200: Loss = 1655.6023\n",
      "Epoch 300: Loss = 1212.4159\n",
      "Epoch 400: Loss = 964.6472\n",
      "Epoch 500: Loss = 840.0464\n",
      "Epoch 600: Loss = 794.6169\n",
      "Epoch 700: Loss = 776.1273\n",
      "Epoch 800: Loss = 764.4741\n",
      "Epoch 900: Loss = 773.8212\n",
      "Epoch 1000: Loss = 765.5721\n",
      "Epoch 1100: Loss = 773.2849\n",
      "Epoch 1200: Loss = 764.6716\n",
      "Epoch 1300: Loss = 768.9176\n",
      "Epoch 1400: Loss = 766.6625\n",
      "Epoch 1500: Loss = 776.7848\n",
      "Epoch 1600: Loss = 765.0906\n",
      "Epoch 1700: Loss = 759.4697\n",
      "Epoch 1800: Loss = 774.5017\n",
      "Epoch 1900: Loss = 776.3164\n",
      "Epoch 2000: Loss = 771.3359\n",
      "Epoch 2100: Loss = 764.5212\n",
      "Epoch 2200: Loss = 771.2474\n",
      "Epoch 2300: Loss = 767.0350\n",
      "Epoch 2400: Loss = 768.6188\n",
      "Epoch 2500: Loss = 767.1592\n",
      "Epoch 2600: Loss = 775.1599\n",
      "Epoch 2700: Loss = 769.4011\n",
      "Epoch 2800: Loss = 762.5023\n",
      "Epoch 2900: Loss = 775.2393\n",
      "Epoch 3000: Loss = 763.7475\n",
      "Epoch 3100: Loss = 771.6437\n",
      "Epoch 3200: Loss = 770.8070\n",
      "\n",
      "Training interrupted by user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from pyro.optim import ClippedAdam\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    # Training parameters\n",
    "    \"max_epochs\": 5000,\n",
    "    \"batch_size\": 128,\n",
    "    \"initial_lr\": 5e-4,\n",
    "    \"lr_decay\": 0.2,\n",
    "    \"decay_step\": 500,\n",
    "    \"clip_norm\": 10.0,\n",
    "    \"early_stop_patience\": 200,\n",
    "    \n",
    "    # Device and precision\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"precision\": torch.float32,\n",
    "    \"pin_memory\": False if torch.cuda.is_available() else True,  # Only pin if using CPU\n",
    "    \"num_workers\": 0,  # Set to 0 for Windows\n",
    "    \"cuda_deterministic\": False,\n",
    "    \n",
    "    # Model parameters\n",
    "    \"elbo_particles\": 10,\n",
    "    \"warmup_epochs\": 100,\n",
    "    \"n_folds\": 5,\n",
    "    \n",
    "    # Logging and checkpointing\n",
    "    \"log_freq\": 100,\n",
    "    \"checkpoint_freq\": 500,\n",
    "    \n",
    "    # Paths\n",
    "    \"data_path\": r\"D:\\cox-model-imputation\\error-in-r-code-for-mcar\\datasets\\vb-cox\\realistic_cox_data.csv\",\n",
    "    \"results_dir\": f\"results_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "}\n",
    "\n",
    "def setup_gpu():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        \n",
    "        # Set the default generator to CUDA and set seeds for reproducibility\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "        \n",
    "        print(\"\\nGPU Information:\")\n",
    "        print(f\"PyTorch version: {torch.__version__}\")\n",
    "        print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "        \n",
    "        # Initial GPU memory info (just once at startup)\n",
    "        print(f\"Initial GPU Memory: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB allocated, {torch.cuda.memory_reserved(0)/1024**2:.2f} MB reserved\")\n",
    "        \n",
    "        # Set for reproducibility\n",
    "        torch.backends.cudnn.deterministic = config[\"cuda_deterministic\"]\n",
    "        torch.backends.cudnn.benchmark = not config[\"cuda_deterministic\"]\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(\"\\nNo GPU available, using CPU\")\n",
    "        return False\n",
    "\n",
    "def load_and_preprocess(path, config):\n",
    "    print(f\"Loading data from: {path}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(path)\n",
    "        print(f\"Data shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Extract features and survival data\n",
    "    X = data.iloc[:, 1:-2].values  # Skip ID, time, event\n",
    "    time_values = data['time'].values\n",
    "    event_values = data['event'].values\n",
    "    \n",
    "    # Handle missing values and standardize\n",
    "    X = (X - np.nanmean(X, axis=0)) / (np.nanstd(X, axis=0) + 1e-8)\n",
    "    X = np.nan_to_num(X)\n",
    "    \n",
    "    # Convert to tensors and move to GPU if available\n",
    "    X_tensor = torch.tensor(X, dtype=config[\"precision\"]).to(config[\"device\"])\n",
    "    time_tensor = torch.tensor(time_values, dtype=config[\"precision\"]).to(config[\"device\"])\n",
    "    event_tensor = torch.tensor(event_values, dtype=config[\"precision\"]).to(config[\"device\"])\n",
    "    \n",
    "    print(f\"Data loading time: {time.time()-start_time:.2f}s\")\n",
    "    print(f\"Data loaded on: {X_tensor.device}\")\n",
    "    print(f\"Number of features: {X_tensor.shape[1]}\")\n",
    "    print(f\"Number of samples: {X_tensor.shape[0]}\")\n",
    "    print(f\"Event rate: {event_tensor.mean().item():.2%}\")\n",
    "    \n",
    "    return X_tensor, time_tensor, event_tensor\n",
    "\n",
    "class CoxPartialLikelihood(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-8\n",
    "        self.max_exp = 20.0\n",
    "        \n",
    "    def forward(self, X_beta, survival_time, event):\n",
    "        event_mask = event == 1\n",
    "        n_events = event_mask.sum()\n",
    "        \n",
    "        if n_events < 1:\n",
    "            return torch.tensor(0.0, device=X_beta.device)\n",
    "        \n",
    "        X_beta = X_beta - X_beta.max()\n",
    "        exp_Xb = torch.clamp(X_beta.exp(), max=torch.exp(torch.tensor(self.max_exp, device=X_beta.device)))\n",
    "        \n",
    "        risk_matrix = (survival_time.unsqueeze(0) >= survival_time[event_mask].unsqueeze(1)).float()\n",
    "        sum_exp = (risk_matrix * exp_Xb.unsqueeze(0)).sum(dim=1)\n",
    "        log_sum_exp = torch.log(sum_exp + self.eps)\n",
    "        \n",
    "        return (X_beta[event_mask] - log_sum_exp).sum() / X_beta.size(0)\n",
    "\n",
    "def model(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    device = X.device\n",
    "    \n",
    "    # Global shrinkage parameter\n",
    "    global_scale = pyro.sample(\"global_scale\", \n",
    "                             dist.HalfCauchy(torch.tensor(1.0, device=device)))\n",
    "    \n",
    "    # Use a single Normal distribution instead of a mixture for simplicity\n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        # Local shrinkage parameters\n",
    "        local_scale = pyro.sample(\"local_scale\", \n",
    "                                dist.HalfCauchy(torch.tensor(1.0, device=device)))\n",
    "        \n",
    "        # Use a single shrinkage prior\n",
    "        scale = global_scale * local_scale\n",
    "        beta = pyro.sample(\"beta\", dist.Normal(torch.zeros(p, device=device), scale))\n",
    "    \n",
    "    # Compute likelihood\n",
    "    cox_likelihood = CoxPartialLikelihood()\n",
    "    log_pl = cox_likelihood(X @ beta, survival_time, event)\n",
    "    pyro.factor(\"log_pl\", log_pl)\n",
    "    \n",
    "    return beta\n",
    "\n",
    "def guide(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    device = X.device\n",
    "    \n",
    "    # Define parameters for global scale\n",
    "    global_scale_loc = pyro.param(\n",
    "        \"global_scale_loc\", \n",
    "        torch.tensor(1.0, device=device),\n",
    "        constraint=constraints.positive\n",
    "    )\n",
    "    \n",
    "    global_scale_scale = pyro.param(\n",
    "        \"global_scale_scale\",\n",
    "        torch.tensor(0.1, device=device),\n",
    "        constraint=constraints.positive\n",
    "    )\n",
    "    \n",
    "    # Sample global scale\n",
    "    pyro.sample(\n",
    "        \"global_scale\",\n",
    "        dist.LogNormal(global_scale_loc.log(), global_scale_scale)\n",
    "    )\n",
    "    \n",
    "    # Define parameters for local scales and betas\n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        # Local scale parameters\n",
    "        local_scale_loc = pyro.param(\n",
    "            \"local_scale_loc\",\n",
    "            torch.ones(p, device=device),\n",
    "            constraint=constraints.positive\n",
    "        )\n",
    "        \n",
    "        local_scale_scale = pyro.param(\n",
    "            \"local_scale_scale\",\n",
    "            torch.ones(p, device=device) * 0.1,\n",
    "            constraint=constraints.positive\n",
    "        )\n",
    "        \n",
    "        # Sample local scales\n",
    "        pyro.sample(\n",
    "            \"local_scale\",\n",
    "            dist.LogNormal(local_scale_loc.log(), local_scale_scale)\n",
    "        )\n",
    "        \n",
    "        # Beta parameters\n",
    "        beta_loc = pyro.param(\n",
    "            \"beta_loc\", \n",
    "            torch.zeros(p, device=device)\n",
    "        )\n",
    "        \n",
    "        beta_scale = pyro.param(\n",
    "            \"beta_scale\",\n",
    "            torch.ones(p, device=device) * 0.1,\n",
    "            constraint=constraints.positive\n",
    "        )\n",
    "        \n",
    "        # Sample beta\n",
    "        pyro.sample(\"beta\", dist.Normal(beta_loc, beta_scale))\n",
    "\n",
    "def initialize_params():\n",
    "    # This function ensures all parameters are registered before training\n",
    "    device = config[\"device\"]\n",
    "    \n",
    "    # Initialize with dummy tensors just to register parameters\n",
    "    X_dummy = torch.zeros((10, 1000), device=device)\n",
    "    time_dummy = torch.zeros(10, device=device)\n",
    "    event_dummy = torch.zeros(10, device=device)\n",
    "    \n",
    "    # Run model and guide once with dummy data to register all parameters\n",
    "    pyro.clear_param_store()\n",
    "    model(X_dummy, time_dummy, event_dummy)\n",
    "    guide(X_dummy, time_dummy, event_dummy)\n",
    "    \n",
    "    # Print registered parameters\n",
    "    print(\"Initialized parameters:\")\n",
    "    for name, param in pyro.get_param_store().items():\n",
    "        print(f\"  {name}: {param.shape}\")\n",
    "\n",
    "class BayesianCoxModel:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = config[\"device\"]\n",
    "        pyro.clear_param_store()\n",
    "        \n",
    "        # Initialize parameters to ensure they're registered\n",
    "        initialize_params()\n",
    "\n",
    "    def train(self, train_loader, val_loader=None):\n",
    "        optimizer = ClippedAdam({\n",
    "            \"lr\": self.config[\"initial_lr\"],\n",
    "            \"clip_norm\": self.config[\"clip_norm\"],\n",
    "            \"weight_decay\": 1e-4\n",
    "        })\n",
    "        \n",
    "        svi = SVI(model, guide, optimizer, \n",
    "                 loss=Trace_ELBO(num_particles=self.config[\"elbo_particles\"]))\n",
    "        \n",
    "        best_loss = float('inf')\n",
    "        losses = []\n",
    "        val_losses = []\n",
    "        patience = 0\n",
    "        param_trajectories = {}\n",
    "        \n",
    "        # Initialize parameter trajectories with all current parameters\n",
    "        for name in pyro.get_param_store().keys():\n",
    "            param_trajectories[name] = []\n",
    "        \n",
    "        try:\n",
    "            for epoch in range(self.config[\"max_epochs\"]):\n",
    "                epoch_loss = 0.0\n",
    "                for batch_idx, (X_batch, t_batch, e_batch) in enumerate(train_loader):\n",
    "                    # Ensure data is on the correct device\n",
    "                    X_batch = X_batch.to(self.device)\n",
    "                    t_batch = t_batch.to(self.device)\n",
    "                    e_batch = e_batch.to(self.device)\n",
    "                    \n",
    "                    loss = svi.step(X_batch, t_batch, e_batch)\n",
    "                    epoch_loss += loss\n",
    "                \n",
    "                avg_loss = epoch_loss / len(train_loader)\n",
    "                losses.append(avg_loss)\n",
    "                \n",
    "                # Store parameter trajectories\n",
    "                for name, param in pyro.get_param_store().items():\n",
    "                    if name not in param_trajectories:\n",
    "                        param_trajectories[name] = []\n",
    "                    param_trajectories[name].append(param.detach().cpu().numpy())\n",
    "                \n",
    "                # Validation loss\n",
    "                if val_loader is not None:\n",
    "                    val_loss = self.evaluate(svi, val_loader)\n",
    "                    val_losses.append(val_loss)\n",
    "                    \n",
    "                    if val_loss < best_loss:\n",
    "                        best_loss = val_loss\n",
    "                        patience = 0\n",
    "                        # Save best model parameters\n",
    "                        self.save_checkpoint(epoch, val_loss)\n",
    "                    else:\n",
    "                        patience += 1\n",
    "                        \n",
    "                    if patience >= self.config[\"early_stop_patience\"]:\n",
    "                        print(f\"Early stopping at epoch {epoch}\")\n",
    "                        break\n",
    "                \n",
    "                # Learning rate decay\n",
    "                if epoch % self.config[\"decay_step\"] == 0 and epoch > 0:\n",
    "                    current_lr = self.config[\"initial_lr\"] * \\\n",
    "                               (self.config[\"lr_decay\"] ** (epoch // self.config[\"decay_step\"]))\n",
    "                    optimizer.set_state({'lr': current_lr})\n",
    "                    \n",
    "                if epoch % self.config[\"log_freq\"] == 0:\n",
    "                    print(f\"Epoch {epoch}: Loss = {avg_loss:.4f}\")\n",
    "                    if val_loader is not None:\n",
    "                        print(f\"Validation Loss = {val_losses[-1]:.4f}\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nTraining interrupted by user\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during training: {e}\")\n",
    "            raise\n",
    "        \n",
    "        return losses, val_losses, param_trajectories\n",
    "    \n",
    "    def evaluate(self, svi, loader):\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, t_batch, e_batch in loader:\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                t_batch = t_batch.to(self.device)\n",
    "                e_batch = e_batch.to(self.device)\n",
    "                val_loss += svi.evaluate_loss(X_batch, t_batch, e_batch)\n",
    "        return val_loss / len(loader)\n",
    "    \n",
    "    def save_checkpoint(self, epoch, val_loss):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss,\n",
    "            'param_store': pyro.get_param_store().get_state()\n",
    "        }\n",
    "        torch.save(checkpoint, \n",
    "                  os.path.join(self.config[\"results_dir\"], f'best_model.pth'))\n",
    "\n",
    "def cross_validate(model_class, X_tensor, time_tensor, event_tensor, config):\n",
    "    device = config[\"device\"]\n",
    "    # Use CPU for KFold as sklearn expects numpy arrays\n",
    "    kf = KFold(n_splits=config[\"n_folds\"], shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    \n",
    "    # Create array for KFold splitting (on CPU)\n",
    "    X_np = X_tensor.cpu().numpy()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_np)):\n",
    "        print(f\"\\nTraining fold {fold + 1}/{config['n_folds']}\")\n",
    "        \n",
    "        # Convert indices to torch tensors and move to GPU\n",
    "        train_idx = torch.tensor(train_idx, device=device)\n",
    "        val_idx = torch.tensor(val_idx, device=device)\n",
    "        \n",
    "        # Create data loaders for this fold\n",
    "        train_loader = DataLoader(\n",
    "            TensorDataset(X_tensor[train_idx], time_tensor[train_idx], event_tensor[train_idx]),\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            pin_memory=False,  # Don't pin CUDA tensors\n",
    "            generator=torch.Generator(device=device)  # Use CUDA generator for shuffling\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            TensorDataset(X_tensor[val_idx], time_tensor[val_idx], event_tensor[val_idx]),\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            pin_memory=False,  # Don't pin CUDA tensors\n",
    "            generator=torch.Generator(device=device)  # Use CUDA generator\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        model = model_class(config)\n",
    "        losses, val_losses, param_trajectories = model.train(train_loader, val_loader)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        with torch.no_grad():\n",
    "            beta = pyro.param(\"beta_loc\").detach()\n",
    "            risk_scores = X_tensor[val_idx] @ beta\n",
    "            \n",
    "            metrics = {\n",
    "                'c_index': concordance_index(\n",
    "                    time_tensor[val_idx].cpu().numpy(),\n",
    "                    -risk_scores.cpu().numpy(),\n",
    "                    event_tensor[val_idx].cpu().numpy()\n",
    "                ),\n",
    "                'final_loss': float(losses[-1]),\n",
    "                'param_trajectories': param_trajectories\n",
    "            }\n",
    "            \n",
    "            fold_results.append(metrics)\n",
    "        \n",
    "        # Clear GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "def plot_diagnostics(results_dir, fold_results, losses, param_trajectories):\n",
    "    # Create diagnostic plots directory\n",
    "    plots_dir = os.path.join(results_dir, 'plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. ELBO convergence plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(losses)\n",
    "    plt.title('ELBO Loss Convergence')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('ELBO Loss')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig(os.path.join(plots_dir, 'elbo_convergence.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Parameter trajectories\n",
    "    for param_name, trajectories in param_trajectories.items():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        trajectories_array = np.array(trajectories)\n",
    "        \n",
    "        if len(trajectories_array.shape) == 2:\n",
    "            for i in range(min(10, trajectories_array.shape[1])):\n",
    "                plt.plot(trajectories_array[:, i], alpha=0.5, label=f'Dim {i}')\n",
    "        else:\n",
    "            plt.plot(trajectories_array)\n",
    "            \n",
    "        plt.title(f'{param_name} Convergence')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(plots_dir, f'{param_name}_convergence.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    # 3. Cross-validation results\n",
    "    c_indices = [result['c_index'] for result in fold_results]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot(c_indices)\n",
    "    plt.title('Cross-validation C-index Distribution')\n",
    "    plt.ylabel('C-index')\n",
    "    plt.savefig(os.path.join(plots_dir, 'cv_c_index.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Feature importance and stability\n",
    "    beta_samples = np.stack([result['param_trajectories']['beta_loc'][-1] \n",
    "                           for result in fold_results])\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(beta_samples, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Coefficient Stability Across Folds')\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Fold')\n",
    "    plt.savefig(os.path.join(plots_dir, 'feature_stability.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Correlation analysis\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    corr_matrix = np.corrcoef(beta_samples.T)\n",
    "    sns.heatmap(corr_matrix, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.savefig(os.path.join(plots_dir, 'feature_correlation.png'))\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Setup GPU\n",
    "    setup_gpu()\n",
    "    \n",
    "    # Create results directory\n",
    "    os.makedirs(config[\"results_dir\"], exist_ok=True)\n",
    "    \n",
    "    # Save configuration\n",
    "    with open(os.path.join(config[\"results_dir\"], 'config.json'), 'w') as f:\n",
    "        json.dump({k: str(v) if isinstance(v, (torch.dtype, type)) else v \n",
    "                  for k, v in config.items()}, f, indent=2)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    try:\n",
    "        X_tensor, time_tensor, event_tensor = load_and_preprocess(config[\"data_path\"], config)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in data preprocessing: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    try:\n",
    "        fold_results = cross_validate(BayesianCoxModel, X_tensor, time_tensor, event_tensor, config)\n",
    "        \n",
    "        # Train final model on full dataset\n",
    "        dataset = TensorDataset(X_tensor, time_tensor, event_tensor)\n",
    "        train_loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            pin_memory=False,  # Don't pin CUDA tensors\n",
    "            generator=torch.Generator(device=config[\"device\"])  # Use CUDA generator\n",
    "        )\n",
    "        \n",
    "        final_model = BayesianCoxModel(config)\n",
    "        losses, _, param_trajectories = final_model.train(train_loader)\n",
    "        \n",
    "        # Plot diagnostics\n",
    "        plot_diagnostics(config[\"results_dir\"], fold_results, losses, param_trajectories)\n",
    "        \n",
    "        # Save results summary\n",
    "        results_summary = {\n",
    "            'mean_c_index': float(np.mean([r['c_index'] for r in fold_results])),\n",
    "            'std_c_index': float(np.std([r['c_index'] for r in fold_results])),\n",
    "            'final_loss': float(losses[-1]),\n",
    "            'n_epochs': len(losses),\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'user': config.get('user', 'unknown')\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(config[\"results_dir\"], 'results_summary.json'), 'w') as f:\n",
    "            json.dump(results_summary, f, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training: {e}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        raise\n",
    "    \n",
    "    finally:\n",
    "        # Clean up\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nProcess interrupted by user\")\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in main execution: {e}\")\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9024d8cb-83f4-43cc-83e7-9d7d7e3cc691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35b793eb-6414-432e-8c67-1fee2cb3c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# triggering early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0758212a-b71e-46f8-ac2e-0576ec5fb28f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf687b73-6496-4ffb-9f38-be586b0ba46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU Information:\n",
      "PyTorch version: 2.4.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "Device: NVIDIA GeForce GTX 1650\n",
      "Device count: 1\n",
      "Current device: 0\n",
      "Initial GPU Memory: 16.28 MB allocated, 42.00 MB reserved\n",
      "Loading data from: D:\\cox-model-imputation\\error-in-r-code-for-mcar\\datasets\\vb-cox\\realistic_cox_data.csv\n",
      "Data shape: (800, 1003)\n",
      "Data loading time: 0.51s\n",
      "Data loaded on: cuda:0\n",
      "Number of features: 1000\n",
      "Number of samples: 800\n",
      "Event rate: 58.88%\n",
      "\n",
      "Training fold 1/5\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 3834.0459\n",
      "Validation Loss = 3799.5961\n",
      "Epoch 100: Loss = 2910.4209\n",
      "Validation Loss = 2907.9669\n",
      "Epoch 200: Loss = 2110.2659\n",
      "Validation Loss = 2145.0293\n",
      "Epoch 300: Loss = 1573.8250\n",
      "Validation Loss = 1557.5415\n",
      "Epoch 400: Loss = 1265.3036\n",
      "Validation Loss = 1254.2033\n",
      "Epoch 500: Loss = 1064.8907\n",
      "Validation Loss = 1056.8585\n",
      "Epoch 600: Loss = 920.8441\n",
      "Validation Loss = 910.7724\n",
      "Epoch 700: Loss = 837.8611\n",
      "Validation Loss = 840.9002\n",
      "Epoch 800: Loss = 798.3001\n",
      "Validation Loss = 792.7463\n",
      "Epoch 900: Loss = 776.0182\n",
      "Validation Loss = 775.0873\n",
      "Epoch 1000: Loss = 769.5976\n",
      "Validation Loss = 758.3886\n",
      "Epoch 1100: Loss = 785.7210\n",
      "Validation Loss = 764.1475\n",
      "Epoch 1200: Loss = 768.5822\n",
      "Validation Loss = 764.9905\n",
      "Epoch 1300: Loss = 762.2175\n",
      "Validation Loss = 765.3275\n",
      "Epoch 1400: Loss = 770.4969\n",
      "Validation Loss = 781.0042\n",
      "Epoch 1500: Loss = 765.8458\n",
      "Validation Loss = 756.8632\n",
      "Early stopping at epoch 1516\n",
      "\n",
      "Training fold 2/5\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 3875.8578\n",
      "Validation Loss = 3822.4972\n",
      "Epoch 100: Loss = 2896.5505\n",
      "Validation Loss = 2897.1375\n",
      "Epoch 200: Loss = 2098.5758\n",
      "Validation Loss = 2105.4426\n",
      "Epoch 300: Loss = 1574.1641\n",
      "Validation Loss = 1558.9283\n",
      "Epoch 400: Loss = 1261.8223\n",
      "Validation Loss = 1267.1739\n",
      "Epoch 500: Loss = 1060.4364\n",
      "Validation Loss = 1056.6886\n",
      "Epoch 600: Loss = 921.8889\n",
      "Validation Loss = 921.0410\n",
      "Epoch 700: Loss = 842.4672\n",
      "Validation Loss = 840.8614\n",
      "Epoch 800: Loss = 795.9610\n",
      "Validation Loss = 804.1849\n",
      "Epoch 900: Loss = 780.1650\n",
      "Validation Loss = 797.1129\n",
      "Epoch 1000: Loss = 778.5764\n",
      "Validation Loss = 767.5205\n",
      "Epoch 1100: Loss = 766.4206\n",
      "Validation Loss = 771.4101\n",
      "Epoch 1200: Loss = 772.3343\n",
      "Validation Loss = 774.8576\n",
      "Epoch 1300: Loss = 765.7747\n",
      "Validation Loss = 783.1495\n",
      "Epoch 1400: Loss = 763.0761\n",
      "Validation Loss = 760.5632\n",
      "Epoch 1500: Loss = 773.0209\n",
      "Validation Loss = 771.8554\n",
      "Epoch 1600: Loss = 767.7302\n",
      "Validation Loss = 754.7571\n",
      "Epoch 1700: Loss = 771.6658\n",
      "Validation Loss = 771.1036\n",
      "Early stopping at epoch 1765\n",
      "\n",
      "Training fold 3/5\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 3830.4877\n",
      "Validation Loss = 3894.1523\n",
      "Epoch 100: Loss = 2928.0641\n",
      "Validation Loss = 2909.4076\n",
      "Epoch 200: Loss = 2129.3345\n",
      "Validation Loss = 2093.6356\n",
      "Epoch 300: Loss = 1566.2977\n",
      "Validation Loss = 1572.8042\n",
      "Epoch 400: Loss = 1264.7302\n",
      "Validation Loss = 1261.9555\n",
      "Epoch 500: Loss = 1058.4560\n",
      "Validation Loss = 1048.1507\n",
      "Epoch 600: Loss = 916.3417\n",
      "Validation Loss = 921.0665\n",
      "Epoch 700: Loss = 843.2460\n",
      "Validation Loss = 836.8878\n",
      "Epoch 800: Loss = 795.5470\n",
      "Validation Loss = 797.6503\n",
      "\n",
      "Training interrupted by user\n",
      "\n",
      "Training fold 4/5\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 3850.6022\n",
      "Validation Loss = 3820.8290\n",
      "\n",
      "Training interrupted by user\n",
      "\n",
      "Training fold 5/5\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 3836.6567\n",
      "Validation Loss = 3828.5297\n",
      "Epoch 100: Loss = 2909.7834\n",
      "Validation Loss = 2893.9755\n",
      "Epoch 200: Loss = 2101.9050\n",
      "Validation Loss = 2123.8020\n",
      "Epoch 300: Loss = 1576.5423\n",
      "Validation Loss = 1581.7826\n",
      "Epoch 400: Loss = 1263.8692\n",
      "Validation Loss = 1262.3972\n",
      "Epoch 500: Loss = 1059.7487\n",
      "Validation Loss = 1058.4017\n",
      "Epoch 600: Loss = 920.4648\n",
      "Validation Loss = 915.6577\n",
      "Epoch 700: Loss = 835.1524\n",
      "Validation Loss = 848.5195\n",
      "Epoch 800: Loss = 804.4113\n",
      "Validation Loss = 799.7027\n",
      "Epoch 900: Loss = 786.6535\n",
      "Validation Loss = 776.8003\n",
      "Epoch 1000: Loss = 771.6309\n",
      "Validation Loss = 773.4894\n",
      "Epoch 1100: Loss = 771.2315\n",
      "Validation Loss = 747.8111\n",
      "Epoch 1200: Loss = 771.3702\n",
      "Validation Loss = 764.8251\n",
      "Epoch 1300: Loss = 765.1960\n",
      "Validation Loss = 768.6319\n",
      "Epoch 1400: Loss = 765.3886\n",
      "Validation Loss = 758.7570\n",
      "Early stopping at epoch 1498\n",
      "Using 1138 epochs for final model based on cross-validation\n",
      "\n",
      "Training final model on full dataset for 1138 epochs\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 3825.9617\n",
      "Epoch 100: Loss = 2578.7162\n",
      "Epoch 200: Loss = 1648.4085\n",
      "Epoch 300: Loss = 1216.4588\n",
      "Epoch 400: Loss = 970.8948\n",
      "Epoch 500: Loss = 839.3232\n",
      "Epoch 600: Loss = 784.6508\n",
      "Epoch 700: Loss = 790.6340\n",
      "Epoch 800: Loss = 766.0024\n",
      "Epoch 900: Loss = 762.3802\n",
      "Epoch 1000: Loss = 760.7407\n",
      "Epoch 1100: Loss = 771.4003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from pyro.optim import ClippedAdam\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    # Training parameters\n",
    "    \"max_epochs\": 5000,\n",
    "    \"batch_size\": 128,\n",
    "    \"initial_lr\": 5e-4,\n",
    "    \"lr_decay\": 0.2,\n",
    "    \"decay_step\": 500,\n",
    "    \"clip_norm\": 10.0,\n",
    "    \"early_stop_patience\": 200,\n",
    "    \n",
    "    # Device and precision\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"precision\": torch.float32,\n",
    "    \"pin_memory\": False if torch.cuda.is_available() else True,  # Only pin if using CPU\n",
    "    \"num_workers\": 0,  # Set to 0 for Windows\n",
    "    \"cuda_deterministic\": False,\n",
    "    \n",
    "    # Model parameters\n",
    "    \"elbo_particles\": 10,\n",
    "    \"warmup_epochs\": 100,\n",
    "    \"n_folds\": 5,\n",
    "    \n",
    "    # Logging and checkpointing\n",
    "    \"log_freq\": 100,\n",
    "    \"checkpoint_freq\": 500,\n",
    "    \n",
    "    # Paths\n",
    "    \"data_path\": r\"D:\\cox-model-imputation\\error-in-r-code-for-mcar\\datasets\\vb-cox\\realistic_cox_data.csv\",\n",
    "    \"results_dir\": f\"results_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "}\n",
    "\n",
    "def setup_gpu():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        \n",
    "        # Set the default generator to CUDA and set seeds for reproducibility\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "        \n",
    "        print(\"\\nGPU Information:\")\n",
    "        print(f\"PyTorch version: {torch.__version__}\")\n",
    "        print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "        \n",
    "        # Initial GPU memory info (just once at startup)\n",
    "        print(f\"Initial GPU Memory: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB allocated, {torch.cuda.memory_reserved(0)/1024**2:.2f} MB reserved\")\n",
    "        \n",
    "        # Set for reproducibility\n",
    "        torch.backends.cudnn.deterministic = config[\"cuda_deterministic\"]\n",
    "        torch.backends.cudnn.benchmark = not config[\"cuda_deterministic\"]\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(\"\\nNo GPU available, using CPU\")\n",
    "        return False\n",
    "\n",
    "def load_and_preprocess(path, config):\n",
    "    print(f\"Loading data from: {path}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(path)\n",
    "        print(f\"Data shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Extract features and survival data\n",
    "    X = data.iloc[:, 1:-2].values  # Skip ID, time, event\n",
    "    time_values = data['time'].values\n",
    "    event_values = data['event'].values\n",
    "    \n",
    "    # Handle missing values and standardize\n",
    "    X = (X - np.nanmean(X, axis=0)) / (np.nanstd(X, axis=0) + 1e-8)\n",
    "    X = np.nan_to_num(X)\n",
    "    \n",
    "    # Convert to tensors and move to GPU if available\n",
    "    X_tensor = torch.tensor(X, dtype=config[\"precision\"]).to(config[\"device\"])\n",
    "    time_tensor = torch.tensor(time_values, dtype=config[\"precision\"]).to(config[\"device\"])\n",
    "    event_tensor = torch.tensor(event_values, dtype=config[\"precision\"]).to(config[\"device\"])\n",
    "    \n",
    "    print(f\"Data loading time: {time.time()-start_time:.2f}s\")\n",
    "    print(f\"Data loaded on: {X_tensor.device}\")\n",
    "    print(f\"Number of features: {X_tensor.shape[1]}\")\n",
    "    print(f\"Number of samples: {X_tensor.shape[0]}\")\n",
    "    print(f\"Event rate: {event_tensor.mean().item():.2%}\")\n",
    "    \n",
    "    return X_tensor, time_tensor, event_tensor\n",
    "\n",
    "class CoxPartialLikelihood(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-8\n",
    "        self.max_exp = 20.0\n",
    "        \n",
    "    def forward(self, X_beta, survival_time, event):\n",
    "        event_mask = event == 1\n",
    "        n_events = event_mask.sum()\n",
    "        \n",
    "        if n_events < 1:\n",
    "            return torch.tensor(0.0, device=X_beta.device)\n",
    "        \n",
    "        X_beta = X_beta - X_beta.max()\n",
    "        exp_Xb = torch.clamp(X_beta.exp(), max=torch.exp(torch.tensor(self.max_exp, device=X_beta.device)))\n",
    "        \n",
    "        risk_matrix = (survival_time.unsqueeze(0) >= survival_time[event_mask].unsqueeze(1)).float()\n",
    "        sum_exp = (risk_matrix * exp_Xb.unsqueeze(0)).sum(dim=1)\n",
    "        log_sum_exp = torch.log(sum_exp + self.eps)\n",
    "        \n",
    "        return (X_beta[event_mask] - log_sum_exp).sum() / X_beta.size(0)\n",
    "\n",
    "def model(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    device = X.device\n",
    "    \n",
    "    # Global shrinkage parameter\n",
    "    global_scale = pyro.sample(\"global_scale\", \n",
    "                             dist.HalfCauchy(torch.tensor(1.0, device=device)))\n",
    "    \n",
    "    # Use a single Normal distribution instead of a mixture for simplicity\n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        # Local shrinkage parameters\n",
    "        local_scale = pyro.sample(\"local_scale\", \n",
    "                                dist.HalfCauchy(torch.tensor(1.0, device=device)))\n",
    "        \n",
    "        # Use a single shrinkage prior\n",
    "        scale = global_scale * local_scale\n",
    "        beta = pyro.sample(\"beta\", dist.Normal(torch.zeros(p, device=device), scale))\n",
    "    \n",
    "    # Compute likelihood\n",
    "    cox_likelihood = CoxPartialLikelihood()\n",
    "    log_pl = cox_likelihood(X @ beta, survival_time, event)\n",
    "    pyro.factor(\"log_pl\", log_pl)\n",
    "    \n",
    "    return beta\n",
    "\n",
    "def guide(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    device = X.device\n",
    "    \n",
    "    # Define parameters for global scale\n",
    "    global_scale_loc = pyro.param(\n",
    "        \"global_scale_loc\", \n",
    "        torch.tensor(1.0, device=device),\n",
    "        constraint=constraints.positive\n",
    "    )\n",
    "    \n",
    "    global_scale_scale = pyro.param(\n",
    "        \"global_scale_scale\",\n",
    "        torch.tensor(0.1, device=device),\n",
    "        constraint=constraints.positive\n",
    "    )\n",
    "    \n",
    "    # Sample global scale\n",
    "    pyro.sample(\n",
    "        \"global_scale\",\n",
    "        dist.LogNormal(global_scale_loc.log(), global_scale_scale)\n",
    "    )\n",
    "    \n",
    "    # Define parameters for local scales and betas\n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        # Local scale parameters\n",
    "        local_scale_loc = pyro.param(\n",
    "            \"local_scale_loc\",\n",
    "            torch.ones(p, device=device),\n",
    "            constraint=constraints.positive\n",
    "        )\n",
    "        \n",
    "        local_scale_scale = pyro.param(\n",
    "            \"local_scale_scale\",\n",
    "            torch.ones(p, device=device) * 0.1,\n",
    "            constraint=constraints.positive\n",
    "        )\n",
    "        \n",
    "        # Sample local scales\n",
    "        pyro.sample(\n",
    "            \"local_scale\",\n",
    "            dist.LogNormal(local_scale_loc.log(), local_scale_scale)\n",
    "        )\n",
    "        \n",
    "        # Beta parameters\n",
    "        beta_loc = pyro.param(\n",
    "            \"beta_loc\", \n",
    "            torch.zeros(p, device=device)\n",
    "        )\n",
    "        \n",
    "        beta_scale = pyro.param(\n",
    "            \"beta_scale\",\n",
    "            torch.ones(p, device=device) * 0.1,\n",
    "            constraint=constraints.positive\n",
    "        )\n",
    "        \n",
    "        # Sample beta\n",
    "        pyro.sample(\"beta\", dist.Normal(beta_loc, beta_scale))\n",
    "\n",
    "def initialize_params():\n",
    "    # This function ensures all parameters are registered before training\n",
    "    device = config[\"device\"]\n",
    "    \n",
    "    # Initialize with dummy tensors just to register parameters\n",
    "    X_dummy = torch.zeros((10, 1000), device=device)\n",
    "    time_dummy = torch.zeros(10, device=device)\n",
    "    event_dummy = torch.zeros(10, device=device)\n",
    "    \n",
    "    # Run model and guide once with dummy data to register all parameters\n",
    "    pyro.clear_param_store()\n",
    "    model(X_dummy, time_dummy, event_dummy)\n",
    "    guide(X_dummy, time_dummy, event_dummy)\n",
    "    \n",
    "    # Print registered parameters\n",
    "    print(\"Initialized parameters:\")\n",
    "    for name, param in pyro.get_param_store().items():\n",
    "        print(f\"  {name}: {param.shape}\")\n",
    "\n",
    "class BayesianCoxModel:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = config[\"device\"]\n",
    "        pyro.clear_param_store()\n",
    "        \n",
    "        # Initialize parameters to ensure they're registered\n",
    "        initialize_params()\n",
    "\n",
    "    def train(self, train_loader, val_loader=None):\n",
    "        optimizer = ClippedAdam({\n",
    "            \"lr\": self.config[\"initial_lr\"],\n",
    "            \"clip_norm\": self.config[\"clip_norm\"],\n",
    "            \"weight_decay\": 1e-4\n",
    "        })\n",
    "        \n",
    "        svi = SVI(model, guide, optimizer, \n",
    "                 loss=Trace_ELBO(num_particles=self.config[\"elbo_particles\"]))\n",
    "        \n",
    "        best_loss = float('inf')\n",
    "        losses = []\n",
    "        val_losses = []\n",
    "        patience = 0\n",
    "        param_trajectories = {}\n",
    "        \n",
    "        # Initialize parameter trajectories with all current parameters\n",
    "        for name in pyro.get_param_store().keys():\n",
    "            param_trajectories[name] = []\n",
    "        \n",
    "        try:\n",
    "            for epoch in range(self.config[\"max_epochs\"]):\n",
    "                epoch_loss = 0.0\n",
    "                for batch_idx, (X_batch, t_batch, e_batch) in enumerate(train_loader):\n",
    "                    # Ensure data is on the correct device\n",
    "                    X_batch = X_batch.to(self.device)\n",
    "                    t_batch = t_batch.to(self.device)\n",
    "                    e_batch = e_batch.to(self.device)\n",
    "                    \n",
    "                    loss = svi.step(X_batch, t_batch, e_batch)\n",
    "                    epoch_loss += loss\n",
    "                \n",
    "                avg_loss = epoch_loss / len(train_loader)\n",
    "                losses.append(avg_loss)\n",
    "                \n",
    "                # Store parameter trajectories\n",
    "                for name, param in pyro.get_param_store().items():\n",
    "                    if name not in param_trajectories:\n",
    "                        param_trajectories[name] = []\n",
    "                    param_trajectories[name].append(param.detach().cpu().numpy())\n",
    "                \n",
    "                # Validation loss if validation set is provided\n",
    "                if val_loader is not None:\n",
    "                    val_loss = self.evaluate(svi, val_loader)\n",
    "                    val_losses.append(val_loss)\n",
    "                    \n",
    "                    if val_loss < best_loss:\n",
    "                        best_loss = val_loss\n",
    "                        patience = 0\n",
    "                        # Save best model parameters\n",
    "                        self.save_checkpoint(epoch, val_loss)\n",
    "                    else:\n",
    "                        patience += 1\n",
    "                        \n",
    "                    if patience >= self.config[\"early_stop_patience\"]:\n",
    "                        print(f\"Early stopping at epoch {epoch}\")\n",
    "                        break\n",
    "                \n",
    "                # Learning rate decay\n",
    "                if epoch % self.config[\"decay_step\"] == 0 and epoch > 0:\n",
    "                    current_lr = self.config[\"initial_lr\"] * \\\n",
    "                               (self.config[\"lr_decay\"] ** (epoch // self.config[\"decay_step\"]))\n",
    "                    optimizer.set_state({'lr': current_lr})\n",
    "                    \n",
    "                if epoch % self.config[\"log_freq\"] == 0:\n",
    "                    print(f\"Epoch {epoch}: Loss = {avg_loss:.4f}\")\n",
    "                    if val_loader is not None:\n",
    "                        print(f\"Validation Loss = {val_losses[-1]:.4f}\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nTraining interrupted by user\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during training: {e}\")\n",
    "            raise\n",
    "        \n",
    "        return losses, val_losses, param_trajectories\n",
    "    \n",
    "    def evaluate(self, svi, loader):\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, t_batch, e_batch in loader:\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                t_batch = t_batch.to(self.device)\n",
    "                e_batch = e_batch.to(self.device)\n",
    "                val_loss += svi.evaluate_loss(X_batch, t_batch, e_batch)\n",
    "        return val_loss / len(loader)\n",
    "    \n",
    "    def save_checkpoint(self, epoch, val_loss):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss,\n",
    "            'param_store': pyro.get_param_store().get_state()\n",
    "        }\n",
    "        torch.save(checkpoint, \n",
    "                  os.path.join(self.config[\"results_dir\"], f'best_model.pth'))\n",
    "\n",
    "# Need to modify the cross_validate function to return validation losses and stopping epochs\n",
    "def cross_validate(model_class, X_tensor, time_tensor, event_tensor, config):\n",
    "    device = config[\"device\"]\n",
    "    # Use CPU for KFold as sklearn expects numpy arrays\n",
    "    kf = KFold(n_splits=config[\"n_folds\"], shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    \n",
    "    # Create array for KFold splitting (on CPU)\n",
    "    X_np = X_tensor.cpu().numpy()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_np)):\n",
    "        print(f\"\\nTraining fold {fold + 1}/{config['n_folds']}\")\n",
    "        \n",
    "        # Convert indices to torch tensors and move to GPU\n",
    "        train_idx = torch.tensor(train_idx, device=device)\n",
    "        val_idx = torch.tensor(val_idx, device=device)\n",
    "        \n",
    "        # Create data loaders for this fold\n",
    "        train_loader = DataLoader(\n",
    "            TensorDataset(X_tensor[train_idx], time_tensor[train_idx], event_tensor[train_idx]),\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            pin_memory=False,\n",
    "            generator=torch.Generator(device=device)\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            TensorDataset(X_tensor[val_idx], time_tensor[val_idx], event_tensor[val_idx]),\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            pin_memory=False,\n",
    "            generator=torch.Generator(device=device)\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        model = model_class(config)\n",
    "        losses, val_losses, param_trajectories = model.train(train_loader, val_loader)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        with torch.no_grad():\n",
    "            beta = pyro.param(\"beta_loc\").detach()\n",
    "            risk_scores = X_tensor[val_idx] @ beta\n",
    "            \n",
    "            metrics = {\n",
    "                'c_index': concordance_index(\n",
    "                    time_tensor[val_idx].cpu().numpy(),\n",
    "                    -risk_scores.cpu().numpy(),\n",
    "                    event_tensor[val_idx].cpu().numpy()\n",
    "                ),\n",
    "                'final_loss': float(losses[-1]),\n",
    "                'param_trajectories': param_trajectories,\n",
    "                'val_losses': val_losses,\n",
    "                'last_epoch': len(losses)\n",
    "            }\n",
    "            \n",
    "            fold_results.append(metrics)\n",
    "        \n",
    "        # Clear GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "def plot_diagnostics(results_dir, fold_results, losses, val_losses_list, param_trajectories):\n",
    "    # Create diagnostic plots directory\n",
    "    plots_dir = os.path.join(results_dir, 'plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Enhanced ELBO convergence plot with training and validation losses\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    # Plot training loss\n",
    "    plt.plot(losses, label='Training Loss', color='blue', linewidth=2)\n",
    "    \n",
    "    # Plot validation losses from cross-validation\n",
    "    if val_losses_list:\n",
    "        for fold_idx, val_losses in enumerate(val_losses_list):\n",
    "            plt.plot(val_losses, label=f'Validation Loss (Fold {fold_idx+1})', \n",
    "                     linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.title('Training and Validation Loss Convergence', fontsize=14)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('ELBO Loss', fontsize=12)\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'loss_convergence.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Parameter trajectories with better visualization\n",
    "    for param_name, trajectories in param_trajectories.items():\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        trajectories_array = np.array(trajectories)\n",
    "        \n",
    "        if len(trajectories_array.shape) == 2 and trajectories_array.shape[1] > 1:\n",
    "            # For high-dimensional parameters (like beta), show statistics\n",
    "            if trajectories_array.shape[1] > 10:\n",
    "                # Show mean, median and quantiles\n",
    "                mean_traj = trajectories_array.mean(axis=1)\n",
    "                median_traj = np.median(trajectories_array, axis=1)\n",
    "                q25 = np.percentile(trajectories_array, 25, axis=1)\n",
    "                q75 = np.percentile(trajectories_array, 75, axis=1)\n",
    "                \n",
    "                plt.plot(mean_traj, label='Mean', linewidth=2)\n",
    "                plt.plot(median_traj, label='Median', linestyle='--', linewidth=2)\n",
    "                plt.fill_between(range(len(mean_traj)), q25, q75, alpha=0.3, label='25-75 Percentile')\n",
    "                \n",
    "                # Show some individual trajectories\n",
    "                for i in range(min(5, trajectories_array.shape[1])):\n",
    "                    plt.plot(trajectories_array[:, i], alpha=0.3, linewidth=1)\n",
    "            else:\n",
    "                # Show all trajectories for small number of parameters\n",
    "                for i in range(trajectories_array.shape[1]):\n",
    "                    plt.plot(trajectories_array[:, i], alpha=0.7, label=f'Dim {i}')\n",
    "        else:\n",
    "            # For scalar parameters\n",
    "            plt.plot(trajectories_array, linewidth=2)\n",
    "            \n",
    "        plt.title(f'{param_name} Convergence', fontsize=14)\n",
    "        plt.xlabel('Epoch', fontsize=12)\n",
    "        plt.ylabel('Value', fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.5)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plots_dir, f'{param_name}_convergence.png'), dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    # 3. Cross-validation results with better visualization\n",
    "    c_indices = [result['c_index'] for result in fold_results]\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    # Create a violin plot\n",
    "    plt.violinplot(c_indices, showmeans=True, showmedians=True)\n",
    "    \n",
    "    # Add individual points\n",
    "    plt.plot([1] * len(c_indices), c_indices, 'o', color='blue', alpha=0.7)\n",
    "    \n",
    "    # Add text with statistics\n",
    "    mean_c = np.mean(c_indices)\n",
    "    std_c = np.std(c_indices)\n",
    "    plt.text(1.2, min(c_indices), \n",
    "             f'Mean: {mean_c:.4f}\\nStd: {std_c:.4f}', \n",
    "             fontsize=12, bbox=dict(facecolor='white', alpha=0.7))\n",
    "    \n",
    "    plt.title('Cross-validation C-index Distribution', fontsize=14)\n",
    "    plt.ylabel('C-index', fontsize=12)\n",
    "    plt.xticks([1], ['C-index'])\n",
    "    plt.ylim([min(c_indices)-0.05, max(c_indices)+0.05])\n",
    "    plt.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'cv_c_index.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Feature importance and stability with sorted importance\n",
    "    beta_samples = np.stack([result['param_trajectories']['beta_loc'][-1] \n",
    "                           for result in fold_results])\n",
    "    \n",
    "    # Calculate mean absolute values for importance ranking\n",
    "    mean_abs_betas = np.mean(np.abs(beta_samples), axis=0)\n",
    "    top_indices = np.argsort(-mean_abs_betas)[:50]  # Top 50 features\n",
    "    \n",
    "    # Plot top features importance\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sorted_betas = beta_samples[:, top_indices]\n",
    "    \n",
    "    ax = sns.heatmap(sorted_betas, cmap='coolwarm', center=0, \n",
    "                    cbar_kws={'label': 'Coefficient Value'})\n",
    "    plt.title('Top 50 Feature Coefficients Across Folds', fontsize=14)\n",
    "    plt.xlabel('Feature Rank', fontsize=12)\n",
    "    plt.ylabel('Fold', fontsize=12)\n",
    "    \n",
    "    # Add feature index annotations\n",
    "    feature_indices = [f\"{idx}\" for idx in top_indices]\n",
    "    ax.set_xticks(np.arange(len(feature_indices)))\n",
    "    ax.set_xticklabels(feature_indices, rotation=90)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'feature_importance.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Stability of top features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    # Calculate mean and std of coefficients across folds\n",
    "    mean_betas = np.mean(beta_samples, axis=0)\n",
    "    std_betas = np.std(beta_samples, axis=0)\n",
    "    \n",
    "    # Select top 20 by absolute value\n",
    "    top20_idx = np.argsort(-np.abs(mean_betas))[:20]\n",
    "    \n",
    "    # Sort in descending order of absolute mean\n",
    "    sorted_indices = top20_idx[np.argsort(-np.abs(mean_betas[top20_idx]))]\n",
    "    \n",
    "    # Plot with error bars\n",
    "    plt.errorbar(range(len(sorted_indices)), mean_betas[sorted_indices], \n",
    "                yerr=std_betas[sorted_indices], fmt='o', capsize=5,\n",
    "                ecolor='red', marker='o', mfc='blue', mec='blue', ms=8)\n",
    "    \n",
    "    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.xticks(range(len(sorted_indices)), [str(idx) for idx in sorted_indices], rotation=90)\n",
    "    plt.title('Top 20 Features: Mean and Standard Deviation Across Folds', fontsize=14)\n",
    "    plt.xlabel('Feature Index', fontsize=12)\n",
    "    plt.ylabel('Coefficient Value', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'feature_stability.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Setup GPU\n",
    "    setup_gpu()\n",
    "    \n",
    "    # Create results directory\n",
    "    os.makedirs(config[\"results_dir\"], exist_ok=True)\n",
    "    \n",
    "    # Save configuration\n",
    "    with open(os.path.join(config[\"results_dir\"], 'config.json'), 'w') as f:\n",
    "        json.dump({k: str(v) if isinstance(v, (torch.dtype, type)) else v \n",
    "                  for k, v in config.items()}, f, indent=2)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    try:\n",
    "        X_tensor, time_tensor, event_tensor = load_and_preprocess(config[\"data_path\"], config)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in data preprocessing: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    try:\n",
    "        fold_results = []\n",
    "        all_val_losses = []\n",
    "        \n",
    "        # Cross-validation\n",
    "        fold_results = cross_validate(BayesianCoxModel, X_tensor, time_tensor, event_tensor, config)\n",
    "        \n",
    "        # Extract validation losses from each fold\n",
    "        for result in fold_results:\n",
    "            if 'val_losses' in result:\n",
    "                all_val_losses.append(result['val_losses'])\n",
    "        \n",
    "        # Calculate average convergence epoch from cross-validation\n",
    "        cv_stopping_epochs = []\n",
    "        for result in fold_results:\n",
    "            if 'last_epoch' in result:\n",
    "                cv_stopping_epochs.append(result['last_epoch'])\n",
    "        \n",
    "        # Determine optimal final training epochs based on CV\n",
    "        if cv_stopping_epochs:\n",
    "            optimal_epochs = int(np.mean(cv_stopping_epochs))\n",
    "            print(f\"Using {optimal_epochs} epochs for final model based on cross-validation\")\n",
    "        else:\n",
    "            # Default to 1700 based on the logs you shared\n",
    "            optimal_epochs = 1700\n",
    "            print(f\"Using default {optimal_epochs} epochs for final model\")\n",
    "        \n",
    "        # Train final model on full dataset with fixed epochs\n",
    "        dataset = TensorDataset(X_tensor, time_tensor, event_tensor)\n",
    "        train_loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            pin_memory=False,\n",
    "            generator=torch.Generator(device=config[\"device\"])\n",
    "        )\n",
    "        \n",
    "        # Create a new config for final training with fixed epochs\n",
    "        final_config = config.copy()\n",
    "        final_config[\"max_epochs\"] = optimal_epochs\n",
    "        \n",
    "        print(f\"\\nTraining final model on full dataset for {optimal_epochs} epochs\")\n",
    "        final_model = BayesianCoxModel(final_config)\n",
    "        losses, _, param_trajectories = final_model.train(train_loader)\n",
    "        \n",
    "        # Plot enhanced diagnostics\n",
    "        plot_diagnostics(config[\"results_dir\"], fold_results, losses, all_val_losses, param_trajectories)\n",
    "        \n",
    "        # Save results summary\n",
    "        results_summary = {\n",
    "            'mean_c_index': float(np.mean([r['c_index'] for r in fold_results])),\n",
    "            'std_c_index': float(np.std([r['c_index'] for r in fold_results])),\n",
    "            'final_loss': float(losses[-1]),\n",
    "            'n_epochs_final': len(losses),\n",
    "            'optimal_epochs': optimal_epochs,\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(config[\"results_dir\"], 'results_summary.json'), 'w') as f:\n",
    "            json.dump(results_summary, f, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training: {e}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        raise\n",
    "    \n",
    "    finally:\n",
    "        # Clean up\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nProcess interrupted by user\")\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in main execution: {e}\")\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a533d6-1f0e-4f01-9771-572217610b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb379065-b77e-41e5-9e13-45a0e970a96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8f04c-6777-4aa1-a301-b8c672c55007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b2f5b9-1774-48fd-b52b-0e59b946221c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f17055-7b75-4703-9cf8-fe32c4d95b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c49e6-2fc6-40f5-ac95-b881160d24cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a956f1f6-9efb-4772-959d-e75843b267c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d968078b-1506-4c36-a38d-429f1a0c69c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CHIKOM~1\\ANACON~1\\envs\\vb_cox_pymc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU Information:\n",
      "PyTorch version: 2.4.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "Device: NVIDIA GeForce GTX 1650\n",
      "Device count: 1\n",
      "Current device: 0\n",
      "Initial GPU Memory: 0.00 MB allocated, 0.00 MB reserved\n",
      "Loading data from: D:\\cox-model-imputation\\error-in-r-code-for-mcar\\datasets\\vb-cox\\realistic_cox_data.csv\n",
      "Data shape: (800, 1003)\n",
      "Data loading time: 0.48s\n",
      "Data loaded on: cuda:0\n",
      "Number of features: 1000\n",
      "Number of samples: 800\n",
      "Event rate: 58.88%\n",
      "\n",
      "Training fold 1/5\n",
      "\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  spike_prob_alpha: torch.Size([])\n",
      "  spike_prob_beta: torch.Size([])\n",
      "  indicator_probs: torch.Size([1000])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 70216900.5101\n",
      "Validation Loss = 282162271.3597\n",
      "Epoch 100: Loss = 69573394.1974\n",
      "Validation Loss = 279230771.9785\n",
      "Epoch 200: Loss = 67989846.9902\n",
      "Validation Loss = 276021169.3175\n",
      "Epoch 300: Loss = 68978011.7507\n",
      "Validation Loss = 272913166.6624\n",
      "Epoch 400: Loss = 66570225.5060\n",
      "Validation Loss = 265174636.1148\n",
      "Epoch 500: Loss = 66843504.5160\n",
      "Validation Loss = 263630360.8446\n",
      "Epoch 600: Loss = 66032361.3378\n",
      "Validation Loss = 266450598.8165\n",
      "Epoch 700: Loss = 64919269.4661\n",
      "Validation Loss = 264751186.4590\n",
      "Epoch 800: Loss = 64650065.9472\n",
      "Validation Loss = 258757180.6106\n",
      "Epoch 900: Loss = 63614767.6864\n",
      "Validation Loss = 254348255.1854\n",
      "Epoch 1000: Loss = 62616046.6236\n",
      "Validation Loss = 252166940.6085\n",
      "Epoch 1100: Loss = 62478295.5206\n",
      "Validation Loss = 251195602.2464\n",
      "Epoch 1200: Loss = 62374630.3365\n",
      "Validation Loss = 245480173.1892\n",
      "Epoch 1300: Loss = 61314374.4355\n",
      "Validation Loss = 248194239.0424\n",
      "Epoch 1400: Loss = 60525319.5326\n",
      "Validation Loss = 241644925.6896\n",
      "Epoch 1500: Loss = 60872700.5500\n",
      "Validation Loss = 240951141.3643\n",
      "Early stopping at epoch 1517\n",
      "\n",
      "Training fold 2/5\n",
      "\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  spike_prob_alpha: torch.Size([])\n",
      "  spike_prob_beta: torch.Size([])\n",
      "  indicator_probs: torch.Size([1000])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 70097376.5385\n",
      "Validation Loss = 276556772.5982\n",
      "Epoch 100: Loss = 69484882.7002\n",
      "Validation Loss = 282185672.2590\n",
      "Epoch 200: Loss = 68948299.6649\n",
      "Validation Loss = 276569269.1176\n",
      "Epoch 300: Loss = 67702881.1514\n",
      "Validation Loss = 269619971.2299\n",
      "Epoch 400: Loss = 67805758.5022\n",
      "Validation Loss = 269530030.7492\n",
      "Epoch 500: Loss = 66748140.2266\n",
      "Validation Loss = 267680577.8136\n",
      "Epoch 600: Loss = 66171526.9719\n",
      "Validation Loss = 254323459.2051\n",
      "Epoch 700: Loss = 64336447.2457\n",
      "Validation Loss = 264330661.6450\n",
      "Epoch 800: Loss = 64422222.9268\n",
      "Validation Loss = 259113092.3215\n",
      "Epoch 900: Loss = 64302447.2342\n",
      "Validation Loss = 256720063.1243\n",
      "Epoch 1000: Loss = 63542818.1561\n",
      "Validation Loss = 255399824.9457\n",
      "Epoch 1100: Loss = 62372358.9741\n",
      "Validation Loss = 246426498.9584\n",
      "Epoch 1200: Loss = 61934404.4239\n",
      "Validation Loss = 244225661.8812\n",
      "Epoch 1300: Loss = 61030174.7647\n",
      "Validation Loss = 244295946.6169\n",
      "Epoch 1400: Loss = 61361833.7056\n",
      "Validation Loss = 244824845.0403\n",
      "Epoch 1500: Loss = 60572457.0807\n",
      "Validation Loss = 249935532.9793\n",
      "Epoch 1600: Loss = 59251461.3578\n",
      "Validation Loss = 235551443.4674\n",
      "Epoch 1700: Loss = 59144644.1890\n",
      "Validation Loss = 235054459.0614\n",
      "Epoch 1800: Loss = 58195265.2984\n",
      "Validation Loss = 235441351.8185\n",
      "Epoch 1900: Loss = 57368767.9424\n",
      "Validation Loss = 228235771.5818\n",
      "Epoch 2000: Loss = 57533834.5498\n",
      "Validation Loss = 233369826.6398\n",
      "Epoch 2100: Loss = 56571088.8953\n",
      "Validation Loss = 228074473.0110\n",
      "Epoch 2200: Loss = 56238204.5560\n",
      "Validation Loss = 220217423.3559\n",
      "Epoch 2300: Loss = 55062539.9161\n",
      "Validation Loss = 222835175.7274\n",
      "Epoch 2400: Loss = 53845317.2621\n",
      "Validation Loss = 217785813.8060\n",
      "Epoch 2500: Loss = 53151076.9259\n",
      "Validation Loss = 216979639.5732\n",
      "Epoch 2600: Loss = 53708405.1965\n",
      "Validation Loss = 212616837.0430\n",
      "Epoch 2700: Loss = 53255368.9951\n",
      "Validation Loss = 211132346.8470\n",
      "Epoch 2800: Loss = 52382368.9095\n",
      "Validation Loss = 212865306.7063\n",
      "Epoch 2900: Loss = 52396298.2265\n",
      "Validation Loss = 210842097.7448\n",
      "Epoch 3000: Loss = 50956914.1330\n",
      "Validation Loss = 202992628.9785\n",
      "Epoch 3100: Loss = 51063067.1666\n",
      "Validation Loss = 206279552.9962\n",
      "Epoch 3200: Loss = 50475848.3871\n",
      "Validation Loss = 203697978.6986\n",
      "Epoch 3300: Loss = 49518769.7923\n",
      "Validation Loss = 204545627.9178\n",
      "Epoch 3400: Loss = 49317810.5550\n",
      "Validation Loss = 193263757.2050\n",
      "Epoch 3500: Loss = 48726616.6828\n",
      "Validation Loss = 194758960.9808\n",
      "Epoch 3600: Loss = 48291991.7563\n",
      "Validation Loss = 190969398.6696\n",
      "Epoch 3700: Loss = 46983592.2428\n",
      "Validation Loss = 191943981.0264\n",
      "Epoch 3800: Loss = 47043959.0178\n",
      "Validation Loss = 190825311.6020\n",
      "Epoch 3900: Loss = 46690224.7268\n",
      "Validation Loss = 183112523.7806\n",
      "Epoch 4000: Loss = 46196253.7422\n",
      "Validation Loss = 181434183.9457\n",
      "Epoch 4100: Loss = 46186707.8870\n",
      "Validation Loss = 180517575.2191\n",
      "Epoch 4200: Loss = 44563167.6333\n",
      "Validation Loss = 178612220.3358\n",
      "Epoch 4300: Loss = 44542248.6438\n",
      "Validation Loss = 180763617.9461\n",
      "Epoch 4400: Loss = 44300092.2035\n",
      "Validation Loss = 177324231.7258\n",
      "Epoch 4500: Loss = 43074325.8033\n",
      "Validation Loss = 172333460.5864\n",
      "Epoch 4600: Loss = 42808152.2296\n",
      "Validation Loss = 172338682.2286\n",
      "Epoch 4700: Loss = 42441311.8586\n",
      "Validation Loss = 171749601.3128\n",
      "Epoch 4800: Loss = 42752914.7428\n",
      "Validation Loss = 170360356.4328\n",
      "Epoch 4900: Loss = 42246642.8393\n",
      "Validation Loss = 167020786.5206\n",
      "\n",
      "Training fold 3/5\n",
      "\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  spike_prob_alpha: torch.Size([])\n",
      "  spike_prob_beta: torch.Size([])\n",
      "  indicator_probs: torch.Size([1000])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 70268078.4139\n",
      "Validation Loss = 280868800.6921\n",
      "Epoch 100: Loss = 68583663.4152\n",
      "Validation Loss = 280722212.5394\n",
      "Epoch 200: Loss = 68117394.1714\n",
      "Validation Loss = 281597720.9378\n",
      "Epoch 300: Loss = 68375911.7216\n",
      "Validation Loss = 272685740.0944\n",
      "Epoch 400: Loss = 67037372.4151\n",
      "Validation Loss = 271670074.1399\n",
      "Epoch 500: Loss = 66821580.1026\n",
      "Validation Loss = 262698063.9836\n",
      "Epoch 600: Loss = 65907874.4623\n",
      "Validation Loss = 258580380.7605\n",
      "Epoch 700: Loss = 65040902.0980\n",
      "Validation Loss = 259739496.1556\n",
      "Epoch 800: Loss = 65258170.2758\n",
      "Validation Loss = 257541681.1370\n",
      "Epoch 900: Loss = 63954389.0605\n",
      "Validation Loss = 249269382.9108\n",
      "Epoch 1000: Loss = 63810627.1001\n",
      "Validation Loss = 250201521.0931\n",
      "Epoch 1100: Loss = 62155687.1410\n",
      "Validation Loss = 249172527.7041\n",
      "Epoch 1200: Loss = 61975267.7804\n",
      "Validation Loss = 248573834.6116\n",
      "Epoch 1300: Loss = 61442774.3949\n",
      "Validation Loss = 246694133.4157\n",
      "Epoch 1400: Loss = 60447781.0064\n",
      "Validation Loss = 243093592.6499\n",
      "Epoch 1500: Loss = 59614685.7943\n",
      "Validation Loss = 239711273.2823\n",
      "Epoch 1600: Loss = 59511240.1840\n",
      "Validation Loss = 238565285.3594\n",
      "Epoch 1700: Loss = 59024726.3050\n",
      "Validation Loss = 237103050.4152\n",
      "Epoch 1800: Loss = 58668025.7237\n",
      "Validation Loss = 232886403.9843\n",
      "Epoch 1900: Loss = 57247393.5110\n",
      "Validation Loss = 232586110.8378\n",
      "Epoch 2000: Loss = 56350994.2177\n",
      "Validation Loss = 231193772.8921\n",
      "Epoch 2100: Loss = 57045041.7925\n",
      "Validation Loss = 225768995.2899\n",
      "Epoch 2200: Loss = 55415621.8236\n",
      "Validation Loss = 222511118.1145\n",
      "Epoch 2300: Loss = 54753523.0517\n",
      "Validation Loss = 223173230.6753\n",
      "Epoch 2400: Loss = 53941796.3148\n",
      "Validation Loss = 220679181.5159\n",
      "Epoch 2500: Loss = 54408751.4435\n",
      "Validation Loss = 212399113.5812\n",
      "Epoch 2600: Loss = 53429380.8198\n",
      "Validation Loss = 214223629.3789\n",
      "Epoch 2700: Loss = 52756459.9571\n",
      "Validation Loss = 209874559.9100\n",
      "Epoch 2800: Loss = 51909374.3047\n",
      "Validation Loss = 204908926.6547\n",
      "Epoch 2900: Loss = 52343606.6315\n",
      "Validation Loss = 204879766.2604\n",
      "Epoch 3000: Loss = 51197436.1004\n",
      "Validation Loss = 200861729.8717\n",
      "Epoch 3100: Loss = 51137007.0728\n",
      "Validation Loss = 201280301.9287\n",
      "Epoch 3200: Loss = 50581547.4689\n",
      "Validation Loss = 202495888.3355\n",
      "Epoch 3300: Loss = 50184015.0291\n",
      "Validation Loss = 195610703.7669\n",
      "Epoch 3400: Loss = 48912740.1193\n",
      "Validation Loss = 197005249.6577\n",
      "Epoch 3500: Loss = 48353206.4468\n",
      "Validation Loss = 195505412.1079\n",
      "Epoch 3600: Loss = 47957033.7818\n",
      "Validation Loss = 195884517.3947\n",
      "Epoch 3700: Loss = 47723357.8535\n",
      "Validation Loss = 190243854.3849\n",
      "Epoch 3800: Loss = 46613013.8640\n",
      "Validation Loss = 188786846.3492\n",
      "Epoch 3900: Loss = 46321256.0884\n",
      "Validation Loss = 188293359.5430\n",
      "Epoch 4000: Loss = 46290832.4307\n",
      "Validation Loss = 184622661.9188\n",
      "Epoch 4100: Loss = 46365934.1389\n",
      "Validation Loss = 181372698.5245\n",
      "Epoch 4200: Loss = 45022719.1102\n",
      "Validation Loss = 178938245.9107\n",
      "Epoch 4300: Loss = 44985438.4545\n",
      "Validation Loss = 177285339.0065\n",
      "Epoch 4400: Loss = 43534641.2222\n",
      "Validation Loss = 176207004.2808\n",
      "Epoch 4500: Loss = 43577689.3194\n",
      "Validation Loss = 176255099.5574\n",
      "Epoch 4600: Loss = 43466135.5790\n",
      "Validation Loss = 171757132.8457\n",
      "Epoch 4700: Loss = 42740106.8736\n",
      "Validation Loss = 172644245.7415\n",
      "Epoch 4800: Loss = 42834274.8139\n",
      "Validation Loss = 168147541.7122\n",
      "Epoch 4900: Loss = 41545989.8708\n",
      "Validation Loss = 167118975.3359\n",
      "\n",
      "Training fold 4/5\n",
      "\n",
      "Initialized parameters:\n",
      "  global_scale_loc: torch.Size([])\n",
      "  global_scale_scale: torch.Size([])\n",
      "  spike_prob_alpha: torch.Size([])\n",
      "  spike_prob_beta: torch.Size([])\n",
      "  indicator_probs: torch.Size([1000])\n",
      "  local_scale_loc: torch.Size([1000])\n",
      "  local_scale_scale: torch.Size([1000])\n",
      "  beta_loc: torch.Size([1000])\n",
      "  beta_scale: torch.Size([1000])\n",
      "Epoch 0: Loss = 70317019.6463\n",
      "Validation Loss = 281760232.4404\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from pyro.optim import ClippedAdam\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    # Training parameters\n",
    "    \"max_epochs\": 5000,\n",
    "    \"batch_size\": 128,\n",
    "    \"initial_lr\": 1e-5,        # Updated for numerical stability\n",
    "    \"lr_decay\": 0.2,\n",
    "    \"decay_step\": 500,\n",
    "    \"clip_norm\": 1.0,          # Updated from 10.0\n",
    "    \"early_stop_patience\": 200,\n",
    "    \n",
    "    # Device and precision\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"precision\": torch.float32,\n",
    "    \"pin_memory\": False if torch.cuda.is_available() else True,\n",
    "    \"num_workers\": 0,\n",
    "    \"cuda_deterministic\": False,\n",
    "    \n",
    "    # Model parameters\n",
    "    \"elbo_particles\": 10,\n",
    "    \"warmup_epochs\": 100,\n",
    "    \"n_folds\": 5,\n",
    "    \n",
    "    # Spike-and-slab lasso parameters\n",
    "    \"max_risk_score\": 10.0,\n",
    "    \"min_scale\": 1e-5,\n",
    "    \"init_spike_prob\": 0.1,\n",
    "    \"slab_df\": 0.1,\n",
    "    \"lasso_scale\": 0.1,\n",
    "    \n",
    "    # Logging and checkpointing\n",
    "    \"log_freq\": 100,\n",
    "    \"checkpoint_freq\": 500,\n",
    "    \n",
    "    # Paths\n",
    "    \"data_path\": r\"D:\\cox-model-imputation\\error-in-r-code-for-mcar\\datasets\\vb-cox\\realistic_cox_data.csv\",\n",
    "    \"results_dir\": f\"results_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "}\n",
    "\n",
    "class CoxPartialLikelihood(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-8\n",
    "        self.max_exp = 20.0\n",
    "        \n",
    "    def forward(self, risk_scores, survival_time, event):\n",
    "        event_mask = event == 1\n",
    "        n_events = event_mask.sum()\n",
    "        n_samples = event.shape[0]\n",
    "        \n",
    "        if n_events < 1:\n",
    "            return torch.tensor(0.0, device=risk_scores.device)\n",
    "        \n",
    "        risk_scores = risk_scores - risk_scores.mean()\n",
    "        risk_scores = torch.clamp(risk_scores, min=-self.max_exp, max=self.max_exp)\n",
    "        \n",
    "        sorted_times, indices = torch.sort(survival_time, descending=True)\n",
    "        risk_scores = risk_scores[indices]\n",
    "        event_mask = event_mask[indices]\n",
    "        \n",
    "        risk_scores_exp = torch.exp(risk_scores)\n",
    "        cumsum_risk = torch.cumsum(risk_scores_exp, dim=0)\n",
    "        log_cumsum_risk = torch.log(cumsum_risk + self.eps)\n",
    "        \n",
    "        event_likelihood = risk_scores[event_mask] - log_cumsum_risk[event_mask]\n",
    "        \n",
    "        # Normalize by both number of events and samples\n",
    "        return event_likelihood.sum() / (n_events * torch.log(torch.tensor(n_samples, device=risk_scores.device)))\n",
    "\n",
    "def model(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    device = X.device\n",
    "    \n",
    "    # More conservative scale for global shrinkage\n",
    "    global_scale = pyro.sample(\"global_scale\", \n",
    "                             dist.HalfCauchy(torch.tensor(0.1, device=device)))\n",
    "    \n",
    "    # More informative prior for spike probability\n",
    "    spike_prob = pyro.sample(\"spike_prob\",\n",
    "                            dist.Beta(torch.tensor(2.0, device=device),\n",
    "                                    torch.tensor(2.0, device=device)))\n",
    "    \n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        # Binary indicators for spike-and-slab\n",
    "        indicators = pyro.sample(\"indicators\",\n",
    "                               dist.Bernoulli(probs=spike_prob))\n",
    "        \n",
    "        # More conservative scale for local shrinkage\n",
    "        local_scale = pyro.sample(\"local_scale\", \n",
    "                                dist.HalfCauchy(torch.tensor(0.1, device=device)))\n",
    "        \n",
    "        # Combine spike and slab components with better numerical stability\n",
    "        scale = torch.clamp(\n",
    "            indicators * global_scale * local_scale + \n",
    "            (1 - indicators) * config[\"min_scale\"],\n",
    "            min=config[\"min_scale\"],\n",
    "            max=1.0\n",
    "        )\n",
    "        \n",
    "        # Use Normal distribution instead of Laplace for better stability\n",
    "        beta = pyro.sample(\"beta\", \n",
    "                          dist.Normal(torch.zeros(p, device=device), scale))\n",
    "    \n",
    "    # Compute risk scores with better numerical stability\n",
    "    risk_scores = torch.clamp(X @ beta, min=-config[\"max_risk_score\"], max=config[\"max_risk_score\"])\n",
    "    \n",
    "    # Compute likelihood\n",
    "    cox_likelihood = CoxPartialLikelihood()\n",
    "    log_pl = cox_likelihood(risk_scores, survival_time, event)\n",
    "    pyro.factor(\"log_pl\", log_pl)\n",
    "    \n",
    "    return beta\n",
    "\n",
    "def guide(X, survival_time, event):\n",
    "    n, p = X.shape\n",
    "    device = X.device\n",
    "    \n",
    "    # More conservative initialization for global scale\n",
    "    global_scale_loc = pyro.param(\n",
    "        \"global_scale_loc\",\n",
    "        torch.tensor(0.1, device=device),\n",
    "        constraint=constraints.positive\n",
    "    )\n",
    "    global_scale_scale = pyro.param(\n",
    "        \"global_scale_scale\",\n",
    "        torch.tensor(0.01, device=device),\n",
    "        constraint=constraints.positive\n",
    "    )\n",
    "    \n",
    "    spike_prob_alpha = pyro.param(\n",
    "        \"spike_prob_alpha\",\n",
    "        torch.tensor(2.0, device=device),\n",
    "        constraint=constraints.positive\n",
    "    )\n",
    "    spike_prob_beta = pyro.param(\n",
    "        \"spike_prob_beta\",\n",
    "        torch.tensor(2.0, device=device),\n",
    "        constraint=constraints.positive\n",
    "    )\n",
    "    \n",
    "    pyro.sample(\n",
    "        \"global_scale\",\n",
    "        dist.LogNormal(global_scale_loc.log(), global_scale_scale)\n",
    "    )\n",
    "    \n",
    "    pyro.sample(\n",
    "        \"spike_prob\",\n",
    "        dist.Beta(spike_prob_alpha, spike_prob_beta)\n",
    "    )\n",
    "    \n",
    "    with pyro.plate(\"features\", p, dim=-1):\n",
    "        indicator_probs = pyro.param(\n",
    "            \"indicator_probs\",\n",
    "            torch.ones(p, device=device) * 0.1,\n",
    "            constraint=constraints.interval(0.0, 1.0)\n",
    "        )\n",
    "        \n",
    "        local_scale_loc = pyro.param(\n",
    "            \"local_scale_loc\",\n",
    "            torch.ones(p, device=device) * 0.1,\n",
    "            constraint=constraints.positive\n",
    "        )\n",
    "        local_scale_scale = pyro.param(\n",
    "            \"local_scale_scale\",\n",
    "            torch.ones(p, device=device) * 0.01,\n",
    "            constraint=constraints.positive\n",
    "        )\n",
    "        \n",
    "        beta_loc = pyro.param(\n",
    "            \"beta_loc\",\n",
    "            torch.zeros(p, device=device)\n",
    "        )\n",
    "        beta_scale = pyro.param(\n",
    "            \"beta_scale\",\n",
    "            torch.ones(p, device=device) * 0.1,\n",
    "            constraint=constraints.positive\n",
    "        )\n",
    "        \n",
    "        pyro.sample(\"indicators\", dist.Bernoulli(indicator_probs))\n",
    "        \n",
    "        pyro.sample(\n",
    "            \"local_scale\",\n",
    "            dist.LogNormal(local_scale_loc.log(), local_scale_scale)\n",
    "        )\n",
    "        \n",
    "        pyro.sample(\"beta\", dist.Normal(beta_loc, beta_scale))\n",
    "\n",
    "def initialize_params():\n",
    "    device = config[\"device\"]\n",
    "    \n",
    "    X_dummy = torch.zeros((10, 1000), device=device)\n",
    "    time_dummy = torch.zeros(10, device=device)\n",
    "    event_dummy = torch.zeros(10, device=device)\n",
    "    \n",
    "    pyro.clear_param_store()\n",
    "    try:\n",
    "        model(X_dummy, time_dummy, event_dummy)\n",
    "        guide(X_dummy, time_dummy, event_dummy)\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing parameters: {e}\")\n",
    "        raise\n",
    "    \n",
    "    print(\"\\nInitialized parameters:\")\n",
    "    for name, param in pyro.get_param_store().items():\n",
    "        print(f\"  {name}: {param.shape}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def setup_gpu():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "        \n",
    "        print(\"\\nGPU Information:\")\n",
    "        print(f\"PyTorch version: {torch.__version__}\")\n",
    "        print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "        print(f\"Initial GPU Memory: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB allocated, {torch.cuda.memory_reserved(0)/1024**2:.2f} MB reserved\")\n",
    "        \n",
    "        torch.backends.cudnn.deterministic = config[\"cuda_deterministic\"]\n",
    "        torch.backends.cudnn.benchmark = not config[\"cuda_deterministic\"]\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(\"\\nNo GPU available, using CPU\")\n",
    "        return False\n",
    "\n",
    "def load_and_preprocess(path, config):\n",
    "    print(f\"Loading data from: {path}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(path)\n",
    "        print(f\"Data shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "    \n",
    "    X = data.iloc[:, 1:-2].values\n",
    "    time_values = data['time'].values\n",
    "    event_values = data['event'].values\n",
    "    \n",
    "    # Improved preprocessing\n",
    "    X = (X - np.nanmean(X, axis=0)) / (np.nanstd(X, axis=0) + 1e-8)\n",
    "    X = np.clip(X, -10, 10)  # Add clipping to prevent extreme values\n",
    "    X = np.nan_to_num(X, 0)  # Replace any remaining NaNs with 0\n",
    "    \n",
    "    X_tensor = torch.tensor(X, dtype=config[\"precision\"]).to(config[\"device\"])\n",
    "    time_tensor = torch.tensor(time_values, dtype=config[\"precision\"]).to(config[\"device\"])\n",
    "    event_tensor = torch.tensor(event_values, dtype=config[\"precision\"]).to(config[\"device\"])\n",
    "    \n",
    "    print(f\"Data loading time: {time.time()-start_time:.2f}s\")\n",
    "    print(f\"Data loaded on: {X_tensor.device}\")\n",
    "    print(f\"Number of features: {X_tensor.shape[1]}\")\n",
    "    print(f\"Number of samples: {X_tensor.shape[0]}\")\n",
    "    print(f\"Event rate: {event_tensor.mean().item():.2%}\")\n",
    "    \n",
    "    return X_tensor, time_tensor, event_tensor\n",
    "\n",
    "class BayesianCoxModel:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = config[\"device\"]\n",
    "        pyro.clear_param_store()\n",
    "        initialize_params()\n",
    "\n",
    "    def train(self, train_loader, val_loader=None):\n",
    "        optimizer = ClippedAdam({\n",
    "            \"lr\": self.config[\"initial_lr\"],\n",
    "            \"clip_norm\": self.config[\"clip_norm\"],\n",
    "            \"weight_decay\": 1e-4\n",
    "        })\n",
    "        \n",
    "        svi = SVI(model, guide, optimizer, \n",
    "                 loss=Trace_ELBO(num_particles=self.config[\"elbo_particles\"]))\n",
    "        \n",
    "        best_loss = float('inf')\n",
    "        losses = []\n",
    "        val_losses = []\n",
    "        patience = 0\n",
    "        param_trajectories = {}\n",
    "        \n",
    "        # Add scale factor for numerical stability\n",
    "        scale_factor = 1.0 / len(train_loader.dataset)\n",
    "        \n",
    "        for name in pyro.get_param_store().keys():\n",
    "            param_trajectories[name] = []\n",
    "        \n",
    "        try:\n",
    "            for epoch in range(self.config[\"max_epochs\"]):\n",
    "                epoch_loss = 0.0\n",
    "                for batch_idx, (X_batch, t_batch, e_batch) in enumerate(train_loader):\n",
    "                    X_batch = X_batch.to(self.device)\n",
    "                    t_batch = t_batch.to(self.device)\n",
    "                    e_batch = e_batch.to(self.device)\n",
    "                    \n",
    "                    loss = svi.step(X_batch, t_batch, e_batch) * scale_factor\n",
    "                    epoch_loss += loss\n",
    "                \n",
    "                avg_loss = epoch_loss / len(train_loader)\n",
    "                losses.append(avg_loss)\n",
    "                \n",
    "                # Store parameter trajectories\n",
    "                for name, param in pyro.get_param_store().items():\n",
    "                    param_trajectories[name].append(param.detach().cpu().numpy())\n",
    "                \n",
    "                if val_loader is not None:\n",
    "                    val_loss = self.evaluate(svi, val_loader)\n",
    "                    val_losses.append(val_loss)\n",
    "                    \n",
    "                    if val_loss < best_loss:\n",
    "                        best_loss = val_loss\n",
    "                        patience = 0\n",
    "                        self.save_checkpoint(epoch, val_loss)\n",
    "                    else:\n",
    "                        patience += 1\n",
    "                    \n",
    "                    if patience >= self.config[\"early_stop_patience\"]:\n",
    "                        print(f\"Early stopping at epoch {epoch}\")\n",
    "                        break\n",
    "                \n",
    "                if epoch % self.config[\"decay_step\"] == 0 and epoch > 0:\n",
    "                    current_lr = self.config[\"initial_lr\"] * \\\n",
    "                               (self.config[\"lr_decay\"] ** (epoch // self.config[\"decay_step\"]))\n",
    "                    optimizer.set_state({'lr': current_lr})\n",
    "                    \n",
    "                if epoch % self.config[\"log_freq\"] == 0:\n",
    "                    print(f\"Epoch {epoch}: Loss = {avg_loss:.4f}\")\n",
    "                    if val_loader is not None:\n",
    "                        print(f\"Validation Loss = {val_losses[-1]:.4f}\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nTraining interrupted by user\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during training: {e}\")\n",
    "            raise\n",
    "        \n",
    "        return losses, val_losses, param_trajectories\n",
    "    \n",
    "    #======================\n",
    "    def evaluate(self, svi, loader):\n",
    "        val_loss = 0.0\n",
    "        scale_factor = 1.0 / len(loader.dataset)\n",
    "        with torch.no_grad():\n",
    "            for X_batch, t_batch, e_batch in loader:\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                t_batch = t_batch.to(self.device)\n",
    "                e_batch = e_batch.to(self.device)\n",
    "                val_loss += svi.evaluate_loss(X_batch, t_batch, e_batch) * scale_factor\n",
    "        return val_loss / len(loader)\n",
    "    \n",
    "    def save_checkpoint(self, epoch, val_loss):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss,\n",
    "            'param_store': pyro.get_param_store().get_state()\n",
    "        }\n",
    "        torch.save(checkpoint, \n",
    "                  os.path.join(self.config[\"results_dir\"], f'best_model.pth'))\n",
    "\n",
    "def cross_validate(model_class, X_tensor, time_tensor, event_tensor, config):\n",
    "    device = config[\"device\"]\n",
    "    kf = KFold(n_splits=config[\"n_folds\"], shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    \n",
    "    X_np = X_tensor.cpu().numpy()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_np)):\n",
    "        print(f\"\\nTraining fold {fold + 1}/{config['n_folds']}\")\n",
    "        \n",
    "        train_idx = torch.tensor(train_idx, device=device)\n",
    "        val_idx = torch.tensor(val_idx, device=device)\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            TensorDataset(X_tensor[train_idx], time_tensor[train_idx], event_tensor[train_idx]),\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            pin_memory=False,\n",
    "            generator=torch.Generator(device=device)\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            TensorDataset(X_tensor[val_idx], time_tensor[val_idx], event_tensor[val_idx]),\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            pin_memory=False,\n",
    "            generator=torch.Generator(device=device)\n",
    "        )\n",
    "        \n",
    "        model = model_class(config)\n",
    "        losses, val_losses, param_trajectories = model.train(train_loader, val_loader)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            beta = pyro.param(\"beta_loc\").detach()\n",
    "            indicators = pyro.param(\"indicator_probs\").detach()\n",
    "            risk_scores = X_tensor[val_idx] @ beta\n",
    "            \n",
    "            metrics = {\n",
    "                'c_index': concordance_index(\n",
    "                    time_tensor[val_idx].cpu().numpy(),\n",
    "                    -risk_scores.cpu().numpy(),\n",
    "                    event_tensor[val_idx].cpu().numpy()\n",
    "                ),\n",
    "                'final_loss': float(losses[-1]),\n",
    "                'param_trajectories': param_trajectories,\n",
    "                'val_losses': val_losses,\n",
    "                'last_epoch': len(losses),\n",
    "                'selected_features': (indicators > 0.5).float().cpu().numpy()\n",
    "            }\n",
    "            \n",
    "            fold_results.append(metrics)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "def plot_diagnostics(results_dir, fold_results, losses, val_losses_list, param_trajectories):\n",
    "    plots_dir = os.path.join(results_dir, 'plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Plot training and validation losses\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.plot(losses, label='Training Loss', color='blue', linewidth=2)\n",
    "    \n",
    "    if val_losses_list:\n",
    "        for fold_idx, val_losses in enumerate(val_losses_list):\n",
    "            plt.plot(val_losses, label=f'Validation Loss (Fold {fold_idx+1})', \n",
    "                     linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.title('Training and Validation Loss Convergence', fontsize=14)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('ELBO Loss', fontsize=12)\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'loss_convergence.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot feature selection probabilities\n",
    "    if 'indicator_probs' in param_trajectories:\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        final_probs = param_trajectories['indicator_probs'][-1]\n",
    "        plt.hist(final_probs, bins=50, alpha=0.7)\n",
    "        plt.title('Feature Selection Probabilities Distribution', fontsize=14)\n",
    "        plt.xlabel('Selection Probability', fontsize=12)\n",
    "        plt.ylabel('Count', fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plots_dir, 'feature_selection_dist.png'), dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    # Plot selected features heatmap\n",
    "    selected_features = np.stack([result['selected_features'] for result in fold_results])\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(selected_features, cmap='coolwarm', center=0.5,\n",
    "                xticklabels=False, yticklabels=range(1, len(fold_results) + 1))\n",
    "    plt.title('Selected Features Across Folds', fontsize=14)\n",
    "    plt.xlabel('Feature Index', fontsize=12)\n",
    "    plt.ylabel('Fold', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'selected_features.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot C-index distribution\n",
    "    c_indices = [result['c_index'] for result in fold_results]\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.violinplot(c_indices, showmeans=True, showmedians=True)\n",
    "    plt.plot([1] * len(c_indices), c_indices, 'o', color='blue', alpha=0.7)\n",
    "    mean_c = np.mean(c_indices)\n",
    "    std_c = np.std(c_indices)\n",
    "    plt.text(1.2, min(c_indices), \n",
    "             f'Mean: {mean_c:.4f}\\nStd: {std_c:.4f}', \n",
    "             fontsize=12, bbox=dict(facecolor='white', alpha=0.7))\n",
    "    plt.title('Cross-validation C-index Distribution', fontsize=14)\n",
    "    plt.ylabel('C-index', fontsize=12)\n",
    "    plt.xticks([1], ['C-index'])\n",
    "    plt.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'cv_c_index.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    setup_gpu()\n",
    "    os.makedirs(config[\"results_dir\"], exist_ok=True)\n",
    "    \n",
    "    with open(os.path.join(config[\"results_dir\"], 'config.json'), 'w') as f:\n",
    "        json.dump({k: str(v) if isinstance(v, (torch.dtype, type)) else v \n",
    "                  for k, v in config.items()}, f, indent=2)\n",
    "    \n",
    "    try:\n",
    "        X_tensor, time_tensor, event_tensor = load_and_preprocess(config[\"data_path\"], config)\n",
    "        fold_results = cross_validate(BayesianCoxModel, X_tensor, time_tensor, event_tensor, config)\n",
    "        \n",
    "        all_val_losses = [result['val_losses'] for result in fold_results if 'val_losses' in result]\n",
    "        cv_stopping_epochs = [result['last_epoch'] for result in fold_results if 'last_epoch' in result]\n",
    "        \n",
    "        optimal_epochs = int(np.mean(cv_stopping_epochs)) if cv_stopping_epochs else 1700\n",
    "        print(f\"\\nUsing {optimal_epochs} epochs for final model based on cross-validation\")\n",
    "        \n",
    "        final_config = config.copy()\n",
    "        final_config[\"max_epochs\"] = optimal_epochs\n",
    "        \n",
    "        dataset = TensorDataset(X_tensor, time_tensor, event_tensor)\n",
    "        train_loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            pin_memory=False,\n",
    "            generator=torch.Generator(device=config[\"device\"])\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nTraining final model on full dataset for {optimal_epochs} epochs\")\n",
    "        final_model = BayesianCoxModel(final_config)\n",
    "        losses, _, param_trajectories = final_model.train(train_loader)\n",
    "        \n",
    "        plot_diagnostics(config[\"results_dir\"], fold_results, losses, all_val_losses, param_trajectories)\n",
    "        \n",
    "        results_summary = {\n",
    "            'mean_c_index': float(np.mean([r['c_index'] for r in fold_results])),\n",
    "            'std_c_index': float(np.std([r['c_index'] for r in fold_results])),\n",
    "            'final_loss': float(losses[-1]),\n",
    "            'n_epochs_final': len(losses),\n",
    "            'optimal_epochs': optimal_epochs,\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(config[\"results_dir\"], 'results_summary.json'), 'w') as f:\n",
    "            json.dump(results_summary, f, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training: {e}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        raise\n",
    "    \n",
    "    finally:\n",
    "        # Clean up\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"\\nTraining completed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nProcess interrupted by user\")\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in main execution: {e}\")\n",
    "        torch.cuda.empty_cache()\n",
    "    finally:\n",
    "        print(\"\\nExecution finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3407d-64b5-45ec-8b7e-bfd6fa20d50b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
